{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, random,datetime\n",
    "\n",
    "\n",
    "sys.path.append(\".\") # For execution form the main file \n",
    "sys.path.append(\"..\") # For execution from the notebook \n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_DTYPES={\"event_name_1\": \"category\",\n",
    "            \"event_name_2\": \"category\",\n",
    "            \"event_type_1\": \"category\", \n",
    "            \"event_type_2\": \"category\",\n",
    "            \"weekday\": \"category\", \n",
    "            'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "            \"month\": \"int16\", \"year\": \"int16\",\n",
    "            \"snap_CA\": \"float32\",\n",
    "            'snap_TX': 'float32',\n",
    "            'snap_WI': 'float32' }\n",
    "PRICE_DTYPES = {\"store_id\": \"category\",\n",
    "                \"item_id\": \"category\",\n",
    "                \"wm_yr_wk\": \"int16\", \n",
    "                \"sell_price\":\"float32\" }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 28 \n",
    "max_lags = 57\n",
    "tr_last = 1913\n",
    "fday = datetime.datetime(2016,4, 25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(is_train = True, nrows = None, first_day = 1200):\n",
    "    prices = pd.read_csv(\"../data/raw/sell_prices.csv\", dtype = PRICE_DTYPES)\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col] -= prices[col].min()\n",
    "            \n",
    "    cal = pd.read_csv(\"../data/raw/calendar.csv\", dtype = CAL_DTYPES)\n",
    "    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col] -= cal[col].min()\n",
    "    \n",
    "    start_day = max(1 if is_train  else tr_last-max_lags, first_day)\n",
    "    numcols = [f\"d_{day}\" for day in range(start_day,tr_last+1)]\n",
    "    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    dtype = {numcol:\"float32\" for numcol in numcols} \n",
    "    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "    dt = pd.read_csv(\"../data/raw/sales_train_validation.csv\", \n",
    "                     nrows = nrows, usecols = catcols + numcols, dtype = dtype)\n",
    "    \n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            dt[col] = dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col] -= dt[col].min()\n",
    "    \n",
    "    if not is_train:\n",
    "        for day in range(tr_last+1, tr_last+ 28 +1):\n",
    "            dt[f\"d_{day}\"] = np.nan\n",
    "    \n",
    "    dt = pd.melt(dt,\n",
    "                  id_vars = catcols,\n",
    "                  value_vars = [col for col in dt.columns if col.startswith(\"d_\")],\n",
    "                  var_name = \"d\",\n",
    "                  value_name = \"sales\")\n",
    "    \n",
    "    dt = dt.merge(cal, on= \"d\", copy = False)\n",
    "    dt = dt.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    \n",
    "    return dt\n",
    "\n",
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n",
    "\n",
    "    \n",
    "    \n",
    "    date_features = {\n",
    "        \n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "#         \"ime\": \"is_month_end\",\n",
    "#         \"ims\": \"is_month_start\",\n",
    "    }\n",
    "    \n",
    "    #     dt.drop([\"d\", \"wm_yr_wk\", \"weekday\"], axis=1, inplace = True)\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FIRST_DAY = 1 # If you want to load all the data set it to '1' -->  Great  memory overflow  risk !\n",
    "df = create_dt(is_train=True, first_day= FIRST_DAY)\n",
    "create_fea(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['item_id', \n",
    "             'dept_id',\n",
    "             'store_id',\n",
    "             'cat_id',\n",
    "             'state_id'] +\\\n",
    "            [\"event_name_1\",\n",
    "             \"event_name_2\",\n",
    "             \"event_type_1\",\n",
    "             \"event_type_2\"]\n",
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "item_id               0\n",
       "dept_id               0\n",
       "store_id              0\n",
       "cat_id                0\n",
       "state_id              0\n",
       "d                     0\n",
       "sales                 0\n",
       "date                  0\n",
       "wm_yr_wk              0\n",
       "weekday               0\n",
       "wday                  0\n",
       "month                 0\n",
       "year                  0\n",
       "event_name_1          0\n",
       "event_type_1          0\n",
       "event_name_2          0\n",
       "event_type_2          0\n",
       "snap_CA               0\n",
       "snap_TX               0\n",
       "snap_WI               0\n",
       "sell_price            0\n",
       "lag_7            213430\n",
       "lag_28           853720\n",
       "rmean_7_7        396370\n",
       "rmean_28_7      1036660\n",
       "rmean_7_28      1036660\n",
       "rmean_28_28     1676950\n",
       "week                  0\n",
       "quarter               0\n",
       "mday                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.87861077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage().sum()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weights for the training (the older the sample the less it will have impact )\n",
    "weights = df['d'].str[2:].astype(int)\n",
    "weights = weights/np.max(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_feats = df.columns[~df.columns.isin(useless_cols+cat_feats)].to_list()\n",
    "train_cols = num_feats+cat_feats\n",
    "\n",
    "X_train = df[train_cols]\n",
    "y_train = df[\"sales\"]\n",
    "\n",
    "np.random.seed(777)\n",
    "fake_valid_inds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "\n",
    "X_test,y_test = X_train.loc[fake_valid_inds],y_train.loc[fake_valid_inds]\n",
    "X_train,y_train = X_train.loc[train_inds],y_train.loc[train_inds]\n",
    "cardinality  = df[cat_feats].max()\n",
    "weights_train =  weights.loc[X_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# further preprocessing \n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train[num_feats] = scaler.fit_transform(X_train[num_feats])\n",
    "# X_test[num_feats] = scaler.fit_transform(X_test[num_feats])\n",
    "\n",
    "# prepare input for tensorflow \n",
    "# as we have multiple input type the best solution is to feed a dict like object \n",
    "\n",
    "input_dict = {f\"input_{col}\": X_train[col] for col in X_train.columns}\n",
    "input_dict_test = {f\"input_{col}\": X_test[col] for col in X_train.columns}\n",
    "\n",
    "del df,X_train,X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wday\n",
      "month\n",
      "year\n",
      "snap_CA\n",
      "snap_TX\n",
      "snap_WI\n",
      "sell_price\n",
      "lag_7\n",
      "lag_28\n",
      "rmean_7_7\n",
      "rmean_28_7\n",
      "rmean_7_28\n",
      "rmean_28_28\n",
      "week\n",
      "quarter\n",
      "mday\n",
      "item_id 3048\n",
      "dept_id 6\n",
      "store_id 9\n",
      "cat_id 2\n",
      "state_id 2\n",
      "event_name_1 30\n",
      "event_name_2 4\n",
      "event_type_1 4\n",
      "event_type_2 2\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_item_id (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_dept_id (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_store_id (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_cat_id (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_state_id (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_event_name_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_event_name_2 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_event_type_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_event_type_2 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_item_id (Embedding)   (None, 1, 50)        152450      input_item_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_dept_id (Embedding)   (None, 1, 3)         21          input_dept_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_store_id (Embedding)  (None, 1, 5)         50          input_store_id[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_cat_id (Embedding)    (None, 1, 1)         3           input_cat_id[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_state_id (Embedding)  (None, 1, 1)         3           input_state_id[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_event_name_1 (Embeddi (None, 1, 15)        465         input_event_name_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_event_name_2 (Embeddi (None, 1, 2)         10          input_event_name_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_event_type_1 (Embeddi (None, 1, 2)         10          input_event_type_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_event_type_2 (Embeddi (None, 1, 1)         3           input_event_type_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_wday (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_month (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_year (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_snap_CA (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_snap_TX (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_snap_WI (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_sell_price (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_lag_7 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_lag_28 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rmean_7_7 (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rmean_28_7 (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rmean_7_28 (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rmean_28_28 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_week (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_quarter (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mday (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 50)        0           embedding_item_id[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 3)         0           embedding_dept_id[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 5)         0           embedding_store_id[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 1)         0           embedding_cat_id[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1, 1)         0           embedding_state_id[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1, 15)        0           embedding_event_name_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 2)         0           embedding_event_name_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1, 2)         0           embedding_event_type_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1, 1)         0           embedding_event_type_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_num (Concatenate)   (None, 16)           0           input_wday[0][0]                 \n",
      "                                                                 input_month[0][0]                \n",
      "                                                                 input_year[0][0]                 \n",
      "                                                                 input_snap_CA[0][0]              \n",
      "                                                                 input_snap_TX[0][0]              \n",
      "                                                                 input_snap_WI[0][0]              \n",
      "                                                                 input_sell_price[0][0]           \n",
      "                                                                 input_lag_7[0][0]                \n",
      "                                                                 input_lag_28[0][0]               \n",
      "                                                                 input_rmean_7_7[0][0]            \n",
      "                                                                 input_rmean_28_7[0][0]           \n",
      "                                                                 input_rmean_7_28[0][0]           \n",
      "                                                                 input_rmean_28_28[0][0]          \n",
      "                                                                 input_week[0][0]                 \n",
      "                                                                 input_quarter[0][0]              \n",
      "                                                                 input_mday[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_item_id (Flatten)       (None, 50)           0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_dept_id (Flatten)       (None, 3)            0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_store_id (Flatten)      (None, 5)            0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_cat_id (Flatten)        (None, 1)            0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_state_id (Flatten)      (None, 1)            0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_event_name_1 (Flatten)  (None, 15)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_event_name_2 (Flatten)  (None, 2)            0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_event_type_1 (Flatten)  (None, 2)            0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_event_type_2 (Flatten)  (None, 1)            0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16)           64          concatenate_num[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_cat (Concatenate)   (None, 80)           0           flatten_item_id[0][0]            \n",
      "                                                                 flatten_dept_id[0][0]            \n",
      "                                                                 flatten_store_id[0][0]           \n",
      "                                                                 flatten_cat_id[0][0]             \n",
      "                                                                 flatten_state_id[0][0]           \n",
      "                                                                 flatten_event_name_1[0][0]       \n",
      "                                                                 flatten_event_name_2[0][0]       \n",
      "                                                                 flatten_event_type_1[0][0]       \n",
      "                                                                 flatten_event_type_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_all (Concatenate)   (None, 96)           0           batch_normalization[0][0]        \n",
      "                                                                 concatenate_cat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Dense_0 (Dense)                 (None, 512)          49664       concatenate_all[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           Dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense_1 (Dense)                 (None, 256)          131328      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           Dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense_2 (Dense)                 (None, 128)          32896       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           Dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128)          512         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense_3 (Dense)                 (None, 64)           8256        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64)           0           Dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64)           256         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 1)            65          batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 379,128\n",
      "Trainable params: 377,176\n",
      "Non-trainable params: 1,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## TF2 model \n",
    "\n",
    "# Dense model, not sequential\n",
    "\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "tfkl = tfk.layers\n",
    "\n",
    "# loss for a poisson regression \n",
    "def poisson(y_true, y_pred): \n",
    "    return K.mean(K.maximum(.0, y_pred) - y_true * K.log(K.maximum(.0, y_pred) + K.epsilon()), axis=-1)\n",
    "\n",
    "def tweedie_loss(y_true, y_pred):\n",
    "    p=1.5\n",
    "    dev = K.pow(y_true, 2-p)/((1-p) * (2-p)) \\\n",
    "    - y_true * K.pow(K.maximum(.0, y_pred)+ K.epsilon(), 1-p)/(1-p) \\\n",
    "    + K.pow(K.maximum(.0, y_pred)+ K.epsilon(), 2-p)/(2-p)\n",
    "    return K.mean(dev,axis=-1)\n",
    "\n",
    "alpha=.5\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    ''' make a comprised loss of poisson and tweedie distribution'''\n",
    "    return (1 - alpha) * poisson(y_true, y_pred) + alpha * tweedie(y_true, y_pred)\n",
    "\n",
    "def create_mlp(layers_list=[512,256,128,64]):\n",
    "    '''\n",
    "    description : \n",
    "    generate regression mlp with\n",
    "    both embedding entries for categorical features and \n",
    "    standard inputs for numerical features\n",
    "\n",
    "    params:\n",
    "    layers_list : list of layers dimensions \n",
    "    output :\n",
    "    compiled keras model  \n",
    "    '''\n",
    "\n",
    "    # define our MLP network\n",
    "    layers = []\n",
    "    output_num = []\n",
    "    inputs = []\n",
    "    output_cat = []\n",
    "    output_num = []\n",
    "    \n",
    "    # sequencial inputs \n",
    "\n",
    "    # numerical data part\n",
    "    if len(num_feats) > 1:\n",
    "        for num_var in num_feats:\n",
    "            print(num_var)\n",
    "            input_num = tfkl.Input(\n",
    "                shape=(1,), name='input_{0}'.format(num_var))\n",
    "            inputs.append(input_num)\n",
    "            output_num.append(input_num)\n",
    "        output_num = tfkl.Concatenate(name='concatenate_num')(output_num)\n",
    "        output_num = tfkl.BatchNormalization()(output_num)\n",
    "\n",
    "    else:\n",
    "        input_num = tfkl.Input(\n",
    "            shape=(1,), name='input_{0}'.format(numeric_features[0]))\n",
    "        inputs.append(input_num)\n",
    "        output_num = input_num\n",
    "\n",
    "    # categorical data input \n",
    "    for categorical_var in cat_feats:\n",
    "        no_of_unique_cat = cardinality[categorical_var] # should me nunique() but events are poorly preprocessed \n",
    "        print(categorical_var , no_of_unique_cat)\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50)\n",
    "        embedding_size = int(embedding_size)\n",
    "        vocab = no_of_unique_cat+1\n",
    "        # functionnal loop\n",
    "        input_cat = tfkl.Input(\n",
    "            shape=(1,), name='input_{0}'.format(categorical_var))\n",
    "        inputs.append(input_cat)\n",
    "        embedding = tfkl.Embedding(vocab,\n",
    "                                   embedding_size,\n",
    "                                   embeddings_regularizer = tf.keras.regularizers.l1(1e-8),\n",
    "                                   name='embedding_{0}'.format(categorical_var))(input_cat)\n",
    "        embedding = tfkl.Dropout(0.1)(embedding)\n",
    "        vec = tfkl.Flatten(name='flatten_{0}'.format(\n",
    "            categorical_var))(embedding)\n",
    "        \n",
    "        output_cat.append(vec)\n",
    "    output_cat = tfkl.Concatenate(name='concatenate_cat')(output_cat)\n",
    "\n",
    "    # concatenate numerical input and embedding output\n",
    "    dense = tfkl.Concatenate(name='concatenate_all')([output_num, output_cat])\n",
    "\n",
    "    for i in range(len(layers_list)):\n",
    "        dense = tfkl.Dense(layers_list[i],\n",
    "                           name='Dense_{0}'.format(str(i)),\n",
    "                           activation='elu')(dense)\n",
    "        dense = tfkl.Dropout(.1)(dense)\n",
    "        dense = tfkl.BatchNormalization()(dense)\n",
    "\n",
    "    dense2 = tfkl.Dense(1, name='Output', activation='elu')(dense)\n",
    "    model = tfk.Model(inputs, dense2)\n",
    "\n",
    "    opt = tfk.optimizers.Adam(learning_rate=1e-3)\n",
    "    model.compile(loss=poisson, optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    del mdl\n",
    "except:\n",
    "    pass\n",
    "\n",
    "mdl = create_mlp()\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 42351007 samples, validate on 2000000 samples\n",
      "Epoch 1/100\n",
      "42351007/42351007 [==============================] - 150s 4us/sample - loss: -0.1180 - root_mean_squared_error: 2.7621 - val_loss: -0.1196 - val_root_mean_squared_error: 2.6695\n",
      "Epoch 2/100\n",
      "42351007/42351007 [==============================] - 142s 3us/sample - loss: -0.1788 - root_mean_squared_error: 2.6547 - val_loss: -0.4662 - val_root_mean_squared_error: 2.4724\n",
      "Epoch 3/100\n",
      "42351007/42351007 [==============================] - 142s 3us/sample - loss: -0.1984 - root_mean_squared_error: 2.6031 - val_loss: -0.4830 - val_root_mean_squared_error: 2.4459\n",
      "Epoch 4/100\n",
      "42351007/42351007 [==============================] - 142s 3us/sample - loss: -0.2070 - root_mean_squared_error: 2.5853 - val_loss: -0.4907 - val_root_mean_squared_error: 2.4265\n",
      "Epoch 5/100\n",
      "42351007/42351007 [==============================] - 141s 3us/sample - loss: -0.2094 - root_mean_squared_error: 2.5772 - val_loss: -0.4960 - val_root_mean_squared_error: 2.4133\n",
      "Epoch 6/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2103 - root_mean_squared_error: 2.5731 - val_loss: -0.4978 - val_root_mean_squared_error: 2.4304\n",
      "Epoch 7/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2124 - root_mean_squared_error: 2.5697 - val_loss: -0.4980 - val_root_mean_squared_error: 2.4100\n",
      "Epoch 8/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2123 - root_mean_squared_error: 2.5727 - val_loss: -0.5008 - val_root_mean_squared_error: 2.4076\n",
      "Epoch 9/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2169 - root_mean_squared_error: 2.5603 - val_loss: -0.5044 - val_root_mean_squared_error: 2.3975\n",
      "Epoch 10/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2183 - root_mean_squared_error: 2.5569 - val_loss: -0.5082 - val_root_mean_squared_error: 2.3942\n",
      "Epoch 11/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2201 - root_mean_squared_error: 2.5490 - val_loss: -0.5092 - val_root_mean_squared_error: 2.3816\n",
      "Epoch 12/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2228 - root_mean_squared_error: 2.5432 - val_loss: -0.5129 - val_root_mean_squared_error: 2.3786\n",
      "Epoch 13/100\n",
      "42351007/42351007 [==============================] - 141s 3us/sample - loss: -0.2238 - root_mean_squared_error: 2.5389 - val_loss: -0.5144 - val_root_mean_squared_error: 2.3742\n",
      "Epoch 14/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2228 - root_mean_squared_error: 2.5404 - val_loss: -0.5122 - val_root_mean_squared_error: 2.3695\n",
      "Epoch 15/100\n",
      "42351007/42351007 [==============================] - 141s 3us/sample - loss: -0.2236 - root_mean_squared_error: 2.5342 - val_loss: -0.5148 - val_root_mean_squared_error: 2.3651\n",
      "Epoch 16/100\n",
      "42351007/42351007 [==============================] - 141s 3us/sample - loss: -0.2239 - root_mean_squared_error: 2.5385 - val_loss: -0.5138 - val_root_mean_squared_error: 2.3971\n",
      "Epoch 17/100\n",
      "42351007/42351007 [==============================] - 141s 3us/sample - loss: -0.2258 - root_mean_squared_error: 2.5294 - val_loss: -0.4592 - val_root_mean_squared_error: 2.5470\n",
      "Epoch 18/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2158 - root_mean_squared_error: 2.5498 - val_loss: -0.2398 - val_root_mean_squared_error: 2.4922\n",
      "Epoch 19/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2164 - root_mean_squared_error: 2.5556 - val_loss: -0.5191 - val_root_mean_squared_error: 2.3653\n",
      "Epoch 20/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2266 - root_mean_squared_error: 2.5305 - val_loss: -0.5213 - val_root_mean_squared_error: 2.3578\n",
      "Epoch 21/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2274 - root_mean_squared_error: 2.5276 - val_loss: -0.5211 - val_root_mean_squared_error: 2.3490\n",
      "Epoch 22/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2265 - root_mean_squared_error: 2.5289 - val_loss: -0.5226 - val_root_mean_squared_error: 2.3479\n",
      "Epoch 23/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2277 - root_mean_squared_error: 2.5262 - val_loss: -0.5258 - val_root_mean_squared_error: 2.3439\n",
      "Epoch 24/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2289 - root_mean_squared_error: 2.5247 - val_loss: -0.5196 - val_root_mean_squared_error: 2.3574\n",
      "Epoch 25/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2290 - root_mean_squared_error: 2.5215 - val_loss: -0.5218 - val_root_mean_squared_error: 2.3552\n",
      "Epoch 26/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2301 - root_mean_squared_error: 2.5196 - val_loss: -0.5227 - val_root_mean_squared_error: 2.3517\n",
      "Epoch 27/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2270 - root_mean_squared_error: 2.5315 - val_loss: -0.5091 - val_root_mean_squared_error: 2.3703\n",
      "Epoch 28/100\n",
      "42351007/42351007 [==============================] - 139s 3us/sample - loss: -0.2313 - root_mean_squared_error: 2.5192 - val_loss: -0.5231 - val_root_mean_squared_error: 2.3378\n",
      "Epoch 29/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2298 - root_mean_squared_error: 2.5211 - val_loss: -0.5206 - val_root_mean_squared_error: 2.3326\n",
      "Epoch 30/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2320 - root_mean_squared_error: 2.5186 - val_loss: -0.5236 - val_root_mean_squared_error: 2.3308\n",
      "Epoch 31/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2301 - root_mean_squared_error: 2.5243 - val_loss: -0.5181 - val_root_mean_squared_error: 2.3372\n",
      "Epoch 32/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2309 - root_mean_squared_error: 2.5173 - val_loss: -0.5251 - val_root_mean_squared_error: 2.3358\n",
      "Epoch 33/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2320 - root_mean_squared_error: 2.5183 - val_loss: -0.5269 - val_root_mean_squared_error: 2.3354\n",
      "Epoch 34/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2328 - root_mean_squared_error: 2.5153 - val_loss: -0.5302 - val_root_mean_squared_error: 2.3305\n",
      "Epoch 35/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2322 - root_mean_squared_error: 2.5178 - val_loss: -0.5308 - val_root_mean_squared_error: 2.3223\n",
      "Epoch 36/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2324 - root_mean_squared_error: 2.5147 - val_loss: -0.5274 - val_root_mean_squared_error: 2.3400\n",
      "Epoch 37/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2330 - root_mean_squared_error: 2.5039 - val_loss: -0.5310 - val_root_mean_squared_error: 2.3310\n",
      "Epoch 38/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2315 - root_mean_squared_error: 2.5108 - val_loss: -0.5307 - val_root_mean_squared_error: 2.3275\n",
      "Epoch 39/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2336 - root_mean_squared_error: 2.4992 - val_loss: -0.5304 - val_root_mean_squared_error: 2.3268\n",
      "Epoch 40/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2321 - root_mean_squared_error: 2.5043 - val_loss: -0.5318 - val_root_mean_squared_error: 2.3150\n",
      "Epoch 41/100\n",
      "42351007/42351007 [==============================] - 139s 3us/sample - loss: -0.2332 - root_mean_squared_error: 2.5032 - val_loss: -0.5318 - val_root_mean_squared_error: 2.3230\n",
      "Epoch 42/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2311 - root_mean_squared_error: 2.4990 - val_loss: -0.5275 - val_root_mean_squared_error: 2.3188\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2334 - root_mean_squared_error: 2.4951 - val_loss: -0.5307 - val_root_mean_squared_error: 2.3233\n",
      "Epoch 44/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2208 - root_mean_squared_error: 2.5357 - val_loss: -0.5309 - val_root_mean_squared_error: 2.3201\n",
      "Epoch 45/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2331 - root_mean_squared_error: 2.4954 - val_loss: -0.5302 - val_root_mean_squared_error: 2.3310\n",
      "Epoch 46/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2344 - root_mean_squared_error: 2.4878 - val_loss: -0.5288 - val_root_mean_squared_error: 2.3366\n",
      "Epoch 47/100\n",
      "42351007/42351007 [==============================] - 140s 3us/sample - loss: -0.2312 - root_mean_squared_error: 2.5022 - val_loss: -0.5302 - val_root_mean_squared_error: 2.3247\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checkpoints  \n",
    "model_save = tfk.callbacks.ModelCheckpoint('model_checkpoints')\n",
    "early_stopping = tfk.callbacks.EarlyStopping('val_root_mean_squared_error',\n",
    "                                             patience = 7,\n",
    "                                            restore_best_weights=True)\n",
    "history = mdl.fit(input_dict,\n",
    "                  y_train.values,\n",
    "                  validation_data=(input_dict_test, y_test.values),\n",
    "                    batch_size=4096,\n",
    "                    epochs=100,\n",
    "                  shuffle=True,\n",
    "                  sample_weight = weights_train.values,\n",
    "                  callbacks=[early_stopping],\n",
    "                  verbose=1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.save('keras_poisson_stable2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# plt.plot(history.history['loss'])\n",
    "# # plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'valid'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history['root_mean_squared_error'])\n",
    "# # plt.plot(history.history['val_loss'])\n",
    "# plt.title('model rmse')\n",
    "# plt.ylabel('rmse')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'valid'], loc='upper left')\n",
    "# plt.show()\n",
    "# plt.savefig('poisson.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-04-25 00:00:00\n",
      "[[0.8589382 ]\n",
      " [0.18866026]\n",
      " [0.35150927]\n",
      " ...\n",
      " [0.7986913 ]\n",
      " [1.007365  ]\n",
      " [1.3013941 ]]\n",
      "0 2016-04-26 00:00:00\n",
      "[[0.81473863]\n",
      " [0.18118778]\n",
      " [0.3471179 ]\n",
      " ...\n",
      " [0.6098655 ]\n",
      " [0.9105312 ]\n",
      " [1.1371032 ]]\n",
      "0 2016-04-27 00:00:00\n",
      "[[0.8396036 ]\n",
      " [0.1937873 ]\n",
      " [0.36002284]\n",
      " ...\n",
      " [0.6243297 ]\n",
      " [0.9226215 ]\n",
      " [1.0865984 ]]\n",
      "0 2016-04-28 00:00:00\n",
      "[[0.90520823]\n",
      " [0.1828256 ]\n",
      " [0.3757764 ]\n",
      " ...\n",
      " [0.5800943 ]\n",
      " [0.8625253 ]\n",
      " [1.1791955 ]]\n",
      "0 2016-04-29 00:00:00\n",
      "[[0.97973776]\n",
      " [0.24200112]\n",
      " [0.5707165 ]\n",
      " ...\n",
      " [0.60721016]\n",
      " [1.0221559 ]\n",
      " [1.4550421 ]]\n",
      "0 2016-04-30 00:00:00\n",
      "[[1.2146274 ]\n",
      " [0.35675222]\n",
      " [0.5996195 ]\n",
      " ...\n",
      " [0.7959142 ]\n",
      " [1.0560411 ]\n",
      " [1.468049  ]]\n",
      "0 2016-05-01 00:00:00\n",
      "[[1.1688615 ]\n",
      " [0.3324589 ]\n",
      " [0.50982136]\n",
      " ...\n",
      " [0.98228085]\n",
      " [1.2533485 ]\n",
      " [1.3501978 ]]\n",
      "0 2016-05-02 00:00:00\n",
      "[[0.88253057]\n",
      " [0.20499623]\n",
      " [0.34245962]\n",
      " ...\n",
      " [1.0032046 ]\n",
      " [1.1335933 ]\n",
      " [1.3844516 ]]\n",
      "0 2016-05-03 00:00:00\n",
      "[[0.91841936]\n",
      " [0.20406306]\n",
      " [0.32843688]\n",
      " ...\n",
      " [1.0087396 ]\n",
      " [1.1560497 ]\n",
      " [1.5010676 ]]\n",
      "0 2016-05-04 00:00:00\n",
      "[[0.8765639 ]\n",
      " [0.19688149]\n",
      " [0.3306992 ]\n",
      " ...\n",
      " [0.86596835]\n",
      " [1.0845377 ]\n",
      " [1.3075864 ]]\n",
      "0 2016-05-05 00:00:00\n",
      "[[0.86790526]\n",
      " [0.19043674]\n",
      " [0.30138314]\n",
      " ...\n",
      " [1.0137876 ]\n",
      " [1.2009513 ]\n",
      " [1.4185996 ]]\n",
      "0 2016-05-06 00:00:00\n",
      "[[0.90124154]\n",
      " [0.24832782]\n",
      " [0.45731756]\n",
      " ...\n",
      " [1.0793184 ]\n",
      " [1.2347244 ]\n",
      " [1.6871492 ]]\n",
      "0 2016-05-07 00:00:00\n",
      "[[1.211885  ]\n",
      " [0.32519996]\n",
      " [0.7255002 ]\n",
      " ...\n",
      " [1.1423368 ]\n",
      " [1.2425814 ]\n",
      " [1.7699836 ]]\n",
      "0 2016-05-08 00:00:00\n",
      "[[1.0006032 ]\n",
      " [0.21699272]\n",
      " [0.40260342]\n",
      " ...\n",
      " [1.1895021 ]\n",
      " [1.1067405 ]\n",
      " [1.6370658 ]]\n",
      "0 2016-05-09 00:00:00\n",
      "[[0.9018997 ]\n",
      " [0.19237159]\n",
      " [0.34123832]\n",
      " ...\n",
      " [1.3081057 ]\n",
      " [1.2378628 ]\n",
      " [1.5033977 ]]\n",
      "0 2016-05-10 00:00:00\n",
      "[[0.86357003]\n",
      " [0.18893552]\n",
      " [0.35538352]\n",
      " ...\n",
      " [0.9416636 ]\n",
      " [1.0694393 ]\n",
      " [1.3588175 ]]\n",
      "0 2016-05-11 00:00:00\n",
      "[[0.88134885]\n",
      " [0.17989331]\n",
      " [0.33964136]\n",
      " ...\n",
      " [1.0785762 ]\n",
      " [1.154732  ]\n",
      " [1.5052981 ]]\n",
      "0 2016-05-12 00:00:00\n",
      "[[0.88761365]\n",
      " [0.18506983]\n",
      " [0.3647915 ]\n",
      " ...\n",
      " [1.0913461 ]\n",
      " [1.1938896 ]\n",
      " [1.5343133 ]]\n",
      "0 2016-05-13 00:00:00\n",
      "[[0.99600613]\n",
      " [0.23819725]\n",
      " [0.5166456 ]\n",
      " ...\n",
      " [0.9846941 ]\n",
      " [1.0927825 ]\n",
      " [1.5545021 ]]\n",
      "0 2016-05-14 00:00:00\n",
      "[[1.2020569 ]\n",
      " [0.31044376]\n",
      " [0.71126735]\n",
      " ...\n",
      " [1.1925514 ]\n",
      " [1.2414175 ]\n",
      " [1.738774  ]]\n",
      "0 2016-05-15 00:00:00\n",
      "[[1.117969  ]\n",
      " [0.3049176 ]\n",
      " [0.62995136]\n",
      " ...\n",
      " [1.4075643 ]\n",
      " [1.3698448 ]\n",
      " [1.9138972 ]]\n",
      "0 2016-05-16 00:00:00\n",
      "[[0.88498485]\n",
      " [0.19619162]\n",
      " [0.40287513]\n",
      " ...\n",
      " [1.0469067 ]\n",
      " [1.1225985 ]\n",
      " [1.4334927 ]]\n",
      "0 2016-05-17 00:00:00\n",
      "[[0.84115005]\n",
      " [0.19469701]\n",
      " [0.3994255 ]\n",
      " ...\n",
      " [0.8768157 ]\n",
      " [1.0940403 ]\n",
      " [1.3674595 ]]\n",
      "0 2016-05-18 00:00:00\n",
      "[[0.83649623]\n",
      " [0.19902323]\n",
      " [0.3907612 ]\n",
      " ...\n",
      " [0.7719105 ]\n",
      " [1.1132452 ]\n",
      " [1.3052548 ]]\n",
      "0 2016-05-19 00:00:00\n",
      "[[0.8690858 ]\n",
      " [0.19249386]\n",
      " [0.39279756]\n",
      " ...\n",
      " [0.69513834]\n",
      " [1.0891868 ]\n",
      " [1.351737  ]]\n",
      "0 2016-05-20 00:00:00\n",
      "[[0.9329571 ]\n",
      " [0.2410229 ]\n",
      " [0.56658864]\n",
      " ...\n",
      " [0.69355726]\n",
      " [1.190035  ]\n",
      " [1.5114154 ]]\n",
      "0 2016-05-21 00:00:00\n",
      "[[1.161198  ]\n",
      " [0.3236268 ]\n",
      " [0.73558164]\n",
      " ...\n",
      " [0.8504989 ]\n",
      " [1.1956989 ]\n",
      " [1.6307139 ]]\n",
      "0 2016-05-22 00:00:00\n",
      "[[1.138579 ]\n",
      " [0.2960882]\n",
      " [0.6505539]\n",
      " ...\n",
      " [0.9426911]\n",
      " [1.2440141]\n",
      " [1.692536 ]]\n",
      "0 1.035 0.3333333333333333\n",
      "1 2016-04-25 00:00:00\n",
      "[[0.8589382 ]\n",
      " [0.18866026]\n",
      " [0.35150927]\n",
      " ...\n",
      " [0.7986913 ]\n",
      " [1.007365  ]\n",
      " [1.3013941 ]]\n",
      "1 2016-04-26 00:00:00\n",
      "[[0.81473863]\n",
      " [0.18118778]\n",
      " [0.3471179 ]\n",
      " ...\n",
      " [0.6098655 ]\n",
      " [0.9105312 ]\n",
      " [1.1371032 ]]\n",
      "1 2016-04-27 00:00:00\n",
      "[[0.8396036 ]\n",
      " [0.1937873 ]\n",
      " [0.36002284]\n",
      " ...\n",
      " [0.6243297 ]\n",
      " [0.9226215 ]\n",
      " [1.0865984 ]]\n",
      "1 2016-04-28 00:00:00\n",
      "[[0.90520823]\n",
      " [0.1828256 ]\n",
      " [0.3757764 ]\n",
      " ...\n",
      " [0.5800943 ]\n",
      " [0.8625253 ]\n",
      " [1.1791955 ]]\n",
      "1 2016-04-29 00:00:00\n",
      "[[0.97973776]\n",
      " [0.24200112]\n",
      " [0.5707165 ]\n",
      " ...\n",
      " [0.60721016]\n",
      " [1.0221559 ]\n",
      " [1.4550421 ]]\n",
      "1 2016-04-30 00:00:00\n",
      "[[1.2146274 ]\n",
      " [0.35675222]\n",
      " [0.5996195 ]\n",
      " ...\n",
      " [0.7959142 ]\n",
      " [1.0560411 ]\n",
      " [1.468049  ]]\n",
      "1 2016-05-01 00:00:00\n",
      "[[1.1688615 ]\n",
      " [0.3324589 ]\n",
      " [0.50982136]\n",
      " ...\n",
      " [0.98228085]\n",
      " [1.2533485 ]\n",
      " [1.3501978 ]]\n",
      "1 2016-05-02 00:00:00\n",
      "[[0.88242376]\n",
      " [0.20499402]\n",
      " [0.34242857]\n",
      " ...\n",
      " [1.0028797 ]\n",
      " [1.1333971 ]\n",
      " [1.3836358 ]]\n",
      "1 2016-05-03 00:00:00\n",
      "[[0.9182626 ]\n",
      " [0.20404814]\n",
      " [0.3283673 ]\n",
      " ...\n",
      " [1.0083653 ]\n",
      " [1.1557198 ]\n",
      " [1.5001293 ]]\n",
      "1 2016-05-04 00:00:00\n",
      "[[0.8763183 ]\n",
      " [0.19685826]\n",
      " [0.3305608 ]\n",
      " ...\n",
      " [0.8654256 ]\n",
      " [1.0841641 ]\n",
      " [1.3067987 ]]\n",
      "1 2016-05-05 00:00:00\n",
      "[[0.8675336 ]\n",
      " [0.19043536]\n",
      " [0.301256  ]\n",
      " ...\n",
      " [1.0131286 ]\n",
      " [1.2003169 ]\n",
      " [1.4174491 ]]\n",
      "1 2016-05-06 00:00:00\n",
      "[[0.90077305]\n",
      " [0.24830759]\n",
      " [0.45702034]\n",
      " ...\n",
      " [1.0784869 ]\n",
      " [1.2340308 ]\n",
      " [1.6852995 ]]\n",
      "1 2016-05-07 00:00:00\n",
      "[[1.2109709]\n",
      " [0.3250856]\n",
      " [0.7246717]\n",
      " ...\n",
      " [1.1413242]\n",
      " [1.2416103]\n",
      " [1.7677258]]\n",
      "1 2016-05-08 00:00:00\n",
      "[[0.9997792 ]\n",
      " [0.21692497]\n",
      " [0.4023405 ]\n",
      " ...\n",
      " [1.1883209 ]\n",
      " [1.105671  ]\n",
      " [1.6343588 ]]\n",
      "1 2016-05-09 00:00:00\n",
      "[[0.9012644]\n",
      " [0.1923103]\n",
      " [0.3409453]\n",
      " ...\n",
      " [1.3063353]\n",
      " [1.2363371]\n",
      " [1.5009146]]\n",
      "1 2016-05-10 00:00:00\n",
      "[[0.8627727 ]\n",
      " [0.18887115]\n",
      " [0.35505873]\n",
      " ...\n",
      " [0.9405339 ]\n",
      " [1.0682739 ]\n",
      " [1.3563572 ]]\n",
      "1 2016-05-11 00:00:00\n",
      "[[0.88047117]\n",
      " [0.17979395]\n",
      " [0.33919913]\n",
      " ...\n",
      " [1.0769864 ]\n",
      " [1.1531515 ]\n",
      " [1.5025836 ]]\n",
      "1 2016-05-12 00:00:00\n",
      "[[0.8866502 ]\n",
      " [0.18496338]\n",
      " [0.36427552]\n",
      " ...\n",
      " [1.0894675 ]\n",
      " [1.192199  ]\n",
      " [1.5314592 ]]\n",
      "1 2016-05-13 00:00:00\n",
      "[[0.9949243 ]\n",
      " [0.23802488]\n",
      " [0.51597   ]\n",
      " ...\n",
      " [0.98334694]\n",
      " [1.0910051 ]\n",
      " [1.5510763 ]]\n",
      "1 2016-05-14 00:00:00\n",
      "[[1.2005119 ]\n",
      " [0.31021616]\n",
      " [0.7098243 ]\n",
      " ...\n",
      " [1.1899104 ]\n",
      " [1.2388953 ]\n",
      " [1.7345414 ]]\n",
      "1 2016-05-15 00:00:00\n",
      "[[1.1164533 ]\n",
      " [0.30467224]\n",
      " [0.6288593 ]\n",
      " ...\n",
      " [1.4045857 ]\n",
      " [1.3669149 ]\n",
      " [1.9085921 ]]\n",
      "1 2016-05-16 00:00:00\n",
      "[[0.8836746 ]\n",
      " [0.19600579]\n",
      " [0.40204996]\n",
      " ...\n",
      " [1.0447552 ]\n",
      " [1.1201429 ]\n",
      " [1.4301189 ]]\n",
      "1 2016-05-17 00:00:00\n",
      "[[0.839581  ]\n",
      " [0.19450778]\n",
      " [0.39855018]\n",
      " ...\n",
      " [0.8743508 ]\n",
      " [1.0915959 ]\n",
      " [1.3644025 ]]\n",
      "1 2016-05-18 00:00:00\n",
      "[[0.83477366]\n",
      " [0.19882464]\n",
      " [0.3898136 ]\n",
      " ...\n",
      " [0.7694918 ]\n",
      " [1.1107231 ]\n",
      " [1.3021134 ]]\n",
      "1 2016-05-19 00:00:00\n",
      "[[0.86721873]\n",
      " [0.19230783]\n",
      " [0.39181378]\n",
      " ...\n",
      " [0.6932564 ]\n",
      " [1.0864358 ]\n",
      " [1.3482069 ]]\n",
      "1 2016-05-20 00:00:00\n",
      "[[0.93103576]\n",
      " [0.24076284]\n",
      " [0.56516266]\n",
      " ...\n",
      " [0.6916045 ]\n",
      " [1.1868942 ]\n",
      " [1.5071473 ]]\n",
      "1 2016-05-21 00:00:00\n",
      "[[1.1582655 ]\n",
      " [0.32314676]\n",
      " [0.73384047]\n",
      " ...\n",
      " [0.8482692 ]\n",
      " [1.1919814 ]\n",
      " [1.6255542 ]]\n",
      "1 2016-05-22 00:00:00\n",
      "[[1.1357027]\n",
      " [0.2956493]\n",
      " [0.6488817]\n",
      " ...\n",
      " [0.9394133]\n",
      " [1.2400905]\n",
      " [1.6865888]]\n",
      "1 1.03 0.3333333333333333\n",
      "2 2016-04-25 00:00:00\n",
      "[[0.8589382 ]\n",
      " [0.18866026]\n",
      " [0.35150927]\n",
      " ...\n",
      " [0.7986913 ]\n",
      " [1.007365  ]\n",
      " [1.3013941 ]]\n",
      "2 2016-04-26 00:00:00\n",
      "[[0.81473863]\n",
      " [0.18118778]\n",
      " [0.3471179 ]\n",
      " ...\n",
      " [0.6098655 ]\n",
      " [0.9105312 ]\n",
      " [1.1371032 ]]\n",
      "2 2016-04-27 00:00:00\n",
      "[[0.8396036 ]\n",
      " [0.1937873 ]\n",
      " [0.36002284]\n",
      " ...\n",
      " [0.6243297 ]\n",
      " [0.9226215 ]\n",
      " [1.0865984 ]]\n",
      "2 2016-04-28 00:00:00\n",
      "[[0.90520823]\n",
      " [0.1828256 ]\n",
      " [0.3757764 ]\n",
      " ...\n",
      " [0.5800943 ]\n",
      " [0.8625253 ]\n",
      " [1.1791955 ]]\n",
      "2 2016-04-29 00:00:00\n",
      "[[0.97973776]\n",
      " [0.24200112]\n",
      " [0.5707165 ]\n",
      " ...\n",
      " [0.60721016]\n",
      " [1.0221559 ]\n",
      " [1.4550421 ]]\n",
      "2 2016-04-30 00:00:00\n",
      "[[1.2146274 ]\n",
      " [0.35675222]\n",
      " [0.5996195 ]\n",
      " ...\n",
      " [0.7959142 ]\n",
      " [1.0560411 ]\n",
      " [1.468049  ]]\n",
      "2 2016-05-01 00:00:00\n",
      "[[1.1688615 ]\n",
      " [0.3324589 ]\n",
      " [0.50982136]\n",
      " ...\n",
      " [0.98228085]\n",
      " [1.2533485 ]\n",
      " [1.3501978 ]]\n",
      "2 2016-05-02 00:00:00\n",
      "[[0.8823168 ]\n",
      " [0.20499182]\n",
      " [0.34239748]\n",
      " ...\n",
      " [1.0025553 ]\n",
      " [1.1332009 ]\n",
      " [1.3828173 ]]\n",
      "2 2016-05-03 00:00:00\n",
      "[[0.9181057 ]\n",
      " [0.2040332 ]\n",
      " [0.32829773]\n",
      " ...\n",
      " [1.0079911 ]\n",
      " [1.1553905 ]\n",
      " [1.4991918 ]]\n",
      "2 2016-05-04 00:00:00\n",
      "[[0.876073  ]\n",
      " [0.19683483]\n",
      " [0.33042225]\n",
      " ...\n",
      " [0.8648817 ]\n",
      " [1.0837902 ]\n",
      " [1.3060085 ]]\n",
      "2 2016-05-05 00:00:00\n",
      "[[0.86716175]\n",
      " [0.1904341 ]\n",
      " [0.30112872]\n",
      " ...\n",
      " [1.012471  ]\n",
      " [1.1996851 ]\n",
      " [1.4162967 ]]\n",
      "2 2016-05-06 00:00:00\n",
      "[[0.9003041 ]\n",
      " [0.24828734]\n",
      " [0.456722  ]\n",
      " ...\n",
      " [1.0776585 ]\n",
      " [1.2333368 ]\n",
      " [1.6834614 ]]\n",
      "2 2016-05-07 00:00:00\n",
      "[[1.2100601]\n",
      " [0.3249714]\n",
      " [0.7238444]\n",
      " ...\n",
      " [1.1403066]\n",
      " [1.2406399]\n",
      " [1.7654747]]\n",
      "2 2016-05-08 00:00:00\n",
      "[[0.99895227]\n",
      " [0.21685734]\n",
      " [0.40207765]\n",
      " ...\n",
      " [1.187138  ]\n",
      " [1.104597  ]\n",
      " [1.6316541 ]]\n",
      "2 2016-05-09 00:00:00\n",
      "[[0.90062904]\n",
      " [0.192249  ]\n",
      " [0.3406516 ]\n",
      " ...\n",
      " [1.3045614 ]\n",
      " [1.2348171 ]\n",
      " [1.4984294 ]]\n",
      "2 2016-05-10 00:00:00\n",
      "[[0.8619778 ]\n",
      " [0.18880689]\n",
      " [0.3547342 ]\n",
      " ...\n",
      " [0.93941987]\n",
      " [1.0671191 ]\n",
      " [1.3538955 ]]\n",
      "2 2016-05-11 00:00:00\n",
      "[[0.8795942 ]\n",
      " [0.17969391]\n",
      " [0.33875215]\n",
      " ...\n",
      " [1.0754062 ]\n",
      " [1.1515701 ]\n",
      " [1.499869  ]]\n",
      "2 2016-05-12 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8856878 ]\n",
      " [0.18485689]\n",
      " [0.3637594 ]\n",
      " ...\n",
      " [1.0875978 ]\n",
      " [1.1905087 ]\n",
      " [1.5286021 ]]\n",
      "2 2016-05-13 00:00:00\n",
      "[[0.99385166]\n",
      " [0.23785351]\n",
      " [0.5152955 ]\n",
      " ...\n",
      " [0.9819957 ]\n",
      " [1.0892164 ]\n",
      " [1.5476519 ]]\n",
      "2 2016-05-14 00:00:00\n",
      "[[1.1989781 ]\n",
      " [0.3099891 ]\n",
      " [0.70839274]\n",
      " ...\n",
      " [1.1872687 ]\n",
      " [1.2363743 ]\n",
      " [1.7303051 ]]\n",
      "2 2016-05-15 00:00:00\n",
      "[[1.1149414 ]\n",
      " [0.30442816]\n",
      " [0.62777114]\n",
      " ...\n",
      " [1.4016119 ]\n",
      " [1.3639811 ]\n",
      " [1.9032809 ]]\n",
      "2 2016-05-16 00:00:00\n",
      "[[0.8823774 ]\n",
      " [0.19582035]\n",
      " [0.40121868]\n",
      " ...\n",
      " [1.0426005 ]\n",
      " [1.117715  ]\n",
      " [1.4267297 ]]\n",
      "2 2016-05-17 00:00:00\n",
      "[[0.8380208 ]\n",
      " [0.19431876]\n",
      " [0.3976656 ]\n",
      " ...\n",
      " [0.8719076 ]\n",
      " [1.0891507 ]\n",
      " [1.361322  ]]\n",
      "2 2016-05-18 00:00:00\n",
      "[[0.83306783]\n",
      " [0.19862802]\n",
      " [0.3888695 ]\n",
      " ...\n",
      " [0.7671554 ]\n",
      " [1.108207  ]\n",
      " [1.2989433 ]]\n",
      "2 2016-05-19 00:00:00\n",
      "[[0.86536014]\n",
      " [0.19212309]\n",
      " [0.39083302]\n",
      " ...\n",
      " [0.69140255]\n",
      " [1.0836878 ]\n",
      " [1.3446552 ]]\n",
      "2 2016-05-20 00:00:00\n",
      "[[0.9291142 ]\n",
      " [0.24050309]\n",
      " [0.56374884]\n",
      " ...\n",
      " [0.6896579 ]\n",
      " [1.1837394 ]\n",
      " [1.5028677 ]]\n",
      "2 2016-05-21 00:00:00\n",
      "[[1.1553266 ]\n",
      " [0.32267082]\n",
      " [0.732106  ]\n",
      " ...\n",
      " [0.84604555]\n",
      " [1.1882838 ]\n",
      " [1.6203648 ]]\n",
      "2 2016-05-22 00:00:00\n",
      "[[1.1328512 ]\n",
      " [0.2952118 ]\n",
      " [0.64719427]\n",
      " ...\n",
      " [0.93613577]\n",
      " [1.2361578 ]\n",
      " [1.6806252 ]]\n",
      "2 1.025 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta \n",
    "alphas = [1.035, 1.03, 1.025]\n",
    "weights = [1/len(alphas)]*len(alphas)\n",
    "sub = 0.\n",
    "\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "\n",
    "    te = create_dt(False)\n",
    "    cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "    for tdelta in range(0, 28):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(icount, day)\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "        create_fea(tst)\n",
    "        tst = tst.loc[tst.date == day , train_cols]\n",
    "        input_dict_predict = {f\"input_{col}\": tst[col] for col in tst.columns}\n",
    "        pred = mdl.predict(input_dict_predict,batch_size=10000)\n",
    "        te.loc[te.date == day, \"sales\"] = alpha*pred\n",
    "        print(pred)\n",
    "\n",
    "\n",
    "\n",
    "    te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "#     te_sub.loc[te.date >= fday+ timedelta(days=h), \"id\"] = te_sub.loc[te.date >= fday+timedelta(days=h), \n",
    "#                                                                           \"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "    te_sub.fillna(0., inplace = True)\n",
    "    te_sub.sort_values(\"id\", inplace = True)\n",
    "    te_sub.reset_index(drop=True, inplace = True)\n",
    "    te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n",
    "    if icount == 0 :\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight\n",
    "    print(icount, alpha, weight)\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission_tf_stable.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # submit using the tensorflow model \n",
    "\n",
    "# alphas = [1.035, 1.03, 1.025]\n",
    "# weights = [1/len(alphas)]*len(alphas)\n",
    "# sub = 0.\n",
    "\n",
    "# for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "\n",
    "#     te = create_dt(False)\n",
    "#     cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "#     for tdelta in range(0, 28):\n",
    "#         day = fday + timedelta(days=tdelta)\n",
    "#         print(icount, day)\n",
    "#         tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "#         create_fea(tst)\n",
    "#         tst = tst.loc[tst.date == day , train_cols]\n",
    "#         input_dict_predict = {f\"input_{col}\": tst[col] for col in tst.columns}\n",
    "#         te.loc[te.date == day, \"sales\"] = alpha*mdl.predict(input_dict_predict,batch_size=10000) # magic multiplier by kyakovlev\n",
    "\n",
    "#     te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "#     te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "#     te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "#     te_sub.fillna(0., inplace = True)\n",
    "#     te_sub.sort_values(\"id\", inplace = True)\n",
    "#     te_sub.reset_index(drop=True, inplace = True)\n",
    "#     te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n",
    "#     if icount == 0 :\n",
    "#         sub = te_sub\n",
    "#         sub[cols] *= weight\n",
    "#     else:\n",
    "#         sub[cols] += te_sub[cols]*weight\n",
    "#     print(icount, alpha, weight)\n",
    "\n",
    "# sub2 = sub.copy()\n",
    "# sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "# sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "# sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
