{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('./tf_pipeline/')\n",
    "\n",
    "from tf_pipeline.tf_utils import create_mlp_softmax\n",
    "\n",
    "from tf_pipeline.conf import *\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def create_dt(horizon=\"validation\", tr_last=1913):\n",
    "    prices = pd.read_csv(os.path.join(RAW_PATH, \"sell_prices.csv\"), dtype=PRICE_DTYPES)\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col] -= prices[col].min()\n",
    "\n",
    "    cal = pd.read_csv(os.path.join(RAW_PATH, \"calendar.csv\"), dtype=CAL_DTYPES)\n",
    "    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col] -= cal[col].min()\n",
    "\n",
    "    numcols = [f\"d_{day}\" for day in range(1, tr_last + 1)]\n",
    "    catcols = [\"id\", \"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n",
    "    dtype = {numcol: \"float32\" for numcol in numcols}\n",
    "    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "    dt = pd.read_csv(\n",
    "        os.path.join(RAW_PATH, \"sales_train_%s.csv\" % horizon),\n",
    "        usecols=catcols + numcols,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "\n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            dt[col] = dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col] -= dt[col].min()\n",
    "\n",
    "    increasing_term = dt.groupby([\"dept_id\", \"store_id\"])[numcols].sum()\n",
    "    increasing_term = (\n",
    "                              increasing_term.T - increasing_term.T.shift(28)\n",
    "                      ) / increasing_term.T.shift(28)\n",
    "    increasing_term = increasing_term.reset_index(drop=True).iloc[-365:, :]\n",
    "    rates = increasing_term[increasing_term.abs() < 1].mean() + 1\n",
    "    rates = rates.reset_index().rename(columns={0: \"rate\"})\n",
    "\n",
    "    for day in range(tr_last + 1, tr_last + 2 * 28 + 1):\n",
    "        dt[f\"d_{day}\"] = np.nan\n",
    "\n",
    "    dt = pd.melt(\n",
    "        dt,\n",
    "        id_vars=catcols,\n",
    "        value_vars=[col for col in dt.columns if col.startswith(\"d_\")],\n",
    "        var_name=\"d\",\n",
    "        value_name=\"sales\",\n",
    "    )\n",
    "\n",
    "    dt = dt.merge(cal, on=\"d\", copy=False)\n",
    "    dt = dt.merge(prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], copy=False)\n",
    "    dt = dt.merge(rates, how=\"left\")\n",
    "\n",
    "    return dt\n",
    "\n",
    "def compute_share(dt):\n",
    "    shares = (\n",
    "        dt.groupby([\"dept_id\", \"store_id\", \"date\"])[\"sales\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"sales\": \"gp_sales\"})\n",
    "    )\n",
    "    dt = dt.merge(shares, how=\"left\")\n",
    "    dt[\"sales\"] = dt[\"sales\"] / dt[\"gp_sales\"]\n",
    "    dt.drop([\"gp_sales\"], axis=1, inplace=True)\n",
    "    return dt\n",
    "\n",
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\", \"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = (\n",
    "                dt[[\"id\", lag_col]]\n",
    "                    .groupby(\"id\")[lag_col]\n",
    "                    .transform(lambda x: x.rolling(win).mean())\n",
    "            )\n",
    "\n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "    }\n",
    "\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
    "    return dt\n",
    "\n",
    "def train_and_pred(horizon=\"validation\"):\n",
    "\n",
    "    if horizon==\"validation\":\n",
    "        tr_last = 1913\n",
    "        fday = datetime(2016, 4, 25)\n",
    "    elif horizon==\"evaluation\":\n",
    "        tr_last = 1941\n",
    "        fday = datetime(2016, 4, 25) + timedelta(days=28)\n",
    "    else:\n",
    "        raise ValueError('Wrong horizon arg.')\n",
    "\n",
    "    dataframe = create_dt(horizon, tr_last)\n",
    "    dataframe = compute_share(dataframe)\n",
    "    dataframe = create_fea(dataframe)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    \n",
    "\n",
    "    list_preds = list()\n",
    "\n",
    "    for _, df_gp in dataframe.groupby(['store_id', 'dept_id']):\n",
    "\n",
    "        cat_feats = ['wday', 'quarter']\n",
    "\n",
    "        n_items = len(df_gp['item_id'].drop_duplicates())    \n",
    "\n",
    "        ids = df_gp[['id', 'item_id']].drop_duplicates()\\\n",
    "                                      .sort_values('item_id')['id']\\\n",
    "                                      .tolist()\n",
    "        X = df_gp[\n",
    "            ['d', 'item_id', 'wday', 'quarter', 'date', 'rmean_28_28', 'sales']\n",
    "        ].pivot_table(index=['d', 'date', 'wday', 'quarter'],\n",
    "                      columns=['item_id'],\n",
    "                      values=['rmean_28_28', 'sales']).fillna(0)\n",
    "\n",
    "        num_feats = ['_'.join(list(map(str, c))) for c in X.columns.tolist()]\n",
    "        X.columns = num_feats\n",
    "\n",
    "        target_feats = num_feats[n_items:]\n",
    "        num_feats = num_feats[:n_items]\n",
    "        X = X.reset_index()\n",
    "\n",
    "        X_train = X[X['date']<fday][num_feats+cat_feats]\n",
    "        X_test = X[X['date']>=fday][num_feats+cat_feats]\n",
    "\n",
    "        input_dict_train = {'input_%s' % c: X_train[c] for c in num_feats+cat_feats}\n",
    "        input_dict_test = {'input_%s' % c: X_test[c] for c in num_feats+cat_feats}\n",
    "\n",
    "        cardinality = X[cat_feats].nunique()\n",
    "\n",
    "        y_train = X[X['date']<fday][target_feats].values\n",
    "\n",
    "        mlp = create_mlp_softmax(layers_list=[2048, 2048],\n",
    "                                 output_count=n_items,\n",
    "                                 cat_feats=cat_feats,\n",
    "                                 cardinality=cardinality,\n",
    "                                 num_feats=num_feats)\n",
    "\n",
    "\n",
    "\n",
    "        training_params = {\n",
    "                    'x': input_dict_train,\n",
    "                    'y': y_train,\n",
    "                    'batch_size': 128,\n",
    "                    'epochs': 20,\n",
    "                    'shuffle': True,\n",
    "                }\n",
    "\n",
    "        mlp.fit(**training_params)\n",
    "        preds = mlp.predict(input_dict_test)\n",
    "        preds = pd.DataFrame(preds,\n",
    "                             index=['F%s' % c for c in range(1,29)],\n",
    "                             columns=ids).T\n",
    "        list_preds.append(preds)\n",
    "\n",
    "    preds = pd.concat(list_preds)\n",
    "    preds = preds.reset_index()\n",
    "    preds.columns = ['id'] + preds.columns.tolist()[1:]\n",
    "    \n",
    "    preds.to_csv(\n",
    "            os.path.join(EXTERNAL_PATH, \"tf_weights_%s.csv\" % horizon), index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for horizon in ['validation', 'evaluation']:\n",
    "    if horizon==\"validation\":\n",
    "        tr_last = 1913\n",
    "        fday = datetime(2016, 4, 25)\n",
    "    elif horizon==\"evaluation\":\n",
    "        tr_last = 1941\n",
    "        fday = datetime(2016, 4, 25) + timedelta(days=28)\n",
    "    else:\n",
    "        raise ValueError('Wrong horizon arg.')\n",
    "\n",
    "    dataframe = create_dt(horizon, tr_last)\n",
    "    dataframe = compute_share(dataframe)\n",
    "    dataframe = create_fea(dataframe)\n",
    "\n",
    "    list_preds = list()\n",
    "\n",
    "    for _, df_gp in dataframe.groupby(['store_id', 'dept_id']):\n",
    "\n",
    "        cat_feats = ['wday', 'quarter']\n",
    "\n",
    "        n_items = len(df_gp['item_id'].drop_duplicates())    \n",
    "\n",
    "        ids = df_gp[['id', 'item_id']].drop_duplicates()\\\n",
    "                                      .sort_values('item_id')['id']\\\n",
    "                                      .tolist()\n",
    "        X = df_gp[\n",
    "            ['d', 'item_id', 'wday', 'quarter', 'date', 'rmean_28_28', 'sales']\n",
    "        ].pivot_table(index=['d', 'date', 'wday', 'quarter'],\n",
    "                      columns=['item_id'],\n",
    "                      values=['rmean_28_28', 'sales']).fillna(0)\n",
    "\n",
    "        num_feats = ['_'.join(list(map(str, c))) for c in X.columns.tolist()]\n",
    "        X.columns = num_feats\n",
    "\n",
    "        target_feats = num_feats[n_items:]\n",
    "        num_feats = num_feats[:n_items]\n",
    "        X = X.reset_index()\n",
    "\n",
    "        X_train = X[X['date']<fday][num_feats+cat_feats]\n",
    "        X_test = X[X['date']>=fday][num_feats+cat_feats]\n",
    "\n",
    "        input_dict_train = {'input_%s' % c: X_train[c] for c in num_feats+cat_feats}\n",
    "        input_dict_test = {'input_%s' % c: X_test[c] for c in num_feats+cat_feats}\n",
    "\n",
    "        cardinality = X[cat_feats].nunique()\n",
    "\n",
    "        y_train = X[X['date']<fday][target_feats].values\n",
    "\n",
    "        mlp = create_mlp_softmax(layers_list=[2048, 2048],\n",
    "                                 output_count=n_items,\n",
    "                                 cat_feats=cat_feats,\n",
    "                                 cardinality=cardinality,\n",
    "                                 num_feats=num_feats)\n",
    "\n",
    "\n",
    "\n",
    "        training_params = {\n",
    "                    'x': input_dict_train,\n",
    "                    'y': y_train,\n",
    "                    'batch_size': 128,\n",
    "                    'epochs': 15,\n",
    "                    'shuffle': True,\n",
    "                }\n",
    "\n",
    "        mlp.fit(**training_params)\n",
    "        preds = mlp.predict(input_dict_test)\n",
    "        preds = pd.DataFrame(preds,\n",
    "                             index=['F%s' % c for c in range(1,29)],\n",
    "                             columns=ids).T\n",
    "        list_preds.append(preds)\n",
    "\n",
    "    preds = pd.concat(list_preds)\n",
    "    preds = pd.concat(list_preds)\n",
    "    preds = preds.reset_index()\n",
    "    preds.columns = ['id'] + preds.columns.tolist()[1:]\n",
    "\n",
    "    preds.to_csv(\n",
    "            os.path.join(EXTERNAL_PATH, \"tf_weights_%s.csv\" % horizon), index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
