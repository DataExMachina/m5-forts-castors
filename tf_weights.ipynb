{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('./tf_pipeline/')\n",
    "\n",
    "from tf_pipeline.tf_utils import create_mlp_softmax\n",
    "\n",
    "from tf_pipeline.conf import *\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np \n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "\n",
    "def create_dt(horizon=\"validation\", tr_last=1913):\n",
    "    prices = pd.read_csv(os.path.join(RAW_PATH, \"sell_prices.csv\"), dtype=PRICE_DTYPES)\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col] -= prices[col].min()\n",
    "\n",
    "    cal = pd.read_csv(os.path.join(RAW_PATH, \"calendar.csv\"), dtype=CAL_DTYPES)\n",
    "    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col] -= cal[col].min()\n",
    "\n",
    "    numcols = [f\"d_{day}\" for day in range(1, tr_last + 1)]\n",
    "    catcols = [\"id\", \"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n",
    "    dtype = {numcol: \"float32\" for numcol in numcols}\n",
    "    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "    dt = pd.read_csv(\n",
    "        os.path.join(RAW_PATH, \"sales_train_%s.csv\" % horizon),\n",
    "        usecols=catcols + numcols,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "\n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            dt[col] = dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col] -= dt[col].min()\n",
    "\n",
    "    increasing_term = dt.groupby([\"dept_id\", \"store_id\"])[numcols].sum()\n",
    "    increasing_term = (\n",
    "                              increasing_term.T - increasing_term.T.shift(28)\n",
    "                      ) / increasing_term.T.shift(28)\n",
    "    increasing_term = increasing_term.reset_index(drop=True).iloc[-365:, :]\n",
    "    rates = increasing_term[increasing_term.abs() < 1].mean() + 1\n",
    "    rates = rates.reset_index().rename(columns={0: \"rate\"})\n",
    "\n",
    "    for day in range(tr_last + 1, tr_last + 2 * 28 + 1):\n",
    "        dt[f\"d_{day}\"] = np.nan\n",
    "\n",
    "    dt = pd.melt(\n",
    "        dt,\n",
    "        id_vars=catcols,\n",
    "        value_vars=[col for col in dt.columns if col.startswith(\"d_\")],\n",
    "        var_name=\"d\",\n",
    "        value_name=\"sales\",\n",
    "    )\n",
    "\n",
    "    dt = dt.merge(cal, on=\"d\", copy=False)\n",
    "    dt = dt.merge(prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], copy=False)\n",
    "    dt = dt.merge(rates, how=\"left\")\n",
    "\n",
    "    return dt\n",
    "\n",
    "def compute_share(dt):\n",
    "    shares = (\n",
    "        dt.groupby([\"dept_id\", \"store_id\", \"date\"])[\"sales\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"sales\": \"gp_sales\"})\n",
    "    )\n",
    "    dt = dt.merge(shares, how=\"left\")\n",
    "    dt[\"sales\"] = dt[\"sales\"] / dt[\"gp_sales\"]\n",
    "    dt.drop([\"gp_sales\"], axis=1, inplace=True)\n",
    "    return dt\n",
    "\n",
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\", \"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = (\n",
    "                dt[[\"id\", lag_col]]\n",
    "                    .groupby(\"id\")[lag_col]\n",
    "                    .transform(lambda x: x.rolling(win).mean())\n",
    "            )\n",
    "\n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "    }\n",
    "\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'd',\n",
      "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
      "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
      "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'rate'],\n",
      "      dtype='object')\n",
      "Index(['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'd',\n",
      "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
      "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
      "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'rate'],\n",
      "      dtype='object')\n",
      "Index(['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'd',\n",
      "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
      "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
      "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'rate', 'lag_7',\n",
      "       'lag_28', 'rmean_7_7', 'rmean_28_7', 'rmean_7_28', 'rmean_28_28',\n",
      "       'week', 'quarter', 'mday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "horizon=\"validation\"\n",
    "\n",
    "if horizon==\"validation\":\n",
    "    tr_last = 1913\n",
    "    fday = datetime(2016, 4, 25)\n",
    "elif horizon==\"evaluation\":\n",
    "    tr_last = 1941\n",
    "    fday = datetime(2016, 4, 25) + timedelta(days=28)\n",
    "else:\n",
    "    raise ValueError('Wrong horizon arg.')\n",
    "\n",
    "dataframe = create_dt(horizon, tr_last)\n",
    "print(dataframe.columns)\n",
    "dataframe = compute_share(dataframe)\n",
    "print(dataframe.columns)\n",
    "\n",
    "dataframe = create_fea(dataframe)\n",
    "print(dataframe.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>rate</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47735392</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>3046</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47735393</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>3047</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>11621</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47735394</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>3047</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47735395</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>3048</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>11621</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47735396</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>3048</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47735397 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  item_id  dept_id  store_id  cat_id  \\\n",
       "0         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "1         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "2         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "3         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "4         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "...                                 ...      ...      ...       ...     ...   \n",
       "47735392    FOODS_3_825_WI_3_validation     3046        6         9       2   \n",
       "47735393    FOODS_3_826_WI_3_validation     3047        6         9       2   \n",
       "47735394    FOODS_3_826_WI_3_validation     3047        6         9       2   \n",
       "47735395    FOODS_3_827_WI_3_validation     3048        6         9       2   \n",
       "47735396    FOODS_3_827_WI_3_validation     3048        6         9       2   \n",
       "\n",
       "          state_id       d     sales       date  wm_yr_wk  ...      rate  \\\n",
       "0                0     d_1  0.022727 2011-01-29     11101  ...  1.020196   \n",
       "1                0     d_2  0.030675 2011-01-30     11101  ...  1.020196   \n",
       "2                0     d_3  0.000000 2011-01-31     11101  ...  1.020196   \n",
       "3                0     d_4  0.000000 2011-02-01     11101  ...  1.020196   \n",
       "4                0     d_5  0.000000 2011-02-02     11101  ...  1.020196   \n",
       "...            ...     ...       ...        ...       ...  ...       ...   \n",
       "47735392         2  d_1969       NaN 2016-06-19     11621  ...  1.033772   \n",
       "47735393         2  d_1968       NaN 2016-06-18     11621  ...  1.033772   \n",
       "47735394         2  d_1969       NaN 2016-06-19     11621  ...  1.033772   \n",
       "47735395         2  d_1968       NaN 2016-06-18     11621  ...  1.033772   \n",
       "47735396         2  d_1969       NaN 2016-06-19     11621  ...  1.033772   \n",
       "\n",
       "          lag_7  lag_28  rmean_7_7  rmean_28_7  rmean_7_28  rmean_28_28  week  \\\n",
       "0           NaN     NaN        NaN         NaN         NaN          NaN     4   \n",
       "1           NaN     NaN        NaN         NaN         NaN          NaN     4   \n",
       "2           NaN     NaN        NaN         NaN         NaN          NaN     5   \n",
       "3           NaN     NaN        NaN         NaN         NaN          NaN     5   \n",
       "4           NaN     NaN        NaN         NaN         NaN          NaN     5   \n",
       "...         ...     ...        ...         ...         ...          ...   ...   \n",
       "47735392    NaN     NaN        NaN         NaN         NaN          NaN    24   \n",
       "47735393    NaN     NaN        NaN         NaN         NaN          NaN    24   \n",
       "47735394    NaN     NaN        NaN         NaN         NaN          NaN    24   \n",
       "47735395    NaN     NaN        NaN         NaN         NaN          NaN    24   \n",
       "47735396    NaN     NaN        NaN         NaN         NaN          NaN    24   \n",
       "\n",
       "          quarter  mday  \n",
       "0               1    29  \n",
       "1               1    30  \n",
       "2               1    31  \n",
       "3               1     1  \n",
       "4               1     2  \n",
       "...           ...   ...  \n",
       "47735392        2    19  \n",
       "47735393        2    18  \n",
       "47735394        2    19  \n",
       "47735395        2    18  \n",
       "47735396        2    19  \n",
       "\n",
       "[47735397 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tfk \n",
    "class CustomCallback(tfk.callbacks.Callback):\n",
    "    def __init__(self, print_n_epochs=10):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.print_n_epochs = print_n_epochs\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch%self.print_n_epochs==0:\n",
    "            try:\n",
    "                print(f\"E: {epoch} loss : {logs['loss']:.2f}, vrmse :{logs['val_root_mean_squared_error']:.2f}\")\n",
    "            except:\n",
    "                print(f\"E: {epoch} loss : {logs['loss']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████▊                                   | 38/70 [1:01:01<50:59, 95.60s/it]"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import warnings\n",
    "list_preds = list()\n",
    "gc.collect()\n",
    "warnings.filterwarnings('ignore')  # TF casse les ******\n",
    "from tqdm import tqdm\n",
    "\n",
    "for _, df_gp in tqdm(dataframe.groupby(['store_id', 'dept_id']),total=70):\n",
    "\n",
    "    cat_feats = ['wday',\n",
    "                 'quarter',\n",
    "                 \"event_name_1\",\n",
    "                 \"event_name_2\",\n",
    "                 \"event_type_1\",\n",
    "                 \"event_type_2\",\n",
    "                 ]\n",
    "\n",
    "    n_items = len(df_gp['item_id'].drop_duplicates())\n",
    "    #print(f'{n_items} in the hierachie')\n",
    "\n",
    "    ids = df_gp[['id', 'item_id']].drop_duplicates()\\\n",
    "                                  .sort_values('item_id')['id']\\\n",
    "                                  .tolist()\n",
    "    X = df_gp[\n",
    "        ['d',\n",
    "         'item_id',\n",
    "         'date',\n",
    "         'rmean_28_28',\n",
    "         'sales']+cat_feats].pivot_table(index=['d', 'date']+cat_feats,\n",
    "                  columns=['item_id'],\n",
    "                  values=['rmean_28_28', 'sales']).fillna(0)\n",
    "\n",
    "    num_feats = ['_'.join(list(map(str, c))) for c in X.columns.tolist()]\n",
    "    X.columns = num_feats\n",
    "\n",
    "    target_feats = num_feats[n_items:]\n",
    "    num_feats = num_feats[:n_items]\n",
    "    X = X.reset_index()\n",
    "\n",
    "    X_train = X[(X['date'] < fday) & (X['date'] >= fday -\n",
    "                                      timedelta(days=364))][num_feats+cat_feats]\n",
    "    X_test = X[X['date'] >= fday][num_feats+cat_feats]\n",
    "\n",
    "    input_dict_train = {'input_%s' %\n",
    "                        c: X_train[c] for c in num_feats+cat_feats}\n",
    "    input_dict_test = {'input_%s' % c: X_test[c] for c in num_feats+cat_feats}\n",
    "\n",
    "    cardinality = X[cat_feats].nunique()\n",
    "\n",
    "    y_train = X[(X['date'] < fday) & (X['date'] >= fday -\n",
    "                                      timedelta(days=364))][target_feats].values\n",
    "\n",
    "    mlp = create_mlp_softmax(layers_list=[32, 64, ],\n",
    "                             emb_dim=1,\n",
    "                             output_count=n_items,\n",
    "                             cat_feats=cat_feats,\n",
    "                             cardinality=cardinality,\n",
    "                             num_feats=num_feats)\n",
    "    #print(f\"{mlp.count_params()} parameters\")\n",
    "\n",
    "    training_params = {\n",
    "        'x': input_dict_train,\n",
    "        'y': y_train,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 300,\n",
    "        #'callbacks': [CustomCallback(49)],\n",
    "        'shuffle': True,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    mlp.fit(**training_params)\n",
    "    preds = mlp.predict(input_dict_test)\n",
    "    preds = pd.DataFrame(preds,\n",
    "                         index=['F%s' % c for c in range(1, 29)],\n",
    "                         columns=ids).T\n",
    "    \n",
    "    list_preds.append(preds)\n",
    "    del mlp\n",
    "    gc.collect() \n",
    "\n",
    "preds = pd.concat(list_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat(list_preds)\n",
    "preds = preds.reset_index()\n",
    "preds.columns = ['id'] + preds.columns.tolist()[1:]\n",
    "\n",
    "preds.to_csv(\n",
    "        os.path.join(EXTERNAL_PATH, \"tf_weights_%s.csv\" % horizon), index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python score_submission_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
