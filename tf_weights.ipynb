{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('./tf_pipeline/')\n",
    "\n",
    "from tf_pipeline.tf_utils import create_mlp_softmax\n",
    "\n",
    "from tf_pipeline.conf import *\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np \n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "\n",
    "def create_dt(horizon=\"validation\", tr_last=1913):\n",
    "    prices = pd.read_csv(os.path.join(RAW_PATH, \"sell_prices.csv\"), dtype=PRICE_DTYPES)\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col] -= prices[col].min()\n",
    "\n",
    "    cal = pd.read_csv(os.path.join(RAW_PATH, \"calendar.csv\"), dtype=CAL_DTYPES)\n",
    "    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col] -= cal[col].min()\n",
    "\n",
    "    numcols = [f\"d_{day}\" for day in range(1, tr_last + 1)]\n",
    "    catcols = [\"id\", \"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n",
    "    dtype = {numcol: \"float32\" for numcol in numcols}\n",
    "    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "    dt = pd.read_csv(\n",
    "        os.path.join(RAW_PATH, \"sales_train_%s.csv\" % horizon),\n",
    "        usecols=catcols + numcols,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "\n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            dt[col] = dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col] -= dt[col].min()\n",
    "\n",
    "    increasing_term = dt.groupby([\"dept_id\", \"store_id\"])[numcols].sum()\n",
    "    increasing_term = (\n",
    "                              increasing_term.T - increasing_term.T.shift(28)\n",
    "                      ) / increasing_term.T.shift(28)\n",
    "    increasing_term = increasing_term.reset_index(drop=True).iloc[-365:, :]\n",
    "    rates = increasing_term[increasing_term.abs() < 1].mean() + 1\n",
    "    rates = rates.reset_index().rename(columns={0: \"rate\"})\n",
    "\n",
    "    for day in range(tr_last + 1, tr_last + 2 * 28 + 1):\n",
    "        dt[f\"d_{day}\"] = np.nan\n",
    "\n",
    "    dt = pd.melt(\n",
    "        dt,\n",
    "        id_vars=catcols,\n",
    "        value_vars=[col for col in dt.columns if col.startswith(\"d_\")],\n",
    "        var_name=\"d\",\n",
    "        value_name=\"sales\",\n",
    "    )\n",
    "\n",
    "    dt = dt.merge(cal, on=\"d\", copy=False)\n",
    "    dt = dt.merge(prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], copy=False)\n",
    "    dt = dt.merge(rates, how=\"left\")\n",
    "\n",
    "    return dt\n",
    "\n",
    "def compute_share(dt):\n",
    "    shares = (\n",
    "        dt.groupby([\"dept_id\", \"store_id\", \"date\"])[\"sales\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"sales\": \"gp_sales\"})\n",
    "    )\n",
    "    dt = dt.merge(shares, how=\"left\")\n",
    "    dt[\"sales\"] = dt[\"sales\"] / dt[\"gp_sales\"]\n",
    "    dt.drop([\"gp_sales\"], axis=1, inplace=True)\n",
    "    return dt\n",
    "\n",
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\", \"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = (\n",
    "                dt[[\"id\", lag_col]]\n",
    "                    .groupby(\"id\")[lag_col]\n",
    "                    .transform(lambda x: x.rolling(win).mean())\n",
    "            )\n",
    "\n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "    }\n",
    "\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
    "    return dt\n",
    "\n",
    "def train_and_pred(horizon=\"validation\"):\n",
    "\n",
    "    if horizon==\"validation\":\n",
    "        tr_last = 1913\n",
    "        fday = datetime(2016, 4, 25)\n",
    "    elif horizon==\"evaluation\":\n",
    "        tr_last = 1941\n",
    "        fday = datetime(2016, 4, 25) + timedelta(days=28)\n",
    "    else:\n",
    "        raise ValueError('Wrong horizon arg.')\n",
    "\n",
    "    dataframe = create_dt(horizon, tr_last)\n",
    "    dataframe = compute_share(dataframe)\n",
    "    dataframe = create_fea(dataframe)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    \n",
    "\n",
    "    list_preds = list()\n",
    "\n",
    "    for _, df_gp in dataframe.groupby(['store_id', 'dept_id']):\n",
    "\n",
    "        cat_feats = ['wday', 'quarter']\n",
    "\n",
    "        n_items = len(df_gp['item_id'].drop_duplicates())    \n",
    "\n",
    "        ids = df_gp[['id', 'item_id']].drop_duplicates()\\\n",
    "                                      .sort_values('item_id')['id']\\\n",
    "                                      .tolist()\n",
    "        X = df_gp[\n",
    "            ['d',\n",
    "             'item_id',\n",
    "             'wday',\n",
    "             'quarter',\n",
    "             'date',\n",
    "             'rmean_28_28',\n",
    "             'sales',\n",
    "             ]\n",
    "            \n",
    "        ].pivot_table(index=['d', 'date', 'wday', 'quarter'],\n",
    "                      columns=['item_id'],\n",
    "                      values=['rmean_28_28', 'sales']).fillna(0)\n",
    "\n",
    "        num_feats = ['_'.join(list(map(str, c))) for c in X.columns.tolist()]\n",
    "        X.columns = num_feats\n",
    "\n",
    "        target_feats = num_feats[n_items:]\n",
    "        num_feats = num_feats[:n_items]\n",
    "        X = X.reset_index()\n",
    "\n",
    "        X_train = X[X['date']<fday][num_feats+cat_feats]\n",
    "        X_test = X[X['date']>=fday][num_feats+cat_feats]\n",
    "\n",
    "        input_dict_train = {'input_%s' % c: X_train[c] for c in num_feats+cat_feats}\n",
    "        input_dict_test = {'input_%s' % c: X_test[c] for c in num_feats+cat_feats}\n",
    "\n",
    "        cardinality = X[cat_feats].nunique()\n",
    "\n",
    "        y_train = X[X['date']<fday][target_feats].values\n",
    "\n",
    "        mlp = create_mlp_softmax(layers_list=[2048, 2048],\n",
    "                                 output_count=n_items,\n",
    "                                 cat_feats=cat_feats,\n",
    "                                 cardinality=cardinality,\n",
    "                                 num_feats=num_feats)\n",
    "\n",
    "\n",
    "\n",
    "        training_params = {\n",
    "                    'x': input_dict_train,\n",
    "                    'y': y_train,\n",
    "                    'batch_size': 128,\n",
    "                    'epochs': 20,\n",
    "                    'shuffle': True,\n",
    "                }\n",
    "\n",
    "        mlp.fit(**training_params)\n",
    "        preds = mlp.predict(input_dict_test)\n",
    "        preds = pd.DataFrame(preds,\n",
    "                             index=['F%s' % c for c in range(1,29)],\n",
    "                             columns=ids).T\n",
    "        list_preds.append(preds)\n",
    "\n",
    "    preds = pd.concat(list_preds)\n",
    "    preds = preds.reset_index()\n",
    "    preds.columns = ['id'] + preds.columns.tolist()[1:]\n",
    "    \n",
    "    preds.to_csv(\n",
    "            os.path.join(EXTERNAL_PATH, \"tf_weights_%s.csv\" % horizon), index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=\"validation\"\n",
    "\n",
    "if horizon==\"validation\":\n",
    "    tr_last = 1913\n",
    "    fday = datetime(2016, 4, 25)\n",
    "elif horizon==\"evaluation\":\n",
    "    tr_last = 1941\n",
    "    fday = datetime(2016, 4, 25) + timedelta(days=28)\n",
    "else:\n",
    "    raise ValueError('Wrong horizon arg.')\n",
    "\n",
    "dataframe = create_dt(horizon, tr_last)\n",
    "dataframe = compute_share(dataframe)\n",
    "dataframe = create_fea(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tfk \n",
    "class CustomCallback(tfk.callbacks.Callback):\n",
    "    def __init__(self, print_n_epochs=10):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.print_n_epochs = print_n_epochs\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch%self.print_n_epochs==0:\n",
    "            try:\n",
    "                print(f\"E: {epoch} loss : {logs['loss']:.2f}, vrmse :{logs['val_root_mean_squared_error']:.2f}\")\n",
    "            except:\n",
    "                print(f\"E: {epoch} loss : {logs['loss']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.03\n",
      "E: 49 loss : 5.29\n",
      "E: 98 loss : 5.28\n",
      "E: 147 loss : 5.27\n",
      "E: 196 loss : 5.27\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.04\n",
      "E: 49 loss : 4.58\n",
      "E: 98 loss : 4.53\n",
      "E: 147 loss : 4.52\n",
      "E: 196 loss : 4.49\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.26\n",
      "E: 49 loss : 5.77\n",
      "E: 98 loss : 5.76\n",
      "E: 147 loss : 5.76\n",
      "E: 196 loss : 5.75\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.24\n",
      "E: 49 loss : 5.79\n",
      "E: 98 loss : 5.78\n",
      "E: 147 loss : 5.77\n",
      "E: 196 loss : 5.76\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.39\n",
      "E: 49 loss : 4.85\n",
      "E: 98 loss : 4.84\n",
      "E: 147 loss : 4.83\n",
      "E: 196 loss : 4.82\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.41\n",
      "E: 98 loss : 5.40\n",
      "E: 147 loss : 5.39\n",
      "E: 196 loss : 5.38\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.69\n",
      "E: 49 loss : 5.94\n",
      "E: 98 loss : 5.93\n",
      "E: 147 loss : 5.92\n",
      "E: 196 loss : 5.91\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.39\n",
      "E: 98 loss : 5.38\n",
      "E: 147 loss : 5.37\n",
      "E: 196 loss : 5.37\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.05\n",
      "E: 49 loss : 4.59\n",
      "E: 98 loss : 4.55\n",
      "E: 147 loss : 4.53\n",
      "E: 196 loss : 4.51\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.26\n",
      "E: 49 loss : 5.83\n",
      "E: 98 loss : 5.82\n",
      "E: 147 loss : 5.81\n",
      "E: 196 loss : 5.81\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.23\n",
      "E: 49 loss : 5.75\n",
      "E: 98 loss : 5.73\n",
      "E: 147 loss : 5.72\n",
      "E: 196 loss : 5.71\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.38\n",
      "E: 49 loss : 4.89\n",
      "E: 98 loss : 4.87\n",
      "E: 147 loss : 4.86\n",
      "E: 196 loss : 4.86\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.97\n",
      "E: 49 loss : 5.41\n",
      "E: 98 loss : 5.40\n",
      "E: 147 loss : 5.39\n",
      "E: 196 loss : 5.39\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.71\n",
      "E: 49 loss : 5.96\n",
      "E: 98 loss : 5.95\n",
      "E: 147 loss : 5.94\n",
      "E: 196 loss : 5.93\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.03\n",
      "E: 49 loss : 5.27\n",
      "E: 98 loss : 5.25\n",
      "E: 147 loss : 5.25\n",
      "E: 196 loss : 5.24\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.04\n",
      "E: 49 loss : 4.54\n",
      "E: 98 loss : 4.50\n",
      "E: 147 loss : 4.48\n",
      "E: 196 loss : 4.46\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.26\n",
      "E: 49 loss : 5.63\n",
      "E: 98 loss : 5.62\n",
      "E: 147 loss : 5.61\n",
      "E: 196 loss : 5.61\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.23\n",
      "E: 49 loss : 5.75\n",
      "E: 98 loss : 5.73\n",
      "E: 147 loss : 5.73\n",
      "E: 196 loss : 5.72\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.39\n",
      "E: 49 loss : 4.85\n",
      "E: 98 loss : 4.83\n",
      "E: 147 loss : 4.82\n",
      "E: 196 loss : 4.81\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.46\n",
      "E: 98 loss : 5.45\n",
      "E: 147 loss : 5.44\n",
      "E: 196 loss : 5.44\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.71\n",
      "E: 49 loss : 5.86\n",
      "E: 98 loss : 5.84\n",
      "E: 147 loss : 5.83\n",
      "E: 196 loss : 5.83\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.20\n",
      "E: 98 loss : 5.18\n",
      "E: 147 loss : 5.18\n",
      "E: 196 loss : 5.17\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.05\n",
      "E: 49 loss : 4.54\n",
      "E: 98 loss : 4.46\n",
      "E: 147 loss : 4.40\n",
      "E: 196 loss : 4.37\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.27\n",
      "E: 49 loss : 5.89\n",
      "E: 98 loss : 5.88\n",
      "E: 147 loss : 5.87\n",
      "E: 196 loss : 5.87\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.24\n",
      "E: 49 loss : 5.75\n",
      "E: 98 loss : 5.73\n",
      "E: 147 loss : 5.71\n",
      "E: 196 loss : 5.70\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.39\n",
      "E: 49 loss : 4.73\n",
      "E: 98 loss : 4.71\n",
      "E: 147 loss : 4.69\n",
      "E: 196 loss : 4.69\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.52\n",
      "E: 98 loss : 5.51\n",
      "E: 147 loss : 5.50\n",
      "E: 196 loss : 5.50\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.69\n",
      "E: 49 loss : 6.11\n",
      "E: 98 loss : 6.09\n",
      "E: 147 loss : 6.08\n",
      "E: 196 loss : 6.07\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.34\n",
      "E: 98 loss : 5.32\n",
      "E: 147 loss : 5.30\n",
      "E: 196 loss : 5.29\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.06\n",
      "E: 49 loss : 4.50\n",
      "E: 98 loss : 4.44\n",
      "E: 147 loss : 4.42\n",
      "E: 196 loss : 4.39\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.26\n",
      "E: 49 loss : 5.66\n",
      "E: 98 loss : 5.64\n",
      "E: 147 loss : 5.64\n",
      "E: 196 loss : 5.63\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.23\n",
      "E: 49 loss : 5.64\n",
      "E: 98 loss : 5.61\n",
      "E: 147 loss : 5.59\n",
      "E: 196 loss : 5.59\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.39\n",
      "E: 49 loss : 4.66\n",
      "E: 98 loss : 4.64\n",
      "E: 147 loss : 4.63\n",
      "E: 196 loss : 4.62\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.39\n",
      "E: 98 loss : 5.38\n",
      "E: 147 loss : 5.36\n",
      "E: 196 loss : 5.36\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.70\n",
      "E: 49 loss : 5.71\n",
      "E: 98 loss : 5.69\n",
      "E: 147 loss : 5.68\n",
      "E: 196 loss : 5.67\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.42\n",
      "E: 98 loss : 5.40\n",
      "E: 147 loss : 5.39\n",
      "E: 196 loss : 5.38\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.06\n",
      "E: 49 loss : 4.58\n",
      "E: 98 loss : 4.54\n",
      "E: 147 loss : 4.53\n",
      "E: 196 loss : 4.50\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.27\n",
      "E: 49 loss : 5.74\n",
      "E: 98 loss : 5.72\n",
      "E: 147 loss : 5.72\n",
      "E: 196 loss : 5.71\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.23\n",
      "E: 49 loss : 5.81\n",
      "E: 98 loss : 5.79\n",
      "E: 147 loss : 5.77\n",
      "E: 196 loss : 5.77\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.39\n",
      "E: 49 loss : 4.69\n",
      "E: 98 loss : 4.67\n",
      "E: 147 loss : 4.66\n",
      "E: 196 loss : 4.65\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.38\n",
      "E: 98 loss : 5.37\n",
      "E: 147 loss : 5.35\n",
      "E: 196 loss : 5.35\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.68\n",
      "E: 49 loss : 5.69\n",
      "E: 98 loss : 5.67\n",
      "E: 147 loss : 5.66\n",
      "E: 196 loss : 5.64\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.20\n",
      "E: 98 loss : 5.18\n",
      "E: 147 loss : 5.17\n",
      "E: 196 loss : 5.16\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.05\n",
      "E: 49 loss : 4.53\n",
      "E: 98 loss : 4.49\n",
      "E: 147 loss : 4.46\n",
      "E: 196 loss : 4.44\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.26\n",
      "E: 49 loss : 5.65\n",
      "E: 98 loss : 5.64\n",
      "E: 147 loss : 5.63\n",
      "E: 196 loss : 5.62\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.23\n",
      "E: 49 loss : 5.76\n",
      "E: 98 loss : 5.74\n",
      "E: 147 loss : 5.73\n",
      "E: 196 loss : 5.72\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.41\n",
      "E: 49 loss : 4.49\n",
      "E: 98 loss : 4.47\n",
      "E: 147 loss : 4.45\n",
      "E: 196 loss : 4.44\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.40\n",
      "E: 98 loss : 5.39\n",
      "E: 147 loss : 5.37\n",
      "E: 196 loss : 5.37\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.70\n",
      "E: 49 loss : 5.66\n",
      "E: 98 loss : 5.63\n",
      "E: 147 loss : 5.63\n",
      "E: 196 loss : 5.61\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.32\n",
      "E: 98 loss : 5.31\n",
      "E: 147 loss : 5.30\n",
      "E: 196 loss : 5.29\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.03\n",
      "E: 49 loss : 4.67\n",
      "E: 98 loss : 4.62\n",
      "E: 147 loss : 4.59\n",
      "E: 196 loss : 4.57\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.27\n",
      "E: 49 loss : 5.82\n",
      "E: 98 loss : 5.80\n",
      "E: 147 loss : 5.80\n",
      "E: 196 loss : 5.79\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.25\n",
      "E: 49 loss : 5.80\n",
      "E: 98 loss : 5.77\n",
      "E: 147 loss : 5.76\n",
      "E: 196 loss : 5.75\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.39\n",
      "E: 49 loss : 4.81\n",
      "E: 98 loss : 4.80\n",
      "E: 147 loss : 4.79\n",
      "E: 196 loss : 4.78\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.57\n",
      "E: 98 loss : 5.56\n",
      "E: 147 loss : 5.55\n",
      "E: 196 loss : 5.55\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.71\n",
      "E: 49 loss : 6.10\n",
      "E: 98 loss : 6.08\n",
      "E: 147 loss : 6.07\n",
      "E: 196 loss : 6.06\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.33\n",
      "E: 98 loss : 5.31\n",
      "E: 147 loss : 5.29\n",
      "E: 196 loss : 5.29\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.04\n",
      "E: 49 loss : 4.50\n",
      "E: 98 loss : 4.44\n",
      "E: 147 loss : 4.40\n",
      "E: 196 loss : 4.37\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.26\n",
      "E: 49 loss : 5.55\n",
      "E: 98 loss : 5.53\n",
      "E: 147 loss : 5.53\n",
      "E: 196 loss : 5.53\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.24\n",
      "E: 49 loss : 5.59\n",
      "E: 98 loss : 5.56\n",
      "E: 147 loss : 5.55\n",
      "E: 196 loss : 5.54\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.40\n",
      "E: 49 loss : 4.45\n",
      "E: 98 loss : 4.42\n",
      "E: 147 loss : 4.40\n",
      "E: 196 loss : 4.40\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.98\n",
      "E: 49 loss : 5.35\n",
      "E: 98 loss : 5.33\n",
      "E: 147 loss : 5.33\n",
      "E: 196 loss : 5.32\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.71\n",
      "E: 49 loss : 5.86\n",
      "E: 98 loss : 5.84\n",
      "E: 147 loss : 5.83\n",
      "E: 196 loss : 5.82\n",
      "416 in the hierachie\n",
      "17514 parameters\n",
      "E: 0 loss : 6.02\n",
      "E: 49 loss : 5.31\n",
      "E: 98 loss : 5.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 147 loss : 5.27\n",
      "E: 196 loss : 5.26\n",
      "149 in the hierachie\n",
      "6567 parameters\n",
      "E: 0 loss : 5.05\n",
      "E: 49 loss : 4.59\n",
      "E: 98 loss : 4.52\n",
      "E: 147 loss : 4.49\n",
      "E: 196 loss : 4.47\n",
      "532 in the hierachie\n",
      "22270 parameters\n",
      "E: 0 loss : 6.26\n",
      "E: 49 loss : 5.58\n",
      "E: 98 loss : 5.56\n",
      "E: 147 loss : 5.56\n",
      "E: 196 loss : 5.55\n",
      "515 in the hierachie\n",
      "21573 parameters\n",
      "E: 0 loss : 6.23\n",
      "E: 49 loss : 5.67\n",
      "E: 98 loss : 5.65\n",
      "E: 147 loss : 5.63\n",
      "E: 196 loss : 5.63\n",
      "216 in the hierachie\n",
      "9314 parameters\n",
      "E: 0 loss : 5.38\n",
      "E: 49 loss : 4.58\n",
      "E: 98 loss : 4.55\n",
      "E: 147 loss : 4.55\n",
      "E: 196 loss : 4.53\n",
      "398 in the hierachie\n",
      "16776 parameters\n",
      "E: 0 loss : 5.97\n",
      "E: 49 loss : 5.38\n",
      "E: 98 loss : 5.35\n",
      "E: 147 loss : 5.34\n",
      "E: 196 loss : 5.34\n",
      "823 in the hierachie\n",
      "34201 parameters\n",
      "E: 0 loss : 6.70\n",
      "E: 49 loss : 5.69\n",
      "E: 98 loss : 5.66\n",
      "E: 147 loss : 5.65\n",
      "E: 196 loss : 5.64\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import warnings\n",
    "list_preds = list()\n",
    "gc.collect()\n",
    "warnings.filterwarnings('ignore')  # TF casse les ******\n",
    "\n",
    "for _, df_gp in dataframe.groupby(['store_id', 'dept_id']):\n",
    "\n",
    "    cat_feats = ['wday', 'quarter']\n",
    "\n",
    "    n_items = len(df_gp['item_id'].drop_duplicates())\n",
    "    print(f'{n_items} in the hierachie')\n",
    "\n",
    "    ids = df_gp[['id', 'item_id']].drop_duplicates()\\\n",
    "                                  .sort_values('item_id')['id']\\\n",
    "                                  .tolist()\n",
    "    X = df_gp[\n",
    "        ['d', 'item_id', 'wday', 'quarter', 'date', 'rmean_28_28', 'sales']\n",
    "    ].pivot_table(index=['d', 'date', 'wday', 'quarter'],\n",
    "                  columns=['item_id'],\n",
    "                  values=['rmean_28_28', 'sales']).fillna(0)\n",
    "\n",
    "    num_feats = ['_'.join(list(map(str, c))) for c in X.columns.tolist()]\n",
    "    X.columns = num_feats\n",
    "\n",
    "    target_feats = num_feats[n_items:]\n",
    "    num_feats = num_feats[:n_items]\n",
    "    X = X.reset_index()\n",
    "\n",
    "    X_train = X[(X['date'] < fday) & (X['date'] >= fday -\n",
    "                                      timedelta(days=364))][num_feats+cat_feats]\n",
    "    X_test = X[X['date'] >= fday][num_feats+cat_feats]\n",
    "\n",
    "    input_dict_train = {'input_%s' %\n",
    "                        c: X_train[c] for c in num_feats+cat_feats}\n",
    "    input_dict_test = {'input_%s' % c: X_test[c] for c in num_feats+cat_feats}\n",
    "\n",
    "    cardinality = X[cat_feats].nunique()\n",
    "\n",
    "    y_train = X[(X['date'] < fday) & (X['date'] >= fday -\n",
    "                                      timedelta(days=364))][target_feats].values\n",
    "\n",
    "    mlp = create_mlp_softmax(layers_list=[8, 16, ],\n",
    "                             emb_dim=3,\n",
    "                             output_count=n_items,\n",
    "                             cat_feats=cat_feats,\n",
    "                             cardinality=cardinality,\n",
    "                             num_feats=num_feats)\n",
    "    print(f\"{mlp.count_params()} parameters\")\n",
    "\n",
    "    training_params = {\n",
    "        'x': input_dict_train,\n",
    "        'y': y_train,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 300,\n",
    "        'callbacks': [CustomCallback(49)],\n",
    "        'shuffle': True,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    mlp.fit(**training_params)\n",
    "    preds = mlp.predict(input_dict_test)\n",
    "    preds = pd.DataFrame(preds,\n",
    "                         index=['F%s' % c for c in range(1, 29)],\n",
    "                         columns=ids).T\n",
    "    list_preds.append(preds)\n",
    "    del mlp\n",
    "    gc.collect()\n",
    "\n",
    "preds = pd.concat(list_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat(list_preds)\n",
    "preds = preds.reset_index()\n",
    "preds.columns = ['id'] + preds.columns.tolist()[1:]\n",
    "\n",
    "preds.to_csv(\n",
    "        os.path.join(EXTERNAL_PATH, \"tf_weights_%s.csv\" % horizon), index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python score_submission_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
