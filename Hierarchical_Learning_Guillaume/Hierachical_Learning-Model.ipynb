{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voQPcQtPVJEq"
   },
   "outputs": [],
   "source": [
    "#!pip install optuna\n",
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_Kz_ENn5iICm",
    "outputId": "abd739c4-b95f-4845-a8e1-34131dab64f3"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle\n",
    "from math import ceil\n",
    "import functools\n",
    "import gc\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKATHRwmgWAF"
   },
   "outputs": [],
   "source": [
    "# Merging by concat to not lose dtypes\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfZGvJMlkC7h"
   },
   "source": [
    " \n",
    "# Step 2: Hierarchical learning\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8LhSxidiWpJS"
   },
   "outputs": [],
   "source": [
    "#start of hierarchical learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCMyIefhV9_-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import optuna\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ko63SvsWVC4"
   },
   "outputs": [],
   "source": [
    "#load prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71oSoLNMWORi"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/interim/grid_df_gho.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "sTrJo8YjXFod",
    "outputId": "954b2a30-4c74-4850-f606-1e5fba8661f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>...</th>\n",
       "      <th>store_id_CA_1</th>\n",
       "      <th>store_id_CA_2</th>\n",
       "      <th>store_id_CA_3</th>\n",
       "      <th>store_id_CA_4</th>\n",
       "      <th>store_id_TX_1</th>\n",
       "      <th>store_id_TX_2</th>\n",
       "      <th>store_id_TX_3</th>\n",
       "      <th>store_id_WI_1</th>\n",
       "      <th>store_id_WI_2</th>\n",
       "      <th>store_id_WI_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id state_id    d  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1       CA  897   \n",
       "1  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1       CA  898   \n",
       "2  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1       CA  899   \n",
       "3  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1       CA  900   \n",
       "4  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1       CA  901   \n",
       "\n",
       "   sales event_name_1 event_type_1 event_name_2 event_type_2  ...  \\\n",
       "0    0.0         None         None         None         None  ...   \n",
       "1    0.0         None         None         None         None  ...   \n",
       "2    0.0         None         None         None         None  ...   \n",
       "3    0.0         None         None         None         None  ...   \n",
       "4    0.0         None         None         None         None  ...   \n",
       "\n",
       "  store_id_CA_1 store_id_CA_2 store_id_CA_3  store_id_CA_4  store_id_TX_1  \\\n",
       "0             1             0             0              0              0   \n",
       "1             1             0             0              0              0   \n",
       "2             1             0             0              0              0   \n",
       "3             1             0             0              0              0   \n",
       "4             1             0             0              0              0   \n",
       "\n",
       "   store_id_TX_2  store_id_TX_3  store_id_WI_1  store_id_WI_2  store_id_WI_3  \n",
       "0              0              0              0              0              0  \n",
       "1              0              0              0              0              0  \n",
       "2              0              0              0              0              0  \n",
       "3              0              0              0              0              0  \n",
       "4              0              0              0              0              0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxAmTD3ZXmei"
   },
   "outputs": [],
   "source": [
    "#dropping some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0bGklnKXZCQ"
   },
   "outputs": [],
   "source": [
    "def drop_features(dfx):\n",
    "    dfx.drop(columns=['id', \n",
    "                           'item_id',\n",
    "                           'event_name_1', \n",
    "                           'event_type_1', \n",
    "                           'event_name_2', \n",
    "                           'event_type_2',\n",
    "                           'sales', \n",
    "                           'dept_id',\n",
    "                           'state_id',], inplace=True)\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqm3raklXkkI"
   },
   "outputs": [],
   "source": [
    "df = drop_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_share']=df['product_share']/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TR-C7mlWY0FT"
   },
   "outputs": [],
   "source": [
    "# TEMPORAL SPLIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "akYr-gwwXsFY"
   },
   "outputs": [],
   "source": [
    "df_train = df[(df['d'] < 1914-28) & (df['d'] > 800)] \n",
    "df_test = df[(df['d'] >= 1914-28) & (df['d'] < 1914)] \n",
    "df_validation = df[df['d'] >= 1914] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcGdFwtvYDuu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hochard/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_train.drop(columns=['d'], inplace=True)\n",
    "df_test.drop(columns=['d'], inplace=True)\n",
    "df_validation.drop(columns=['d'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tdMWY8hYonl"
   },
   "outputs": [],
   "source": [
    "# Setting targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2r6EgewTY3C6"
   },
   "outputs": [],
   "source": [
    "y_train = df_train['product_share']\n",
    "y_test = df_test['product_share']\n",
    "\n",
    "df_train.drop(columns=['product_share'], inplace=True) \n",
    "df_test.drop(columns=['product_share'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJlEDPSwY37M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_KzsVVffZc3K"
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(df_train, label=y_train)\n",
    "dval = lgb.Dataset(df_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train tout simple pour tester "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'cross_entropy'\n",
    "params['metric'] = 'cross_entropy'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 10\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's cross_entropy: 0.0173074\tvalid_1's cross_entropy: 0.0162499\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's cross_entropy: 0.0173019\tvalid_1's cross_entropy: 0.0162454\n",
      "[3]\ttraining's cross_entropy: 0.0172975\tvalid_1's cross_entropy: 0.016242\n",
      "[4]\ttraining's cross_entropy: 0.0172933\tvalid_1's cross_entropy: 0.0162388\n",
      "[5]\ttraining's cross_entropy: 0.017289\tvalid_1's cross_entropy: 0.0162355\n",
      "[6]\ttraining's cross_entropy: 0.017284\tvalid_1's cross_entropy: 0.0162315\n",
      "[7]\ttraining's cross_entropy: 0.0172819\tvalid_1's cross_entropy: 0.0162296\n",
      "[8]\ttraining's cross_entropy: 0.0172778\tvalid_1's cross_entropy: 0.0162264\n",
      "[9]\ttraining's cross_entropy: 0.0172756\tvalid_1's cross_entropy: 0.0162245\n",
      "[10]\ttraining's cross_entropy: 0.0172751\tvalid_1's cross_entropy: 0.016224\n",
      "[11]\ttraining's cross_entropy: 0.017271\tvalid_1's cross_entropy: 0.0162208\n",
      "[12]\ttraining's cross_entropy: 0.0172661\tvalid_1's cross_entropy: 0.0162167\n",
      "[13]\ttraining's cross_entropy: 0.0172655\tvalid_1's cross_entropy: 0.0162162\n",
      "[14]\ttraining's cross_entropy: 0.0172615\tvalid_1's cross_entropy: 0.0162128\n",
      "[15]\ttraining's cross_entropy: 0.0172575\tvalid_1's cross_entropy: 0.0162097\n",
      "[16]\ttraining's cross_entropy: 0.0172558\tvalid_1's cross_entropy: 0.0162082\n",
      "[17]\ttraining's cross_entropy: 0.0172537\tvalid_1's cross_entropy: 0.0162063\n",
      "[18]\ttraining's cross_entropy: 0.01725\tvalid_1's cross_entropy: 0.0162032\n",
      "[19]\ttraining's cross_entropy: 0.0172499\tvalid_1's cross_entropy: 0.0162031\n",
      "[20]\ttraining's cross_entropy: 0.0172479\tvalid_1's cross_entropy: 0.0162013\n",
      "[21]\ttraining's cross_entropy: 0.0172477\tvalid_1's cross_entropy: 0.0162011\n",
      "[22]\ttraining's cross_entropy: 0.0172473\tvalid_1's cross_entropy: 0.0162007\n",
      "[23]\ttraining's cross_entropy: 0.0172468\tvalid_1's cross_entropy: 0.0162003\n",
      "[24]\ttraining's cross_entropy: 0.0172421\tvalid_1's cross_entropy: 0.0161964\n",
      "[25]\ttraining's cross_entropy: 0.0172421\tvalid_1's cross_entropy: 0.0161963\n",
      "[26]\ttraining's cross_entropy: 0.0172376\tvalid_1's cross_entropy: 0.0161926\n",
      "[27]\ttraining's cross_entropy: 0.0172338\tvalid_1's cross_entropy: 0.0161893\n",
      "[28]\ttraining's cross_entropy: 0.017232\tvalid_1's cross_entropy: 0.0161877\n",
      "[29]\ttraining's cross_entropy: 0.0172304\tvalid_1's cross_entropy: 0.0161863\n",
      "[30]\ttraining's cross_entropy: 0.017226\tvalid_1's cross_entropy: 0.0161825\n",
      "[31]\ttraining's cross_entropy: 0.0172217\tvalid_1's cross_entropy: 0.016179\n",
      "[32]\ttraining's cross_entropy: 0.0172174\tvalid_1's cross_entropy: 0.0161753\n",
      "[33]\ttraining's cross_entropy: 0.0172139\tvalid_1's cross_entropy: 0.0161726\n",
      "[34]\ttraining's cross_entropy: 0.0172104\tvalid_1's cross_entropy: 0.0161699\n",
      "[35]\ttraining's cross_entropy: 0.0172062\tvalid_1's cross_entropy: 0.0161663\n",
      "[36]\ttraining's cross_entropy: 0.0172044\tvalid_1's cross_entropy: 0.0161646\n",
      "[37]\ttraining's cross_entropy: 0.0172002\tvalid_1's cross_entropy: 0.0161611\n",
      "[38]\ttraining's cross_entropy: 0.0171969\tvalid_1's cross_entropy: 0.0161584\n",
      "[39]\ttraining's cross_entropy: 0.0171936\tvalid_1's cross_entropy: 0.0161558\n",
      "[40]\ttraining's cross_entropy: 0.0171931\tvalid_1's cross_entropy: 0.0161554\n",
      "[41]\ttraining's cross_entropy: 0.0171891\tvalid_1's cross_entropy: 0.016152\n",
      "[42]\ttraining's cross_entropy: 0.0171873\tvalid_1's cross_entropy: 0.0161504\n",
      "[43]\ttraining's cross_entropy: 0.0171868\tvalid_1's cross_entropy: 0.01615\n",
      "[44]\ttraining's cross_entropy: 0.0171865\tvalid_1's cross_entropy: 0.0161498\n",
      "[45]\ttraining's cross_entropy: 0.0171826\tvalid_1's cross_entropy: 0.0161464\n",
      "[46]\ttraining's cross_entropy: 0.0171796\tvalid_1's cross_entropy: 0.0161439\n",
      "[47]\ttraining's cross_entropy: 0.0171791\tvalid_1's cross_entropy: 0.0161435\n",
      "[48]\ttraining's cross_entropy: 0.017179\tvalid_1's cross_entropy: 0.0161434\n",
      "[49]\ttraining's cross_entropy: 0.0171759\tvalid_1's cross_entropy: 0.0161409\n",
      "[50]\ttraining's cross_entropy: 0.0171755\tvalid_1's cross_entropy: 0.0161405\n",
      "[51]\ttraining's cross_entropy: 0.0171754\tvalid_1's cross_entropy: 0.0161405\n",
      "[52]\ttraining's cross_entropy: 0.0171753\tvalid_1's cross_entropy: 0.0161404\n",
      "[53]\ttraining's cross_entropy: 0.0171739\tvalid_1's cross_entropy: 0.0161393\n",
      "[54]\ttraining's cross_entropy: 0.0171738\tvalid_1's cross_entropy: 0.0161392\n",
      "[55]\ttraining's cross_entropy: 0.0171701\tvalid_1's cross_entropy: 0.0161361\n",
      "[56]\ttraining's cross_entropy: 0.01717\tvalid_1's cross_entropy: 0.016136\n",
      "[57]\ttraining's cross_entropy: 0.0171699\tvalid_1's cross_entropy: 0.0161359\n",
      "[58]\ttraining's cross_entropy: 0.0171682\tvalid_1's cross_entropy: 0.0161344\n",
      "[59]\ttraining's cross_entropy: 0.0171645\tvalid_1's cross_entropy: 0.0161314\n",
      "[60]\ttraining's cross_entropy: 0.0171642\tvalid_1's cross_entropy: 0.016131\n",
      "[61]\ttraining's cross_entropy: 0.0171625\tvalid_1's cross_entropy: 0.0161296\n",
      "[62]\ttraining's cross_entropy: 0.0171595\tvalid_1's cross_entropy: 0.0161272\n",
      "[63]\ttraining's cross_entropy: 0.0171594\tvalid_1's cross_entropy: 0.0161272\n",
      "[64]\ttraining's cross_entropy: 0.017159\tvalid_1's cross_entropy: 0.0161267\n",
      "[65]\ttraining's cross_entropy: 0.0171562\tvalid_1's cross_entropy: 0.0161245\n",
      "[66]\ttraining's cross_entropy: 0.0171534\tvalid_1's cross_entropy: 0.0161219\n",
      "[67]\ttraining's cross_entropy: 0.0171507\tvalid_1's cross_entropy: 0.0161197\n",
      "[68]\ttraining's cross_entropy: 0.0171479\tvalid_1's cross_entropy: 0.016117\n",
      "[69]\ttraining's cross_entropy: 0.0171475\tvalid_1's cross_entropy: 0.0161166\n",
      "[70]\ttraining's cross_entropy: 0.0171447\tvalid_1's cross_entropy: 0.0161143\n",
      "[71]\ttraining's cross_entropy: 0.0171446\tvalid_1's cross_entropy: 0.0161143\n",
      "[72]\ttraining's cross_entropy: 0.0171411\tvalid_1's cross_entropy: 0.0161112\n",
      "[73]\ttraining's cross_entropy: 0.0171377\tvalid_1's cross_entropy: 0.0161084\n",
      "[74]\ttraining's cross_entropy: 0.0171376\tvalid_1's cross_entropy: 0.0161083\n",
      "[75]\ttraining's cross_entropy: 0.0171373\tvalid_1's cross_entropy: 0.0161081\n",
      "[76]\ttraining's cross_entropy: 0.0171346\tvalid_1's cross_entropy: 0.0161058\n",
      "[77]\ttraining's cross_entropy: 0.0171313\tvalid_1's cross_entropy: 0.016103\n",
      "[78]\ttraining's cross_entropy: 0.0171297\tvalid_1's cross_entropy: 0.0161017\n",
      "[79]\ttraining's cross_entropy: 0.0171264\tvalid_1's cross_entropy: 0.0160989\n",
      "[80]\ttraining's cross_entropy: 0.0171231\tvalid_1's cross_entropy: 0.016096\n",
      "[81]\ttraining's cross_entropy: 0.0171226\tvalid_1's cross_entropy: 0.0160956\n",
      "[82]\ttraining's cross_entropy: 0.0171226\tvalid_1's cross_entropy: 0.0160956\n",
      "[83]\ttraining's cross_entropy: 0.0171226\tvalid_1's cross_entropy: 0.0160956\n",
      "[84]\ttraining's cross_entropy: 0.0171201\tvalid_1's cross_entropy: 0.0160933\n",
      "[85]\ttraining's cross_entropy: 0.0171198\tvalid_1's cross_entropy: 0.016093\n",
      "[86]\ttraining's cross_entropy: 0.0171198\tvalid_1's cross_entropy: 0.016093\n",
      "[87]\ttraining's cross_entropy: 0.0171166\tvalid_1's cross_entropy: 0.0160903\n",
      "[88]\ttraining's cross_entropy: 0.0171162\tvalid_1's cross_entropy: 0.01609\n",
      "[89]\ttraining's cross_entropy: 0.0171147\tvalid_1's cross_entropy: 0.0160886\n",
      "[90]\ttraining's cross_entropy: 0.0171122\tvalid_1's cross_entropy: 0.0160862\n",
      "[91]\ttraining's cross_entropy: 0.0171098\tvalid_1's cross_entropy: 0.016084\n",
      "[92]\ttraining's cross_entropy: 0.0171094\tvalid_1's cross_entropy: 0.0160837\n",
      "[93]\ttraining's cross_entropy: 0.0171062\tvalid_1's cross_entropy: 0.0160809\n",
      "[94]\ttraining's cross_entropy: 0.0171031\tvalid_1's cross_entropy: 0.0160782\n",
      "[95]\ttraining's cross_entropy: 0.0171007\tvalid_1's cross_entropy: 0.016076\n",
      "[96]\ttraining's cross_entropy: 0.0171003\tvalid_1's cross_entropy: 0.0160757\n",
      "[97]\ttraining's cross_entropy: 0.0170987\tvalid_1's cross_entropy: 0.0160743\n",
      "[98]\ttraining's cross_entropy: 0.0170963\tvalid_1's cross_entropy: 0.0160722\n",
      "[99]\ttraining's cross_entropy: 0.0170934\tvalid_1's cross_entropy: 0.0160696\n",
      "[100]\ttraining's cross_entropy: 0.0170904\tvalid_1's cross_entropy: 0.0160671\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's cross_entropy: 0.0170904\tvalid_1's cross_entropy: 0.0160671\n",
      "time elapsed (seconds): 125.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "watchlist = [dtrain, dval]\n",
    "\n",
    "#training lightgbm \n",
    "clf = lgb.train(params, train_set = dtrain,\n",
    "                valid_sets=watchlist,\n",
    "                num_boost_round=100, \n",
    "                early_stopping_rounds=20)\n",
    "\n",
    "end_time = time.time()\n",
    "print('time elapsed (seconds):', np.round(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse error: 4.394508995615032e-05\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(df_test)\n",
    "error = mean_squared_error(y_test, y_pred)\n",
    "print('rmse error:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "\n",
    "def objective(trial:Trial, fastCheck=True, targetMeter=0, returnInfo=False):\n",
    "    \n",
    "    model, yPredValid, log = fitLGBM(trial, dtrain, dval, df_test, y_test, numRounds=num_rounds)\n",
    "    gc.collect()\n",
    "    validScore =log[\"valid xentropy\"]\n",
    "    \n",
    "    return validScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitLGBM(trial, dtrain, dval, df_test, y_test, numRounds=num_rounds):\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"cross_entropy\",\n",
    "        \"metric\": \"cross_entropy\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 5e-7, 5e-1),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 32, 255),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 256),\n",
    "        'min_data_in_bin': trial.suggest_int('min_data_in_bin', 1, 256),\n",
    "        'min_gain_to_split' : trial.suggest_discrete_uniform('min_gain_to_split', 0.1, 5, 0.01),      \n",
    "    }\n",
    "\n",
    "    earlyStop=20\n",
    "    verboseEval=0\n",
    "    \n",
    "    watchlist = [dtrain, dval]\n",
    "\n",
    "    # Callback for pruning.\n",
    "    lgbmPruningCallback = optuna.integration.LightGBMPruningCallback(trial, 'cross_entropy', valid_name='valid_1')\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_set=dtrain,\n",
    "                      num_boost_round=numRounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verboseEval,\n",
    "                      early_stopping_rounds=earlyStop,\n",
    "                      callbacks=[lgbmPruningCallback])\n",
    "    \n",
    "    #predictions\n",
    "    y_pred = model.predict(df_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print('***********************RMSE error :', error)\n",
    "    log={'train xentropy':model.best_score['training']['cross_entropy'],\n",
    "         'valid xentropy':model.best_score['valid_1']['cross_entropy']}\n",
    "    \n",
    "    return model, y_pred, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 4.445704940775249e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-01 23:07:07,636] Finished trial#0 with value: 0.01623548803451911 with parameters: {'learning_rate': 7.988904924119535e-06, 'lambda_l1': 9.332243940674252e-05, 'lambda_l2': 0.02308042163929847, 'num_leaves': 184, 'max_depth': 10, 'max_bin': 41, 'feature_fraction': 0.9008702414186154, 'bagging_fraction': 0.848215462319994, 'bagging_freq': 4, 'min_child_samples': 73, 'min_data_in_leaf': 40, 'min_data_in_bin': 243, 'min_gain_to_split': 2.42}. Best is trial#0 with value: 0.01623548803451911.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 4.45121056309461e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-01 23:31:47,407] Finished trial#1 with value: 0.01624648112671596 with parameters: {'learning_rate': 2.5220579182894676e-06, 'lambda_l1': 8.067898750185522e-05, 'lambda_l2': 0.003478945668621516, 'num_leaves': 91, 'max_depth': 15, 'max_bin': 209, 'feature_fraction': 0.75639724144409, 'bagging_fraction': 0.5297126163703857, 'bagging_freq': 5, 'min_child_samples': 39, 'min_data_in_leaf': 216, 'min_data_in_bin': 16, 'min_gain_to_split': 2.66}. Best is trial#0 with value: 0.01623548803451911.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 4.181577192327654e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-01 23:58:59,556] Finished trial#2 with value: 0.015834702682442976 with parameters: {'learning_rate': 0.00037017137519645824, 'lambda_l1': 0.00013453276478413406, 'lambda_l2': 1.6520008473207896e-06, 'num_leaves': 152, 'max_depth': 15, 'max_bin': 140, 'feature_fraction': 0.912208713680511, 'bagging_fraction': 0.5015969466131242, 'bagging_freq': 2, 'min_child_samples': 80, 'min_data_in_leaf': 249, 'min_data_in_bin': 107, 'min_gain_to_split': 4.68}. Best is trial#2 with value: 0.015834702682442976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.9050527909135094e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 00:08:46,237] Finished trial#3 with value: 0.015495801247978894 with parameters: {'learning_rate': 0.014742455557264741, 'lambda_l1': 0.001023850182763574, 'lambda_l2': 8.580299063495601e-07, 'num_leaves': 77, 'max_depth': 13, 'max_bin': 153, 'feature_fraction': 0.7221075553613421, 'bagging_fraction': 0.5331392075467332, 'bagging_freq': 4, 'min_child_samples': 85, 'min_data_in_leaf': 72, 'min_data_in_bin': 47, 'min_gain_to_split': 3.48}. Best is trial#3 with value: 0.015495801247978894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 4.3231478045923566e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 00:27:39,290] Finished trial#4 with value: 0.016028751498046393 with parameters: {'learning_rate': 0.00036927438777645266, 'lambda_l1': 0.0002753059767036483, 'lambda_l2': 0.022718306092948885, 'num_leaves': 243, 'max_depth': 2, 'max_bin': 189, 'feature_fraction': 0.6539445271489235, 'bagging_fraction': 0.9367458461341642, 'bagging_freq': 5, 'min_child_samples': 60, 'min_data_in_leaf': 9, 'min_data_in_bin': 21, 'min_gain_to_split': 0.32}. Best is trial#3 with value: 0.015495801247978894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.986862138851447e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 00:28:37,883] Finished trial#5 with value: 0.015548282856623076 with parameters: {'learning_rate': 0.31861257407317917, 'lambda_l1': 2.408834614635858e-08, 'lambda_l2': 8.165484685773725e-07, 'num_leaves': 72, 'max_depth': 19, 'max_bin': 194, 'feature_fraction': 0.5029308023180911, 'bagging_fraction': 0.4200391812506534, 'bagging_freq': 5, 'min_child_samples': 51, 'min_data_in_leaf': 244, 'min_data_in_bin': 10, 'min_gain_to_split': 4.77}. Best is trial#3 with value: 0.015495801247978894.\n",
      "[I 2020-06-02 00:28:49,321] Setting status of trial#6 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.8432244566661994e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 00:58:15,337] Finished trial#7 with value: 0.015430696058407457 with parameters: {'learning_rate': 0.012267754648536971, 'lambda_l1': 4.746831975005726, 'lambda_l2': 5.330734006159441, 'num_leaves': 184, 'max_depth': 20, 'max_bin': 200, 'feature_fraction': 0.6374868894171288, 'bagging_fraction': 0.9038017802247659, 'bagging_freq': 5, 'min_child_samples': 33, 'min_data_in_leaf': 224, 'min_data_in_bin': 86, 'min_gain_to_split': 0.41000000000000003}. Best is trial#7 with value: 0.015430696058407457.\n",
      "[I 2020-06-02 00:58:24,732] Setting status of trial#8 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 00:58:33,999] Setting status of trial#9 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.790594200288385e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:10:55,192] Finished trial#10 with value: 0.015383979808111481 with parameters: {'learning_rate': 0.04672556449915609, 'lambda_l1': 0.19223541123883978, 'lambda_l2': 7.505821327156282, 'num_leaves': 256, 'max_depth': 20, 'max_bin': 238, 'feature_fraction': 0.5963624737736998, 'bagging_fraction': 0.985375832323254, 'bagging_freq': 7, 'min_child_samples': 6, 'min_data_in_leaf': 181, 'min_data_in_bin': 196, 'min_gain_to_split': 0.14}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.802537933551528e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:19:24,500] Finished trial#11 with value: 0.015395464888510147 with parameters: {'learning_rate': 0.05465751013425922, 'lambda_l1': 0.11232641580037202, 'lambda_l2': 9.874040534636881, 'num_leaves': 242, 'max_depth': 20, 'max_bin': 254, 'feature_fraction': 0.6153093991919243, 'bagging_fraction': 0.9789164130712753, 'bagging_freq': 7, 'min_child_samples': 10, 'min_data_in_leaf': 161, 'min_data_in_bin': 213, 'min_gain_to_split': 0.24000000000000002}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.8938556361168337e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:20:39,033] Finished trial#12 with value: 0.015463387600816078 with parameters: {'learning_rate': 0.3617065476784789, 'lambda_l1': 0.07749898008325296, 'lambda_l2': 6.059939180052031, 'num_leaves': 247, 'max_depth': 18, 'max_bin': 255, 'feature_fraction': 0.514272027225567, 'bagging_fraction': 0.9992004510497131, 'bagging_freq': 7, 'min_child_samples': 6, 'min_data_in_leaf': 181, 'min_data_in_bin': 203, 'min_gain_to_split': 1.2000000000000002}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.873815733574562e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:32:00,970] Finished trial#13 with value: 0.015456346889230609 with parameters: {'learning_rate': 0.022617309610826437, 'lambda_l1': 0.06607319810545503, 'lambda_l2': 0.8924609408886841, 'num_leaves': 253, 'max_depth': 9, 'max_bin': 249, 'feature_fraction': 0.5870617468054775, 'bagging_fraction': 0.7593053813137137, 'bagging_freq': 7, 'min_child_samples': 5, 'min_data_in_leaf': 157, 'min_data_in_bin': 194, 'min_gain_to_split': 1.12}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 01:34:54,310] Setting status of trial#14 as TrialState.PRUNED. Trial was pruned at iteration 122.\n",
      "[I 2020-06-02 01:35:06,590] Setting status of trial#15 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 01:35:20,791] Setting status of trial#16 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.807365591641739e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:39:05,298] Finished trial#17 with value: 0.015407887056659046 with parameters: {'learning_rate': 0.07971759503035489, 'lambda_l1': 0.5495844208807855, 'lambda_l2': 0.5701859968596182, 'num_leaves': 217, 'max_depth': 17, 'max_bin': 226, 'feature_fraction': 0.8121338133247982, 'bagging_fraction': 0.9682641107516065, 'bagging_freq': 6, 'min_child_samples': 24, 'min_data_in_leaf': 200, 'min_data_in_bin': 237, 'min_gain_to_split': 0.75}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 01:39:22,138] Setting status of trial#18 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.846295273836005e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:40:45,459] Finished trial#19 with value: 0.01550235238160056 with parameters: {'learning_rate': 0.4663441303478698, 'lambda_l1': 0.005355064390960959, 'lambda_l2': 0.04609261023977546, 'num_leaves': 255, 'max_depth': 12, 'max_bin': 164, 'feature_fraction': 0.9869988475421183, 'bagging_fraction': 0.8019932454579767, 'bagging_freq': 7, 'min_child_samples': 32, 'min_data_in_leaf': 113, 'min_data_in_bin': 153, 'min_gain_to_split': 0.1}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 01:43:12,945] Setting status of trial#20 as TrialState.PRUNED. Trial was pruned at iteration 114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.8109798366746e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:47:57,360] Finished trial#21 with value: 0.015407976129835079 with parameters: {'learning_rate': 0.06634469800308233, 'lambda_l1': 0.7918075335443765, 'lambda_l2': 0.7102774577836031, 'num_leaves': 219, 'max_depth': 17, 'max_bin': 220, 'feature_fraction': 0.8159751409987478, 'bagging_fraction': 0.973960568042915, 'bagging_freq': 6, 'min_child_samples': 24, 'min_data_in_leaf': 202, 'min_data_in_bin': 238, 'min_gain_to_split': 0.72}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.833070143639715e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:57:53,348] Finished trial#22 with value: 0.015420443697624681 with parameters: {'learning_rate': 0.03510238593928628, 'lambda_l1': 0.5897635095285348, 'lambda_l2': 9.607652425168133, 'num_leaves': 228, 'max_depth': 20, 'max_bin': 233, 'feature_fraction': 0.6992739704581483, 'bagging_fraction': 0.9242042451719761, 'bagging_freq': 7, 'min_child_samples': 10, 'min_data_in_leaf': 202, 'min_data_in_bin': 180, 'min_gain_to_split': 0.69}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 01:58:10,093] Setting status of trial#23 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.882190643841149e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 01:59:36,517] Finished trial#24 with value: 0.015459297128262968 with parameters: {'learning_rate': 0.21529827279847671, 'lambda_l1': 0.365506743238857, 'lambda_l2': 1.8261972917339315, 'num_leaves': 168, 'max_depth': 16, 'max_bin': 217, 'feature_fraction': 0.7208217094869586, 'bagging_fraction': 0.8608943078290621, 'bagging_freq': 7, 'min_child_samples': 42, 'min_data_in_leaf': 232, 'min_data_in_bin': 254, 'min_gain_to_split': 1.6700000000000002}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 01:59:51,493] Setting status of trial#25 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.857081497903538e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:02:42,051] Finished trial#26 with value: 0.015431479710881798 with parameters: {'learning_rate': 0.13467531468079033, 'lambda_l1': 0.0011517467518581783, 'lambda_l2': 2.3014012229398686, 'num_leaves': 256, 'max_depth': 18, 'max_bin': 172, 'feature_fraction': 0.5466874619435877, 'bagging_fraction': 0.9518359992833421, 'bagging_freq': 7, 'min_child_samples': 12, 'min_data_in_leaf': 142, 'min_data_in_bin': 148, 'min_gain_to_split': 0.89}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:02:57,428] Setting status of trial#27 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.781760417261153e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:10:12,189] Finished trial#28 with value: 0.015389292527430877 with parameters: {'learning_rate': 0.0457241981893922, 'lambda_l1': 0.01994549380938392, 'lambda_l2': 0.008294212483226732, 'num_leaves': 238, 'max_depth': 20, 'max_bin': 255, 'feature_fraction': 0.686441383985279, 'bagging_fraction': 0.8942264179636222, 'bagging_freq': 7, 'min_child_samples': 38, 'min_data_in_leaf': 122, 'min_data_in_bin': 193, 'min_gain_to_split': 0.41000000000000003}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:10:34,692] Setting status of trial#29 as TrialState.PRUNED. Trial was pruned at iteration 9.\n",
      "[I 2020-06-02 02:10:50,437] Setting status of trial#30 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:11:08,113] Setting status of trial#31 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.832394767426361e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:14:01,121] Finished trial#32 with value: 0.015418958967817498 with parameters: {'learning_rate': 0.1556553665897034, 'lambda_l1': 1.415588693486073, 'lambda_l2': 2.193052244337545, 'num_leaves': 240, 'max_depth': 18, 'max_bin': 252, 'feature_fraction': 0.6036099817976659, 'bagging_fraction': 0.9552099326000861, 'bagging_freq': 6, 'min_child_samples': 44, 'min_data_in_leaf': 93, 'min_data_in_bin': 223, 'min_gain_to_split': 0.53}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:14:17,480] Setting status of trial#33 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:14:33,765] Setting status of trial#34 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:14:55,029] Setting status of trial#35 as TrialState.PRUNED. Trial was pruned at iteration 8.\n",
      "[I 2020-06-02 02:15:10,689] Setting status of trial#36 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.798750961780266e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:16:58,431] Finished trial#37 with value: 0.015403411678898023 with parameters: {'learning_rate': 0.21114305396718394, 'lambda_l1': 1.187702448122071, 'lambda_l2': 0.006498386998032238, 'num_leaves': 242, 'max_depth': 20, 'max_bin': 207, 'feature_fraction': 0.731914464956665, 'bagging_fraction': 0.9379927031218722, 'bagging_freq': 5, 'min_child_samples': 9, 'min_data_in_leaf': 236, 'min_data_in_bin': 230, 'min_gain_to_split': 0.45000000000000007}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 4.1505911648481894e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:18:15,902] Finished trial#38 with value: 0.015488495520535285 with parameters: {'learning_rate': 0.4729922606921974, 'lambda_l1': 0.0002786347797482512, 'lambda_l2': 0.007384653269999145, 'num_leaves': 124, 'max_depth': 19, 'max_bin': 140, 'feature_fraction': 0.724752846232954, 'bagging_fraction': 0.9306545202031414, 'bagging_freq': 3, 'min_child_samples': 5, 'min_data_in_leaf': 41, 'min_data_in_bin': 186, 'min_gain_to_split': 0.45000000000000007}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.930298033337437e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:19:21,380] Finished trial#39 with value: 0.015490786674630578 with parameters: {'learning_rate': 0.24735281602427597, 'lambda_l1': 5.012717813086712, 'lambda_l2': 8.840026091043762e-05, 'num_leaves': 256, 'max_depth': 20, 'max_bin': 203, 'feature_fraction': 0.6142533444446687, 'bagging_fraction': 0.6580678739105695, 'bagging_freq': 4, 'min_child_samples': 83, 'min_data_in_leaf': 223, 'min_data_in_bin': 224, 'min_gain_to_split': 1.4600000000000002}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:19:37,682] Setting status of trial#40 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.815495058332818e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:21:57,092] Finished trial#41 with value: 0.015408863182774669 with parameters: {'learning_rate': 0.12725032095450362, 'lambda_l1': 0.1861371342602372, 'lambda_l2': 0.041174362010410866, 'num_leaves': 222, 'max_depth': 20, 'max_bin': 235, 'feature_fraction': 0.8188571865109217, 'bagging_fraction': 0.9677230548819022, 'bagging_freq': 5, 'min_child_samples': 20, 'min_data_in_leaf': 196, 'min_data_in_bin': 246, 'min_gain_to_split': 0.9}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:22:14,486] Setting status of trial#42 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.795492657857734e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:25:43,481] Finished trial#43 with value: 0.01539624745365669 with parameters: {'learning_rate': 0.08507898951507449, 'lambda_l1': 0.0399269792176962, 'lambda_l2': 0.7372242161925592, 'num_leaves': 208, 'max_depth': 19, 'max_bin': 196, 'feature_fraction': 0.8719199124129706, 'bagging_fraction': 0.8826745305053596, 'bagging_freq': 5, 'min_child_samples': 47, 'min_data_in_leaf': 173, 'min_data_in_bin': 221, 'min_gain_to_split': 0.5700000000000001}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.846341356902153e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:27:18,212] Finished trial#44 with value: 0.015418037805283735 with parameters: {'learning_rate': 0.2317543561317322, 'lambda_l1': 0.019207755390180912, 'lambda_l2': 0.006600113185698534, 'num_leaves': 189, 'max_depth': 19, 'max_bin': 172, 'feature_fraction': 0.8852297492497865, 'bagging_fraction': 0.8730612212786004, 'bagging_freq': 5, 'min_child_samples': 64, 'min_data_in_leaf': 167, 'min_data_in_bin': 196, 'min_gain_to_split': 0.56}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:27:33,459] Setting status of trial#45 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:27:46,502] Setting status of trial#46 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:27:59,923] Setting status of trial#47 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.9116851091658056e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:28:49,343] Finished trial#48 with value: 0.015489036646901747 with parameters: {'learning_rate': 0.4963246544303288, 'lambda_l1': 0.040891029931649364, 'lambda_l2': 1.319423975536279, 'num_leaves': 256, 'max_depth': 18, 'max_bin': 211, 'feature_fraction': 0.9320080556562105, 'bagging_fraction': 0.9060033247001236, 'bagging_freq': 4, 'min_child_samples': 49, 'min_data_in_leaf': 190, 'min_data_in_bin': 74, 'min_gain_to_split': 2.29}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:29:03,678] Setting status of trial#49 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.878359354636423e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:30:45,460] Finished trial#50 with value: 0.015433485754932497 with parameters: {'learning_rate': 0.28454776098778667, 'lambda_l1': 0.01056298261559104, 'lambda_l2': 5.071075226538684, 'num_leaves': 225, 'max_depth': 17, 'max_bin': 201, 'feature_fraction': 0.5968443882075133, 'bagging_fraction': 0.8952048371864803, 'bagging_freq': 2, 'min_child_samples': 96, 'min_data_in_leaf': 94, 'min_data_in_bin': 202, 'min_gain_to_split': 0.5700000000000001}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:31:03,192] Setting status of trial#51 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:31:20,447] Setting status of trial#52 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:31:37,477] Setting status of trial#53 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.829028180857063e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:33:05,372] Finished trial#54 with value: 0.015422500637023544 with parameters: {'learning_rate': 0.1789709504583878, 'lambda_l1': 2.8962939570237962e-08, 'lambda_l2': 0.045325321870761985, 'num_leaves': 176, 'max_depth': 20, 'max_bin': 224, 'feature_fraction': 0.8517437212681074, 'bagging_fraction': 0.8084505667024134, 'bagging_freq': 7, 'min_child_samples': 38, 'min_data_in_leaf': 155, 'min_data_in_bin': 230, 'min_gain_to_split': 1.29}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:33:20,971] Setting status of trial#55 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:33:37,383] Setting status of trial#56 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.822971944203034e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:36:23,233] Finished trial#57 with value: 0.015415587064792968 with parameters: {'learning_rate': 0.09797454481910406, 'lambda_l1': 0.0006197922795647555, 'lambda_l2': 0.1288353614846227, 'num_leaves': 209, 'max_depth': 16, 'max_bin': 197, 'feature_fraction': 0.9074589534834223, 'bagging_fraction': 0.8853688002347412, 'bagging_freq': 5, 'min_child_samples': 46, 'min_data_in_leaf': 210, 'min_data_in_bin': 249, 'min_gain_to_split': 0.79}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:36:39,870] Setting status of trial#58 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:36:55,617] Setting status of trial#59 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:37:12,688] Setting status of trial#60 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:37:30,237] Setting status of trial#61 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:37:47,745] Setting status of trial#62 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.80517764296621e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:39:59,181] Finished trial#63 with value: 0.01540621651723402 with parameters: {'learning_rate': 0.1574596613694259, 'lambda_l1': 0.11480469032655599, 'lambda_l2': 1.63262228484109, 'num_leaves': 198, 'max_depth': 19, 'max_bin': 228, 'feature_fraction': 0.746868372881267, 'bagging_fraction': 0.9842366802485063, 'bagging_freq': 6, 'min_child_samples': 24, 'min_data_in_leaf': 184, 'min_data_in_bin': 211, 'min_gain_to_split': 0.6799999999999999}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.851670347853328e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:41:47,605] Finished trial#64 with value: 0.015434406242276424 with parameters: {'learning_rate': 0.1596533699994528, 'lambda_l1': 0.11153099521470575, 'lambda_l2': 1.9787817305461968, 'num_leaves': 192, 'max_depth': 19, 'max_bin': 230, 'feature_fraction': 0.7431257196739487, 'bagging_fraction': 0.9211855090200672, 'bagging_freq': 7, 'min_child_samples': 7, 'min_data_in_leaf': 185, 'min_data_in_bin': 205, 'min_gain_to_split': 1.1700000000000002}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:42:04,974] Setting status of trial#65 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:42:18,115] Setting status of trial#66 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 4.0067722835663945e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:43:24,634] Finished trial#67 with value: 0.01546321056849383 with parameters: {'learning_rate': 0.34426969083887426, 'lambda_l1': 0.02112832941711081, 'lambda_l2': 0.01160222021185481, 'num_leaves': 233, 'max_depth': 18, 'max_bin': 192, 'feature_fraction': 0.708615058642041, 'bagging_fraction': 0.955299856074852, 'bagging_freq': 6, 'min_child_samples': 13, 'min_data_in_leaf': 151, 'min_data_in_bin': 253, 'min_gain_to_split': 0.6799999999999999}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:44:34,779] Setting status of trial#68 as TrialState.PRUNED. Trial was pruned at iteration 35.\n",
      "[I 2020-06-02 02:45:03,625] Setting status of trial#69 as TrialState.PRUNED. Trial was pruned at iteration 14.\n",
      "[I 2020-06-02 02:45:15,137] Setting status of trial#70 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.807342982568593e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:48:05,164] Finished trial#71 with value: 0.015405635209067747 with parameters: {'learning_rate': 0.11513191006484721, 'lambda_l1': 1.6084291410437908, 'lambda_l2': 1.3885775551903827, 'num_leaves': 225, 'max_depth': 17, 'max_bin': 206, 'feature_fraction': 0.8349313789400487, 'bagging_fraction': 0.9674622881083809, 'bagging_freq': 6, 'min_child_samples': 25, 'min_data_in_leaf': 220, 'min_data_in_bin': 219, 'min_gain_to_split': 0.67}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:48:22,770] Setting status of trial#72 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:49:38,645] Setting status of trial#73 as TrialState.PRUNED. Trial was pruned at iteration 52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.836754940513188e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:51:12,870] Finished trial#74 with value: 0.015424395792804222 with parameters: {'learning_rate': 0.2247112040308986, 'lambda_l1': 0.16001297107189097, 'lambda_l2': 9.124707499351938, 'num_leaves': 235, 'max_depth': 18, 'max_bin': 225, 'feature_fraction': 0.7840516801433143, 'bagging_fraction': 0.930557303247367, 'bagging_freq': 7, 'min_child_samples': 41, 'min_data_in_leaf': 122, 'min_data_in_bin': 221, 'min_gain_to_split': 0.97}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:51:28,757] Setting status of trial#75 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:51:46,027] Setting status of trial#76 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.8145427390803624e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:54:18,232] Finished trial#77 with value: 0.015413122963374057 with parameters: {'learning_rate': 0.12541977498622295, 'lambda_l1': 0.5173884097461672, 'lambda_l2': 5.65322536853033, 'num_leaves': 223, 'max_depth': 20, 'max_bin': 195, 'feature_fraction': 0.9262074481790201, 'bagging_fraction': 0.9996063497048033, 'bagging_freq': 6, 'min_child_samples': 50, 'min_data_in_leaf': 245, 'min_data_in_bin': 200, 'min_gain_to_split': 0.76}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:54:33,741] Setting status of trial#78 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:54:51,685] Setting status of trial#79 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:55:08,135] Setting status of trial#80 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:55:25,632] Setting status of trial#81 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.861621854300688e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:56:35,148] Finished trial#82 with value: 0.0154413030680098 with parameters: {'learning_rate': 0.2873302644748382, 'lambda_l1': 0.6277122219066414, 'lambda_l2': 2.45327906874064, 'num_leaves': 246, 'max_depth': 19, 'max_bin': 222, 'feature_fraction': 0.8521095653883991, 'bagging_fraction': 0.9848773458084654, 'bagging_freq': 6, 'min_child_samples': 25, 'min_data_in_leaf': 191, 'min_data_in_bin': 237, 'min_gain_to_split': 1.09}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 02:56:52,125] Setting status of trial#83 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:57:08,621] Setting status of trial#84 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:57:25,251] Setting status of trial#85 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 02:57:40,798] Setting status of trial#86 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.819268959329785e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 02:59:49,368] Finished trial#87 with value: 0.015411843278584645 with parameters: {'learning_rate': 0.2068488419075381, 'lambda_l1': 0.06675193966088065, 'lambda_l2': 0.2859598898548823, 'num_leaves': 222, 'max_depth': 16, 'max_bin': 189, 'feature_fraction': 0.5539845960358277, 'bagging_fraction': 0.9176346229850432, 'bagging_freq': 5, 'min_child_samples': 52, 'min_data_in_leaf': 187, 'min_data_in_bin': 243, 'min_gain_to_split': 0.4}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 03:00:07,508] Setting status of trial#88 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 03:00:23,561] Setting status of trial#89 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.842778876217338e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 03:01:47,946] Finished trial#90 with value: 0.015432098436929947 with parameters: {'learning_rate': 0.1536707924253036, 'lambda_l1': 0.897116978701202, 'lambda_l2': 0.11982578754403288, 'num_leaves': 214, 'max_depth': 18, 'max_bin': 237, 'feature_fraction': 0.7828452381747459, 'bagging_fraction': 0.4390561224686261, 'bagging_freq': 4, 'min_child_samples': 11, 'min_data_in_leaf': 196, 'min_data_in_bin': 220, 'min_gain_to_split': 0.66}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 03:02:05,680] Setting status of trial#91 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.818484538947872e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 03:03:12,179] Finished trial#92 with value: 0.015420511220074058 with parameters: {'learning_rate': 0.37468903202285786, 'lambda_l1': 0.41452483902705956, 'lambda_l2': 1.6532604323304667, 'num_leaves': 220, 'max_depth': 20, 'max_bin': 236, 'feature_fraction': 0.8072854524998097, 'bagging_fraction': 0.9729821342377858, 'bagging_freq': 5, 'min_child_samples': 15, 'min_data_in_leaf': 181, 'min_data_in_bin': 228, 'min_gain_to_split': 0.55}. Best is trial#10 with value: 0.015383979808111481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************RMSE error : 3.838578741934999e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-02 03:04:47,270] Finished trial#93 with value: 0.015423460315906844 with parameters: {'learning_rate': 0.20399720965433085, 'lambda_l1': 1.5573673791803873, 'lambda_l2': 0.05384106847091197, 'num_leaves': 248, 'max_depth': 19, 'max_bin': 221, 'feature_fraction': 0.820331184054927, 'bagging_fraction': 0.9514711067626433, 'bagging_freq': 5, 'min_child_samples': 24, 'min_data_in_leaf': 195, 'min_data_in_bin': 243, 'min_gain_to_split': 0.82}. Best is trial#10 with value: 0.015383979808111481.\n",
      "[I 2020-06-02 03:05:04,667] Setting status of trial#94 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 03:05:20,473] Setting status of trial#95 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 03:05:37,543] Setting status of trial#96 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 03:05:51,665] Setting status of trial#97 as TrialState.PRUNED. Trial was pruned at iteration 6.\n",
      "[I 2020-06-02 03:07:08,561] Setting status of trial#98 as TrialState.PRUNED. Trial was pruned at iteration 45.\n",
      "[I 2020-06-02 03:07:25,610] Setting status of trial#99 as TrialState.PRUNED. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed (seconds): 16547.0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"minimize\")\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "end_time = time.time()\n",
    "print('time elapsed (seconds):', np.round(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_bagging_freq</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_lambda_l1</th>\n",
       "      <th>params_lambda_l2</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_bin</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_samples</th>\n",
       "      <th>params_min_data_in_bin</th>\n",
       "      <th>params_min_data_in_leaf</th>\n",
       "      <th>params_min_gain_to_split</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>2020-06-01 22:31:38.489494</td>\n",
       "      <td>2020-06-01 23:07:07.631807</td>\n",
       "      <td>00:35:29.142313</td>\n",
       "      <td>0.848215</td>\n",
       "      <td>4</td>\n",
       "      <td>0.900870</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>2.308042e-02</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>73</td>\n",
       "      <td>243</td>\n",
       "      <td>40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>184</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>2020-06-01 23:07:07.638626</td>\n",
       "      <td>2020-06-01 23:31:47.402641</td>\n",
       "      <td>00:24:39.764015</td>\n",
       "      <td>0.529713</td>\n",
       "      <td>5</td>\n",
       "      <td>0.756397</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>3.478946e-03</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>209</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>216</td>\n",
       "      <td>2.66</td>\n",
       "      <td>91</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>2020-06-01 23:31:47.409976</td>\n",
       "      <td>2020-06-01 23:58:59.552106</td>\n",
       "      <td>00:27:12.142130</td>\n",
       "      <td>0.501597</td>\n",
       "      <td>2</td>\n",
       "      <td>0.912209</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>1.652001e-06</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>107</td>\n",
       "      <td>249</td>\n",
       "      <td>4.68</td>\n",
       "      <td>152</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.015496</td>\n",
       "      <td>2020-06-01 23:58:59.559132</td>\n",
       "      <td>2020-06-02 00:08:46.235572</td>\n",
       "      <td>00:09:46.676440</td>\n",
       "      <td>0.533139</td>\n",
       "      <td>4</td>\n",
       "      <td>0.722108</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>8.580299e-07</td>\n",
       "      <td>0.014742</td>\n",
       "      <td>153</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>47</td>\n",
       "      <td>72</td>\n",
       "      <td>3.48</td>\n",
       "      <td>77</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>2020-06-02 00:08:46.241261</td>\n",
       "      <td>2020-06-02 00:27:39.287737</td>\n",
       "      <td>00:18:53.046476</td>\n",
       "      <td>0.936746</td>\n",
       "      <td>5</td>\n",
       "      <td>0.653945</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>2.271831e-02</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>243</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>2020-06-02 03:05:04.802595</td>\n",
       "      <td>2020-06-02 03:05:20.485138</td>\n",
       "      <td>00:00:15.682543</td>\n",
       "      <td>0.880665</td>\n",
       "      <td>6</td>\n",
       "      <td>0.764518</td>\n",
       "      <td>0.118984</td>\n",
       "      <td>1.919324e-02</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>197</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>202</td>\n",
       "      <td>9</td>\n",
       "      <td>0.51</td>\n",
       "      <td>207</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.015594</td>\n",
       "      <td>2020-06-02 03:05:20.597711</td>\n",
       "      <td>2020-06-02 03:05:37.554587</td>\n",
       "      <td>00:00:16.956876</td>\n",
       "      <td>0.927105</td>\n",
       "      <td>6</td>\n",
       "      <td>0.715608</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>2.749057e+00</td>\n",
       "      <td>0.131415</td>\n",
       "      <td>252</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>239</td>\n",
       "      <td>188</td>\n",
       "      <td>1.70</td>\n",
       "      <td>244</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.015721</td>\n",
       "      <td>2020-06-02 03:05:37.674057</td>\n",
       "      <td>2020-06-02 03:05:51.676250</td>\n",
       "      <td>00:00:14.002193</td>\n",
       "      <td>0.708084</td>\n",
       "      <td>7</td>\n",
       "      <td>0.631256</td>\n",
       "      <td>0.073784</td>\n",
       "      <td>3.389232e-02</td>\n",
       "      <td>0.083678</td>\n",
       "      <td>215</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>1.05</td>\n",
       "      <td>212</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>2020-06-02 03:05:51.795286</td>\n",
       "      <td>2020-06-02 03:07:08.572390</td>\n",
       "      <td>00:01:16.777104</td>\n",
       "      <td>0.962641</td>\n",
       "      <td>5</td>\n",
       "      <td>0.914607</td>\n",
       "      <td>0.551033</td>\n",
       "      <td>1.099971e-03</td>\n",
       "      <td>0.265402</td>\n",
       "      <td>226</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>232</td>\n",
       "      <td>167</td>\n",
       "      <td>0.68</td>\n",
       "      <td>228</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>2020-06-02 03:07:08.701901</td>\n",
       "      <td>2020-06-02 03:07:25.620048</td>\n",
       "      <td>00:00:16.918147</td>\n",
       "      <td>0.980774</td>\n",
       "      <td>4</td>\n",
       "      <td>0.884719</td>\n",
       "      <td>7.726006</td>\n",
       "      <td>6.563593e-01</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>240</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>157</td>\n",
       "      <td>0.11</td>\n",
       "      <td>194</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.016235 2020-06-01 22:31:38.489494 2020-06-01 23:07:07.631807   \n",
       "1        1  0.016246 2020-06-01 23:07:07.638626 2020-06-01 23:31:47.402641   \n",
       "2        2  0.015835 2020-06-01 23:31:47.409976 2020-06-01 23:58:59.552106   \n",
       "3        3  0.015496 2020-06-01 23:58:59.559132 2020-06-02 00:08:46.235572   \n",
       "4        4  0.016029 2020-06-02 00:08:46.241261 2020-06-02 00:27:39.287737   \n",
       "..     ...       ...                        ...                        ...   \n",
       "95      95  0.015953 2020-06-02 03:05:04.802595 2020-06-02 03:05:20.485138   \n",
       "96      96  0.015594 2020-06-02 03:05:20.597711 2020-06-02 03:05:37.554587   \n",
       "97      97  0.015721 2020-06-02 03:05:37.674057 2020-06-02 03:05:51.676250   \n",
       "98      98  0.015441 2020-06-02 03:05:51.795286 2020-06-02 03:07:08.572390   \n",
       "99      99  0.016086 2020-06-02 03:07:08.701901 2020-06-02 03:07:25.620048   \n",
       "\n",
       "          duration  params_bagging_fraction  params_bagging_freq  \\\n",
       "0  00:35:29.142313                 0.848215                    4   \n",
       "1  00:24:39.764015                 0.529713                    5   \n",
       "2  00:27:12.142130                 0.501597                    2   \n",
       "3  00:09:46.676440                 0.533139                    4   \n",
       "4  00:18:53.046476                 0.936746                    5   \n",
       "..             ...                      ...                  ...   \n",
       "95 00:00:15.682543                 0.880665                    6   \n",
       "96 00:00:16.956876                 0.927105                    6   \n",
       "97 00:00:14.002193                 0.708084                    7   \n",
       "98 00:01:16.777104                 0.962641                    5   \n",
       "99 00:00:16.918147                 0.980774                    4   \n",
       "\n",
       "    params_feature_fraction  params_lambda_l1  params_lambda_l2  \\\n",
       "0                  0.900870          0.000093      2.308042e-02   \n",
       "1                  0.756397          0.000081      3.478946e-03   \n",
       "2                  0.912209          0.000135      1.652001e-06   \n",
       "3                  0.722108          0.001024      8.580299e-07   \n",
       "4                  0.653945          0.000275      2.271831e-02   \n",
       "..                      ...               ...               ...   \n",
       "95                 0.764518          0.118984      1.919324e-02   \n",
       "96                 0.715608          0.032600      2.749057e+00   \n",
       "97                 0.631256          0.073784      3.389232e-02   \n",
       "98                 0.914607          0.551033      1.099971e-03   \n",
       "99                 0.884719          7.726006      6.563593e-01   \n",
       "\n",
       "    params_learning_rate  params_max_bin  params_max_depth  \\\n",
       "0               0.000008              41                10   \n",
       "1               0.000003             209                15   \n",
       "2               0.000370             140                15   \n",
       "3               0.014742             153                13   \n",
       "4               0.000369             189                 2   \n",
       "..                   ...             ...               ...   \n",
       "95              0.027657             197                19   \n",
       "96              0.131415             252                20   \n",
       "97              0.083678             215                18   \n",
       "98              0.265402             226                17   \n",
       "99              0.013422             240                18   \n",
       "\n",
       "    params_min_child_samples  params_min_data_in_bin  params_min_data_in_leaf  \\\n",
       "0                         73                     243                       40   \n",
       "1                         39                      16                      216   \n",
       "2                         80                     107                      249   \n",
       "3                         85                      47                       72   \n",
       "4                         60                      21                        9   \n",
       "..                       ...                     ...                      ...   \n",
       "95                        19                     202                        9   \n",
       "96                        22                     239                      188   \n",
       "97                         5                     207                      209   \n",
       "98                        25                     232                      167   \n",
       "99                        31                      28                      157   \n",
       "\n",
       "    params_min_gain_to_split  params_num_leaves     state  \n",
       "0                       2.42                184  COMPLETE  \n",
       "1                       2.66                 91  COMPLETE  \n",
       "2                       4.68                152  COMPLETE  \n",
       "3                       3.48                 77  COMPLETE  \n",
       "4                       0.32                243  COMPLETE  \n",
       "..                       ...                ...       ...  \n",
       "95                      0.51                207    PRUNED  \n",
       "96                      1.70                244    PRUNED  \n",
       "97                      1.05                212    PRUNED  \n",
       "98                      0.68                228    PRUNED  \n",
       "99                      0.11                194    PRUNED  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.015383979808111481, params {'learning_rate': 0.04672556449915609, 'lambda_l1': 0.19223541123883978, 'lambda_l2': 7.505821327156282, 'num_leaves': 256, 'max_depth': 20, 'max_bin': 238, 'feature_fraction': 0.5963624737736998, 'bagging_fraction': 0.985375832323254, 'bagging_freq': 7, 'min_child_samples': 6, 'min_data_in_leaf': 181, 'min_data_in_bin': 196, 'min_gain_to_split': 0.14}\n"
     ]
    }
   ],
   "source": [
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          10,
          11,
          12,
          13,
          17,
          19,
          21,
          22,
          24,
          26,
          28,
          32,
          37,
          38,
          39,
          41,
          43,
          44,
          48,
          50,
          54,
          57,
          63,
          64,
          67,
          71,
          74,
          77,
          82,
          87,
          90,
          92,
          93
         ],
         "y": [
          0.01623548803451911,
          0.01624648112671596,
          0.015834702682442976,
          0.015495801247978894,
          0.016028751498046393,
          0.015548282856623076,
          0.015430696058407457,
          0.015383979808111481,
          0.015395464888510147,
          0.015463387600816078,
          0.015456346889230609,
          0.015407887056659046,
          0.01550235238160056,
          0.015407976129835079,
          0.015420443697624681,
          0.015459297128262968,
          0.015431479710881798,
          0.015389292527430877,
          0.015418958967817498,
          0.015403411678898023,
          0.015488495520535285,
          0.015490786674630578,
          0.015408863182774669,
          0.01539624745365669,
          0.015418037805283735,
          0.015489036646901747,
          0.015433485754932497,
          0.015422500637023544,
          0.015415587064792968,
          0.01540621651723402,
          0.015434406242276424,
          0.01546321056849383,
          0.015405635209067747,
          0.015424395792804222,
          0.015413122963374057,
          0.0154413030680098,
          0.015411843278584645,
          0.015432098436929947,
          0.015420511220074058,
          0.015423460315906844
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          10,
          11,
          12,
          13,
          17,
          19,
          21,
          22,
          24,
          26,
          28,
          32,
          37,
          38,
          39,
          41,
          43,
          44,
          48,
          50,
          54,
          57,
          63,
          64,
          67,
          71,
          74,
          77,
          82,
          87,
          90,
          92,
          93
         ],
         "y": [
          0.01623548803451911,
          0.01623548803451911,
          0.015834702682442976,
          0.015495801247978894,
          0.015495801247978894,
          0.015495801247978894,
          0.015430696058407457,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481,
          0.015383979808111481
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "#Trials"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"8d783b41-51b5-4247-9a13-6b852b7c88f5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"8d783b41-51b5-4247-9a13-6b852b7c88f5\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '8d783b41-51b5-4247-9a13-6b852b7c88f5',\n",
       "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 17, 19, 21, 22, 24, 26, 28, 32, 37, 38, 39, 41, 43, 44, 48, 50, 54, 57, 63, 64, 67, 71, 74, 77, 82, 87, 90, 92, 93], \"y\": [0.01623548803451911, 0.01624648112671596, 0.015834702682442976, 0.015495801247978894, 0.016028751498046393, 0.015548282856623076, 0.015430696058407457, 0.015383979808111481, 0.015395464888510147, 0.015463387600816078, 0.015456346889230609, 0.015407887056659046, 0.01550235238160056, 0.015407976129835079, 0.015420443697624681, 0.015459297128262968, 0.015431479710881798, 0.015389292527430877, 0.015418958967817498, 0.015403411678898023, 0.015488495520535285, 0.015490786674630578, 0.015408863182774669, 0.01539624745365669, 0.015418037805283735, 0.015489036646901747, 0.015433485754932497, 0.015422500637023544, 0.015415587064792968, 0.01540621651723402, 0.015434406242276424, 0.01546321056849383, 0.015405635209067747, 0.015424395792804222, 0.015413122963374057, 0.0154413030680098, 0.015411843278584645, 0.015432098436929947, 0.015420511220074058, 0.015423460315906844]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 17, 19, 21, 22, 24, 26, 28, 32, 37, 38, 39, 41, 43, 44, 48, 50, 54, 57, 63, 64, 67, 71, 74, 77, 82, 87, 90, 92, 93], \"y\": [0.01623548803451911, 0.01623548803451911, 0.015834702682442976, 0.015495801247978894, 0.015495801247978894, 0.015495801247978894, 0.015430696058407457, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481, 0.015383979808111481]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8d783b41-51b5-4247-9a13-6b852b7c88f5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.015383979808111481\n",
      "  Params: \n",
      "    learning_rate: 0.04672556449915609\n",
      "    lambda_l1: 0.19223541123883978\n",
      "    lambda_l2: 7.505821327156282\n",
      "    num_leaves: 256\n",
      "    max_depth: 20\n",
      "    max_bin: 238\n",
      "    feature_fraction: 0.5963624737736998\n",
      "    bagging_fraction: 0.985375832323254\n",
      "    bagging_freq: 7\n",
      "    min_child_samples: 6\n",
      "    min_data_in_leaf: 181\n",
      "    min_data_in_bin: 196\n",
      "    min_gain_to_split: 0.14\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'cross_entropy',\n",
       " 'metric': 'cross_entropy',\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'gbdt'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"objective\": \"cross_entropy\",\n",
    "          \"metric\": \"cross_entropy\",\n",
    "          \"verbosity\": -1,\n",
    "          \"boosting_type\": \"gbdt\"}\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'cross_entropy',\n",
       " 'metric': 'cross_entropy',\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'learning_rate': 0.04672556449915609,\n",
       " 'lambda_l1': 0.19223541123883978,\n",
       " 'lambda_l2': 7.505821327156282,\n",
       " 'num_leaves': 256,\n",
       " 'max_depth': 20,\n",
       " 'max_bin': 238,\n",
       " 'feature_fraction': 0.5963624737736998,\n",
       " 'bagging_fraction': 0.985375832323254,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 6,\n",
       " 'min_data_in_leaf': 181,\n",
       " 'min_data_in_bin': 196,\n",
       " 'min_gain_to_split': 0.14}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's cross_entropy: 0.017211\tvalid_1's cross_entropy: 0.016173\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's cross_entropy: 0.0171203\tvalid_1's cross_entropy: 0.016098\n",
      "[3]\ttraining's cross_entropy: 0.0170584\tvalid_1's cross_entropy: 0.0160479\n",
      "[4]\ttraining's cross_entropy: 0.0170094\tvalid_1's cross_entropy: 0.0160109\n",
      "[5]\ttraining's cross_entropy: 0.0169501\tvalid_1's cross_entropy: 0.0159603\n",
      "[6]\ttraining's cross_entropy: 0.0168918\tvalid_1's cross_entropy: 0.0159121\n",
      "[7]\ttraining's cross_entropy: 0.0168683\tvalid_1's cross_entropy: 0.0158929\n",
      "[8]\ttraining's cross_entropy: 0.0168325\tvalid_1's cross_entropy: 0.0158642\n",
      "[9]\ttraining's cross_entropy: 0.0167889\tvalid_1's cross_entropy: 0.015826\n",
      "[10]\ttraining's cross_entropy: 0.0167575\tvalid_1's cross_entropy: 0.0157997\n",
      "[11]\ttraining's cross_entropy: 0.0167315\tvalid_1's cross_entropy: 0.0157798\n",
      "[12]\ttraining's cross_entropy: 0.0166998\tvalid_1's cross_entropy: 0.0157531\n",
      "[13]\ttraining's cross_entropy: 0.0166947\tvalid_1's cross_entropy: 0.0157489\n",
      "[14]\ttraining's cross_entropy: 0.0166731\tvalid_1's cross_entropy: 0.0157314\n",
      "[15]\ttraining's cross_entropy: 0.0166553\tvalid_1's cross_entropy: 0.0157177\n",
      "[16]\ttraining's cross_entropy: 0.0166464\tvalid_1's cross_entropy: 0.0157101\n",
      "[17]\ttraining's cross_entropy: 0.0166341\tvalid_1's cross_entropy: 0.0157\n",
      "[18]\ttraining's cross_entropy: 0.0166151\tvalid_1's cross_entropy: 0.0156843\n",
      "[19]\ttraining's cross_entropy: 0.0166069\tvalid_1's cross_entropy: 0.0156773\n",
      "[20]\ttraining's cross_entropy: 0.016597\tvalid_1's cross_entropy: 0.0156689\n",
      "[21]\ttraining's cross_entropy: 0.0165951\tvalid_1's cross_entropy: 0.0156678\n",
      "[22]\ttraining's cross_entropy: 0.0165941\tvalid_1's cross_entropy: 0.0156669\n",
      "[23]\ttraining's cross_entropy: 0.0165904\tvalid_1's cross_entropy: 0.0156638\n",
      "[24]\ttraining's cross_entropy: 0.0165688\tvalid_1's cross_entropy: 0.0156447\n",
      "[25]\ttraining's cross_entropy: 0.0165679\tvalid_1's cross_entropy: 0.0156438\n",
      "[26]\ttraining's cross_entropy: 0.0165491\tvalid_1's cross_entropy: 0.015628\n",
      "[27]\ttraining's cross_entropy: 0.0165352\tvalid_1's cross_entropy: 0.0156169\n",
      "[28]\ttraining's cross_entropy: 0.016529\tvalid_1's cross_entropy: 0.0156112\n",
      "[29]\ttraining's cross_entropy: 0.0165238\tvalid_1's cross_entropy: 0.0156068\n",
      "[30]\ttraining's cross_entropy: 0.0165081\tvalid_1's cross_entropy: 0.015594\n",
      "[31]\ttraining's cross_entropy: 0.0164939\tvalid_1's cross_entropy: 0.0155827\n",
      "[32]\ttraining's cross_entropy: 0.0164811\tvalid_1's cross_entropy: 0.0155728\n",
      "[33]\ttraining's cross_entropy: 0.0164729\tvalid_1's cross_entropy: 0.0155664\n",
      "[34]\ttraining's cross_entropy: 0.0164624\tvalid_1's cross_entropy: 0.0155581\n",
      "[35]\ttraining's cross_entropy: 0.016452\tvalid_1's cross_entropy: 0.01555\n",
      "[36]\ttraining's cross_entropy: 0.0164484\tvalid_1's cross_entropy: 0.0155471\n",
      "[37]\ttraining's cross_entropy: 0.0164378\tvalid_1's cross_entropy: 0.0155389\n",
      "[38]\ttraining's cross_entropy: 0.0164302\tvalid_1's cross_entropy: 0.0155328\n",
      "[39]\ttraining's cross_entropy: 0.0164239\tvalid_1's cross_entropy: 0.0155277\n",
      "[40]\ttraining's cross_entropy: 0.0164224\tvalid_1's cross_entropy: 0.0155263\n",
      "[41]\ttraining's cross_entropy: 0.0164136\tvalid_1's cross_entropy: 0.0155193\n",
      "[42]\ttraining's cross_entropy: 0.0164114\tvalid_1's cross_entropy: 0.0155175\n",
      "[43]\ttraining's cross_entropy: 0.0164085\tvalid_1's cross_entropy: 0.0155149\n",
      "[44]\ttraining's cross_entropy: 0.0164071\tvalid_1's cross_entropy: 0.0155135\n",
      "[45]\ttraining's cross_entropy: 0.0163996\tvalid_1's cross_entropy: 0.0155081\n",
      "[46]\ttraining's cross_entropy: 0.0163947\tvalid_1's cross_entropy: 0.0155047\n",
      "[47]\ttraining's cross_entropy: 0.0163935\tvalid_1's cross_entropy: 0.0155034\n",
      "[48]\ttraining's cross_entropy: 0.0163922\tvalid_1's cross_entropy: 0.0155023\n",
      "[49]\ttraining's cross_entropy: 0.0163877\tvalid_1's cross_entropy: 0.0154991\n",
      "[50]\ttraining's cross_entropy: 0.0163873\tvalid_1's cross_entropy: 0.015499\n",
      "[51]\ttraining's cross_entropy: 0.0163854\tvalid_1's cross_entropy: 0.0154977\n",
      "[52]\ttraining's cross_entropy: 0.0163852\tvalid_1's cross_entropy: 0.0154976\n",
      "[53]\ttraining's cross_entropy: 0.0163835\tvalid_1's cross_entropy: 0.0154963\n",
      "[54]\ttraining's cross_entropy: 0.0163834\tvalid_1's cross_entropy: 0.0154962\n",
      "[55]\ttraining's cross_entropy: 0.0163774\tvalid_1's cross_entropy: 0.0154918\n",
      "[56]\ttraining's cross_entropy: 0.0163773\tvalid_1's cross_entropy: 0.0154917\n",
      "[57]\ttraining's cross_entropy: 0.0163773\tvalid_1's cross_entropy: 0.0154916\n",
      "[58]\ttraining's cross_entropy: 0.0163761\tvalid_1's cross_entropy: 0.0154906\n",
      "[59]\ttraining's cross_entropy: 0.0163705\tvalid_1's cross_entropy: 0.0154866\n",
      "[60]\ttraining's cross_entropy: 0.0163704\tvalid_1's cross_entropy: 0.0154865\n",
      "[61]\ttraining's cross_entropy: 0.0163656\tvalid_1's cross_entropy: 0.0154826\n",
      "[62]\ttraining's cross_entropy: 0.0163618\tvalid_1's cross_entropy: 0.0154799\n",
      "[63]\ttraining's cross_entropy: 0.0163616\tvalid_1's cross_entropy: 0.0154799\n",
      "[64]\ttraining's cross_entropy: 0.0163608\tvalid_1's cross_entropy: 0.0154793\n",
      "[65]\ttraining's cross_entropy: 0.0163576\tvalid_1's cross_entropy: 0.0154771\n",
      "[66]\ttraining's cross_entropy: 0.0163529\tvalid_1's cross_entropy: 0.0154741\n",
      "[67]\ttraining's cross_entropy: 0.01635\tvalid_1's cross_entropy: 0.0154718\n",
      "[68]\ttraining's cross_entropy: 0.0163464\tvalid_1's cross_entropy: 0.015469\n",
      "[69]\ttraining's cross_entropy: 0.0163455\tvalid_1's cross_entropy: 0.0154682\n",
      "[70]\ttraining's cross_entropy: 0.0163426\tvalid_1's cross_entropy: 0.015466\n",
      "[71]\ttraining's cross_entropy: 0.0163395\tvalid_1's cross_entropy: 0.0154634\n",
      "[72]\ttraining's cross_entropy: 0.0163355\tvalid_1's cross_entropy: 0.0154607\n",
      "[73]\ttraining's cross_entropy: 0.0163321\tvalid_1's cross_entropy: 0.0154583\n",
      "[74]\ttraining's cross_entropy: 0.0163318\tvalid_1's cross_entropy: 0.0154582\n",
      "[75]\ttraining's cross_entropy: 0.0163317\tvalid_1's cross_entropy: 0.0154582\n",
      "[76]\ttraining's cross_entropy: 0.0163294\tvalid_1's cross_entropy: 0.0154564\n",
      "[77]\ttraining's cross_entropy: 0.0163263\tvalid_1's cross_entropy: 0.0154547\n",
      "[78]\ttraining's cross_entropy: 0.0163251\tvalid_1's cross_entropy: 0.0154537\n",
      "[79]\ttraining's cross_entropy: 0.0163224\tvalid_1's cross_entropy: 0.0154524\n",
      "[80]\ttraining's cross_entropy: 0.0163191\tvalid_1's cross_entropy: 0.01545\n",
      "[81]\ttraining's cross_entropy: 0.0163164\tvalid_1's cross_entropy: 0.0154485\n",
      "[82]\ttraining's cross_entropy: 0.0163164\tvalid_1's cross_entropy: 0.0154485\n",
      "[83]\ttraining's cross_entropy: 0.0163163\tvalid_1's cross_entropy: 0.0154484\n",
      "[84]\ttraining's cross_entropy: 0.016314\tvalid_1's cross_entropy: 0.0154468\n",
      "[85]\ttraining's cross_entropy: 0.0163139\tvalid_1's cross_entropy: 0.0154467\n",
      "[86]\ttraining's cross_entropy: 0.0163139\tvalid_1's cross_entropy: 0.0154467\n",
      "[87]\ttraining's cross_entropy: 0.0163108\tvalid_1's cross_entropy: 0.0154447\n",
      "[88]\ttraining's cross_entropy: 0.01631\tvalid_1's cross_entropy: 0.0154442\n",
      "[89]\ttraining's cross_entropy: 0.0163096\tvalid_1's cross_entropy: 0.0154439\n",
      "[90]\ttraining's cross_entropy: 0.0163072\tvalid_1's cross_entropy: 0.0154421\n",
      "[91]\ttraining's cross_entropy: 0.016305\tvalid_1's cross_entropy: 0.0154406\n",
      "[92]\ttraining's cross_entropy: 0.0163034\tvalid_1's cross_entropy: 0.0154394\n",
      "[93]\ttraining's cross_entropy: 0.0163009\tvalid_1's cross_entropy: 0.0154381\n",
      "[94]\ttraining's cross_entropy: 0.016299\tvalid_1's cross_entropy: 0.015437\n",
      "[95]\ttraining's cross_entropy: 0.016298\tvalid_1's cross_entropy: 0.0154361\n",
      "[96]\ttraining's cross_entropy: 0.0162978\tvalid_1's cross_entropy: 0.0154357\n",
      "[97]\ttraining's cross_entropy: 0.016297\tvalid_1's cross_entropy: 0.0154349\n",
      "[98]\ttraining's cross_entropy: 0.0162954\tvalid_1's cross_entropy: 0.0154337\n",
      "[99]\ttraining's cross_entropy: 0.0162933\tvalid_1's cross_entropy: 0.0154328\n",
      "[100]\ttraining's cross_entropy: 0.0162914\tvalid_1's cross_entropy: 0.0154314\n",
      "[101]\ttraining's cross_entropy: 0.0162896\tvalid_1's cross_entropy: 0.0154303\n",
      "[102]\ttraining's cross_entropy: 0.0162881\tvalid_1's cross_entropy: 0.0154292\n",
      "[103]\ttraining's cross_entropy: 0.0162875\tvalid_1's cross_entropy: 0.0154286\n",
      "[104]\ttraining's cross_entropy: 0.0162851\tvalid_1's cross_entropy: 0.0154272\n",
      "[105]\ttraining's cross_entropy: 0.0162846\tvalid_1's cross_entropy: 0.015427\n",
      "[106]\ttraining's cross_entropy: 0.0162831\tvalid_1's cross_entropy: 0.015426\n",
      "[107]\ttraining's cross_entropy: 0.0162811\tvalid_1's cross_entropy: 0.0154245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108]\ttraining's cross_entropy: 0.0162807\tvalid_1's cross_entropy: 0.0154244\n",
      "[109]\ttraining's cross_entropy: 0.0162802\tvalid_1's cross_entropy: 0.0154242\n",
      "[110]\ttraining's cross_entropy: 0.0162797\tvalid_1's cross_entropy: 0.0154237\n",
      "[111]\ttraining's cross_entropy: 0.0162794\tvalid_1's cross_entropy: 0.0154235\n",
      "[112]\ttraining's cross_entropy: 0.0162776\tvalid_1's cross_entropy: 0.0154223\n",
      "[113]\ttraining's cross_entropy: 0.0162759\tvalid_1's cross_entropy: 0.0154211\n",
      "[114]\ttraining's cross_entropy: 0.0162758\tvalid_1's cross_entropy: 0.0154211\n",
      "[115]\ttraining's cross_entropy: 0.0162747\tvalid_1's cross_entropy: 0.0154207\n",
      "[116]\ttraining's cross_entropy: 0.0162734\tvalid_1's cross_entropy: 0.0154198\n",
      "[117]\ttraining's cross_entropy: 0.0162716\tvalid_1's cross_entropy: 0.0154187\n",
      "[118]\ttraining's cross_entropy: 0.0162713\tvalid_1's cross_entropy: 0.0154184\n",
      "[119]\ttraining's cross_entropy: 0.0162708\tvalid_1's cross_entropy: 0.015418\n",
      "[120]\ttraining's cross_entropy: 0.0162708\tvalid_1's cross_entropy: 0.015418\n",
      "[121]\ttraining's cross_entropy: 0.0162706\tvalid_1's cross_entropy: 0.015418\n",
      "[122]\ttraining's cross_entropy: 0.0162698\tvalid_1's cross_entropy: 0.0154174\n",
      "[123]\ttraining's cross_entropy: 0.0162679\tvalid_1's cross_entropy: 0.0154162\n",
      "[124]\ttraining's cross_entropy: 0.0162662\tvalid_1's cross_entropy: 0.0154155\n",
      "[125]\ttraining's cross_entropy: 0.0162645\tvalid_1's cross_entropy: 0.0154146\n",
      "[126]\ttraining's cross_entropy: 0.0162641\tvalid_1's cross_entropy: 0.0154146\n",
      "[127]\ttraining's cross_entropy: 0.0162631\tvalid_1's cross_entropy: 0.0154137\n",
      "[128]\ttraining's cross_entropy: 0.0162614\tvalid_1's cross_entropy: 0.015413\n",
      "[129]\ttraining's cross_entropy: 0.0162609\tvalid_1's cross_entropy: 0.0154125\n",
      "[130]\ttraining's cross_entropy: 0.0162607\tvalid_1's cross_entropy: 0.0154124\n",
      "[131]\ttraining's cross_entropy: 0.0162595\tvalid_1's cross_entropy: 0.0154117\n",
      "[132]\ttraining's cross_entropy: 0.0162593\tvalid_1's cross_entropy: 0.0154115\n",
      "[133]\ttraining's cross_entropy: 0.0162583\tvalid_1's cross_entropy: 0.015411\n",
      "[134]\ttraining's cross_entropy: 0.0162569\tvalid_1's cross_entropy: 0.0154102\n",
      "[135]\ttraining's cross_entropy: 0.0162558\tvalid_1's cross_entropy: 0.0154097\n",
      "[136]\ttraining's cross_entropy: 0.0162549\tvalid_1's cross_entropy: 0.0154088\n",
      "[137]\ttraining's cross_entropy: 0.0162542\tvalid_1's cross_entropy: 0.0154084\n",
      "[138]\ttraining's cross_entropy: 0.0162534\tvalid_1's cross_entropy: 0.0154079\n",
      "[139]\ttraining's cross_entropy: 0.0162533\tvalid_1's cross_entropy: 0.0154079\n",
      "[140]\ttraining's cross_entropy: 0.016252\tvalid_1's cross_entropy: 0.0154074\n",
      "[141]\ttraining's cross_entropy: 0.0162511\tvalid_1's cross_entropy: 0.0154071\n",
      "[142]\ttraining's cross_entropy: 0.0162503\tvalid_1's cross_entropy: 0.0154067\n",
      "[143]\ttraining's cross_entropy: 0.0162502\tvalid_1's cross_entropy: 0.0154067\n",
      "[144]\ttraining's cross_entropy: 0.0162496\tvalid_1's cross_entropy: 0.0154063\n",
      "[145]\ttraining's cross_entropy: 0.0162494\tvalid_1's cross_entropy: 0.0154061\n",
      "[146]\ttraining's cross_entropy: 0.0162493\tvalid_1's cross_entropy: 0.0154061\n",
      "[147]\ttraining's cross_entropy: 0.0162492\tvalid_1's cross_entropy: 0.015406\n",
      "[148]\ttraining's cross_entropy: 0.0162484\tvalid_1's cross_entropy: 0.0154058\n",
      "[149]\ttraining's cross_entropy: 0.0162484\tvalid_1's cross_entropy: 0.0154058\n",
      "[150]\ttraining's cross_entropy: 0.0162483\tvalid_1's cross_entropy: 0.0154059\n",
      "[151]\ttraining's cross_entropy: 0.0162483\tvalid_1's cross_entropy: 0.0154058\n",
      "[152]\ttraining's cross_entropy: 0.0162473\tvalid_1's cross_entropy: 0.0154053\n",
      "[153]\ttraining's cross_entropy: 0.0162471\tvalid_1's cross_entropy: 0.0154052\n",
      "[154]\ttraining's cross_entropy: 0.0162456\tvalid_1's cross_entropy: 0.0154045\n",
      "[155]\ttraining's cross_entropy: 0.0162455\tvalid_1's cross_entropy: 0.0154044\n",
      "[156]\ttraining's cross_entropy: 0.0162451\tvalid_1's cross_entropy: 0.0154039\n",
      "[157]\ttraining's cross_entropy: 0.0162445\tvalid_1's cross_entropy: 0.0154035\n",
      "[158]\ttraining's cross_entropy: 0.0162432\tvalid_1's cross_entropy: 0.0154029\n",
      "[159]\ttraining's cross_entropy: 0.0162432\tvalid_1's cross_entropy: 0.0154028\n",
      "[160]\ttraining's cross_entropy: 0.0162431\tvalid_1's cross_entropy: 0.0154028\n",
      "[161]\ttraining's cross_entropy: 0.0162421\tvalid_1's cross_entropy: 0.0154021\n",
      "[162]\ttraining's cross_entropy: 0.0162419\tvalid_1's cross_entropy: 0.0154019\n",
      "[163]\ttraining's cross_entropy: 0.0162419\tvalid_1's cross_entropy: 0.0154019\n",
      "[164]\ttraining's cross_entropy: 0.0162417\tvalid_1's cross_entropy: 0.0154017\n",
      "[165]\ttraining's cross_entropy: 0.0162408\tvalid_1's cross_entropy: 0.0154011\n",
      "[166]\ttraining's cross_entropy: 0.0162397\tvalid_1's cross_entropy: 0.0154005\n",
      "[167]\ttraining's cross_entropy: 0.0162389\tvalid_1's cross_entropy: 0.0154001\n",
      "[168]\ttraining's cross_entropy: 0.0162382\tvalid_1's cross_entropy: 0.0153997\n",
      "[169]\ttraining's cross_entropy: 0.0162381\tvalid_1's cross_entropy: 0.0153997\n",
      "[170]\ttraining's cross_entropy: 0.016238\tvalid_1's cross_entropy: 0.0153996\n",
      "[171]\ttraining's cross_entropy: 0.0162378\tvalid_1's cross_entropy: 0.0153995\n",
      "[172]\ttraining's cross_entropy: 0.016237\tvalid_1's cross_entropy: 0.015399\n",
      "[173]\ttraining's cross_entropy: 0.0162361\tvalid_1's cross_entropy: 0.0153985\n",
      "[174]\ttraining's cross_entropy: 0.0162357\tvalid_1's cross_entropy: 0.0153983\n",
      "[175]\ttraining's cross_entropy: 0.016235\tvalid_1's cross_entropy: 0.015398\n",
      "[176]\ttraining's cross_entropy: 0.016235\tvalid_1's cross_entropy: 0.015398\n",
      "[177]\ttraining's cross_entropy: 0.0162344\tvalid_1's cross_entropy: 0.0153977\n",
      "[178]\ttraining's cross_entropy: 0.016234\tvalid_1's cross_entropy: 0.0153974\n",
      "[179]\ttraining's cross_entropy: 0.0162339\tvalid_1's cross_entropy: 0.0153972\n",
      "[180]\ttraining's cross_entropy: 0.0162339\tvalid_1's cross_entropy: 0.0153972\n",
      "[181]\ttraining's cross_entropy: 0.0162332\tvalid_1's cross_entropy: 0.0153969\n",
      "[182]\ttraining's cross_entropy: 0.0162331\tvalid_1's cross_entropy: 0.0153969\n",
      "[183]\ttraining's cross_entropy: 0.0162322\tvalid_1's cross_entropy: 0.0153966\n",
      "[184]\ttraining's cross_entropy: 0.0162322\tvalid_1's cross_entropy: 0.0153966\n",
      "[185]\ttraining's cross_entropy: 0.0162322\tvalid_1's cross_entropy: 0.0153966\n",
      "[186]\ttraining's cross_entropy: 0.016232\tvalid_1's cross_entropy: 0.0153966\n",
      "[187]\ttraining's cross_entropy: 0.0162317\tvalid_1's cross_entropy: 0.0153965\n",
      "[188]\ttraining's cross_entropy: 0.0162311\tvalid_1's cross_entropy: 0.0153961\n",
      "[189]\ttraining's cross_entropy: 0.0162303\tvalid_1's cross_entropy: 0.0153958\n",
      "[190]\ttraining's cross_entropy: 0.0162302\tvalid_1's cross_entropy: 0.0153956\n",
      "[191]\ttraining's cross_entropy: 0.0162296\tvalid_1's cross_entropy: 0.015395\n",
      "[192]\ttraining's cross_entropy: 0.016229\tvalid_1's cross_entropy: 0.0153947\n",
      "[193]\ttraining's cross_entropy: 0.0162283\tvalid_1's cross_entropy: 0.0153943\n",
      "[194]\ttraining's cross_entropy: 0.0162273\tvalid_1's cross_entropy: 0.0153936\n",
      "[195]\ttraining's cross_entropy: 0.0162267\tvalid_1's cross_entropy: 0.0153933\n",
      "[196]\ttraining's cross_entropy: 0.0162263\tvalid_1's cross_entropy: 0.0153928\n",
      "[197]\ttraining's cross_entropy: 0.0162263\tvalid_1's cross_entropy: 0.0153928\n",
      "[198]\ttraining's cross_entropy: 0.0162263\tvalid_1's cross_entropy: 0.0153928\n",
      "[199]\ttraining's cross_entropy: 0.0162255\tvalid_1's cross_entropy: 0.0153924\n",
      "[200]\ttraining's cross_entropy: 0.0162248\tvalid_1's cross_entropy: 0.015392\n",
      "[201]\ttraining's cross_entropy: 0.0162241\tvalid_1's cross_entropy: 0.0153917\n",
      "[202]\ttraining's cross_entropy: 0.0162241\tvalid_1's cross_entropy: 0.0153917\n",
      "[203]\ttraining's cross_entropy: 0.0162234\tvalid_1's cross_entropy: 0.0153912\n",
      "[204]\ttraining's cross_entropy: 0.0162233\tvalid_1's cross_entropy: 0.0153912\n",
      "[205]\ttraining's cross_entropy: 0.0162228\tvalid_1's cross_entropy: 0.0153909\n",
      "[206]\ttraining's cross_entropy: 0.0162228\tvalid_1's cross_entropy: 0.015391\n",
      "[207]\ttraining's cross_entropy: 0.0162228\tvalid_1's cross_entropy: 0.0153909\n",
      "[208]\ttraining's cross_entropy: 0.0162222\tvalid_1's cross_entropy: 0.0153905\n",
      "[209]\ttraining's cross_entropy: 0.0162216\tvalid_1's cross_entropy: 0.0153902\n",
      "[210]\ttraining's cross_entropy: 0.0162212\tvalid_1's cross_entropy: 0.0153899\n",
      "[211]\ttraining's cross_entropy: 0.0162212\tvalid_1's cross_entropy: 0.0153899\n",
      "[212]\ttraining's cross_entropy: 0.0162208\tvalid_1's cross_entropy: 0.0153896\n",
      "[213]\ttraining's cross_entropy: 0.0162208\tvalid_1's cross_entropy: 0.0153896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214]\ttraining's cross_entropy: 0.0162206\tvalid_1's cross_entropy: 0.0153895\n",
      "[215]\ttraining's cross_entropy: 0.0162204\tvalid_1's cross_entropy: 0.0153887\n",
      "[216]\ttraining's cross_entropy: 0.0162204\tvalid_1's cross_entropy: 0.0153887\n",
      "[217]\ttraining's cross_entropy: 0.0162203\tvalid_1's cross_entropy: 0.0153881\n",
      "[218]\ttraining's cross_entropy: 0.0162199\tvalid_1's cross_entropy: 0.0153876\n",
      "[219]\ttraining's cross_entropy: 0.0162199\tvalid_1's cross_entropy: 0.0153876\n",
      "[220]\ttraining's cross_entropy: 0.0162193\tvalid_1's cross_entropy: 0.0153873\n",
      "[221]\ttraining's cross_entropy: 0.0162193\tvalid_1's cross_entropy: 0.0153873\n",
      "[222]\ttraining's cross_entropy: 0.0162189\tvalid_1's cross_entropy: 0.0153871\n",
      "[223]\ttraining's cross_entropy: 0.0162186\tvalid_1's cross_entropy: 0.015387\n",
      "[224]\ttraining's cross_entropy: 0.0162182\tvalid_1's cross_entropy: 0.015387\n",
      "[225]\ttraining's cross_entropy: 0.0162181\tvalid_1's cross_entropy: 0.0153869\n",
      "[226]\ttraining's cross_entropy: 0.0162181\tvalid_1's cross_entropy: 0.0153869\n",
      "[227]\ttraining's cross_entropy: 0.0162181\tvalid_1's cross_entropy: 0.0153869\n",
      "[228]\ttraining's cross_entropy: 0.0162177\tvalid_1's cross_entropy: 0.0153866\n",
      "[229]\ttraining's cross_entropy: 0.0162177\tvalid_1's cross_entropy: 0.0153866\n",
      "[230]\ttraining's cross_entropy: 0.0162175\tvalid_1's cross_entropy: 0.0153864\n",
      "[231]\ttraining's cross_entropy: 0.0162175\tvalid_1's cross_entropy: 0.0153864\n",
      "[232]\ttraining's cross_entropy: 0.0162169\tvalid_1's cross_entropy: 0.0153861\n",
      "[233]\ttraining's cross_entropy: 0.0162169\tvalid_1's cross_entropy: 0.0153861\n",
      "[234]\ttraining's cross_entropy: 0.0162168\tvalid_1's cross_entropy: 0.0153861\n",
      "[235]\ttraining's cross_entropy: 0.0162164\tvalid_1's cross_entropy: 0.0153858\n",
      "[236]\ttraining's cross_entropy: 0.0162164\tvalid_1's cross_entropy: 0.0153858\n",
      "[237]\ttraining's cross_entropy: 0.0162164\tvalid_1's cross_entropy: 0.0153858\n",
      "[238]\ttraining's cross_entropy: 0.0162164\tvalid_1's cross_entropy: 0.0153858\n",
      "[239]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[240]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[241]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[242]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[243]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[244]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[245]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[246]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[247]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[248]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[249]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153856\n",
      "[250]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153855\n",
      "[251]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153855\n",
      "[252]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153855\n",
      "[253]\ttraining's cross_entropy: 0.0162159\tvalid_1's cross_entropy: 0.0153855\n",
      "[254]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[255]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[256]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[257]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[258]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[259]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[260]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[261]\ttraining's cross_entropy: 0.0162153\tvalid_1's cross_entropy: 0.0153849\n",
      "[262]\ttraining's cross_entropy: 0.0162149\tvalid_1's cross_entropy: 0.0153846\n",
      "[263]\ttraining's cross_entropy: 0.0162149\tvalid_1's cross_entropy: 0.0153847\n",
      "[264]\ttraining's cross_entropy: 0.0162149\tvalid_1's cross_entropy: 0.0153846\n",
      "[265]\ttraining's cross_entropy: 0.0162149\tvalid_1's cross_entropy: 0.0153847\n",
      "[266]\ttraining's cross_entropy: 0.0162149\tvalid_1's cross_entropy: 0.0153847\n",
      "[267]\ttraining's cross_entropy: 0.0162149\tvalid_1's cross_entropy: 0.0153847\n",
      "[268]\ttraining's cross_entropy: 0.0162149\tvalid_1's cross_entropy: 0.0153847\n",
      "[269]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[270]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[271]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[272]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[273]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[274]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[275]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[276]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[277]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[278]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[279]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[280]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[281]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[282]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[283]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[284]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[285]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[286]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[287]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[288]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[289]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[290]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[291]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[292]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[293]\ttraining's cross_entropy: 0.0162145\tvalid_1's cross_entropy: 0.0153845\n",
      "[294]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[295]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[296]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[297]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[298]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[299]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[300]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[301]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[302]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[303]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[304]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[305]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[306]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[307]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[308]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[309]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[310]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[311]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[312]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[313]\ttraining's cross_entropy: 0.0162144\tvalid_1's cross_entropy: 0.0153845\n",
      "[314]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.0153841\n",
      "[315]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[316]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[317]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[318]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[319]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[321]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[322]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[323]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[324]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[325]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[326]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[327]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[328]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[329]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[330]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[331]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[332]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[333]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[334]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[335]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[336]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[337]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[338]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[339]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[340]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[341]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[342]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[343]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[344]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[345]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[346]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[347]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[348]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[349]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[350]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[351]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[352]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[353]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[354]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[355]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[356]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[357]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[358]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[359]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[360]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[361]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[362]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[363]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[364]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[365]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[366]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[367]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[368]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[369]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[370]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[371]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[372]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[373]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[374]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[375]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[376]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[377]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[378]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[379]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[380]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[381]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[382]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[383]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[384]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[385]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[386]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[387]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[388]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[389]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[390]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[391]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[392]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[393]\ttraining's cross_entropy: 0.0162139\tvalid_1's cross_entropy: 0.015384\n",
      "[394]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[395]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[396]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[397]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[398]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[399]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[400]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[401]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[402]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[403]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[404]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[405]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[406]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[407]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[408]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[409]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[410]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[411]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[412]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[413]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[414]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[415]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[416]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[417]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[418]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "[419]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's cross_entropy: 0.0162138\tvalid_1's cross_entropy: 0.015384\n",
      "time elapsed (seconds): 743.0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "watchlist = [dtrain, dval]\n",
    "\n",
    "\n",
    "#training lightgbm \n",
    "model = lgb.train(params = params,\n",
    "                train_set = dtrain,\n",
    "                valid_sets = watchlist,\n",
    "                early_stopping_rounds=20,\n",
    "                num_boost_round=1000)\n",
    "\n",
    "end_time = time.time()\n",
    "print('time elapsed (seconds):', np.round(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'cross_entropy',\n",
       " 'metric': 'cross_entropy',\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'learning_rate': 0.04672556449915609,\n",
       " 'lambda_l1': 0.19223541123883978,\n",
       " 'lambda_l2': 7.505821327156282,\n",
       " 'num_leaves': 256,\n",
       " 'max_depth': 20,\n",
       " 'max_bin': 238,\n",
       " 'feature_fraction': 0.5963624737736998,\n",
       " 'bagging_fraction': 0.985375832323254,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 6,\n",
       " 'min_data_in_leaf': 181,\n",
       " 'min_data_in_bin': 196,\n",
       " 'min_gain_to_split': 0.14}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.006156780165223041\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(df_test)\n",
    "error = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"error:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, name, study, df_results, model, df_train, df_test, df_validation):\n",
    "        self.name = name\n",
    "        self.study = study\n",
    "        self.df_study = df_results\n",
    "        self.params = study.best_trial.params\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test \n",
    "        self.df_validation = df_validation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/interim/trained_model.pkl', 'wb') as output:\n",
    "    model1 = Model('LightGBM_bayesopt', study, study.trials_dataframe(), model, df_train, df_test, df_validation)\n",
    "    pickle.dump(model1, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa8711f2940>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAD1CAYAAACP+vgcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt0nPV95/H3dy66WB5kWwgMFjZ2IhpIYbcOgbQkhTYXIIGQ3UBDknZDl3JCNiTnpHspnNKUpm5DsnuabQsn9JC09JYlgd0SCDY+pSQkUCAYJyE1NxkbGxnbyLItj+7S6Ld/zIw0l+eZeUYaPXP7vM7xOXN5Rvo+M/Lznd/t+zPnHCIiImGK1DoAERFpPUo+IiISOiUfEREJnZKPiIiETslHRERCF6t1ACMjI5puJyLS5Lq7uy33vlo+IiISOiUfEREJXdMmn4GBgVqHsCSNHj80/jk0evzQ+OfQ6PFD45/DcsXftMlHRETql5KPiIiETslHRERCp+QjIiKhU/IREZHQKfmIiEjolHxERCR0Sj4iIhI6JR8REQmdko+IiIROyUdEREKn5CMiIqFT8hERkdAp+YiISOiUfEREJHRKPiIiEjolHxERCZ2Sj4iIhE7JR0REQqfkIyIioVPyERGR0Cn5iIhI6JR8REQkdEo+IiISOiUfEREJnZKPiIiETslHRERCFyj5mNllZvayme02s5s9nm83s29nnn/GzM7Mee48M3vKzHaZ2c/NrKN64YuISCMqm3zMLArcCVwOnAN83MzOKTjseuCYc+6twNeAr2ReGwP+AbjROfd24BJgpmrRi4hIQwrS8rkA2O2c2+OcmwbuBa4qOOYq4G8zt+8H3mtmBnwAeN459zMA59ywcy5VndBFRKRRmXOu9AFmVwOXOed+J3P/t4ALnXM35Rzzb5ljBjP3XwUuBH4TeAdwCtAL3Ouc+2ruzx8ZGZkPYGBgoBrnJCIidaC/v3/+dnd3t+U+FwvwevN4rDBj+R0TA94NvBMYB/7FzJ5zzv1LuUCXamBgoKo/L2yNHj80/jk0evzQ+OfQ6PFD45/DcsUfpNttEDgj534f8IbfMZlxnm7gaObxx51zR5xz48BWYPNSgxYRkcYWJPk8C/Sb2UYzawOuBR4sOOZB4FOZ21cDj7l0f9524DwzW5FJShcDL1QndBERaVRlu92cc7NmdhPpRBIF/to5t8vMvgTscM49CHwT+Hsz2026xXNt5rXHzOzPSCcwB2x1zj28TOciIiINIsiYD865raS7zHIf+2LO7UngGp/X/gPp6dYiIiJAwOTTDPYlZ9iyM8nB8RSnrYhy6+YEGxLxWodVt/R+ichyarrkk71ovnC4neRPD3FKZ4RTOiI8PzzN4PjCJL0dQ9M8cGmPLqge9iVn+Mj2YfYmF5ZkPXV4inNXx0nOuoqSkZKYiHhpquSTf9GMAin2j3qvad2bTLFlZ5K7L16jC2SBLTuTeYkHYHBsjsGxqfn7Tx2a5LyeNk7M+CejAxPGFwqSmJK+iECTJR+vi2Yph8ZTnt/yW/0CeXC8/Hs4OO4YHF9IRl7v2V37Y0WfR27SF5HW1VRVrYNcNHOtXRH1TFjZC2SrOm1FtOLXeL1nQ1Pef16HKvycRKT5NFXyqeSiuTGR7iryS1itfIG8dXOCjYnKE1Dhe9bbPud53NpFJDcRaS5N1e126+YEO4amPbve+roinLs6zuisY23OGIVfwmrlC+SGRJwHLu1hy84kh8ZTJOJWNGHDS+F7duP6WV6e7Mj7PLJJX0RaW1Mln9yL5gtvjpKkjVM7I5yZiPlOIvBKWLpApt/L3HGZ7KSMQ+MpVsaMnx+bYXBsoWXj9Z6t63R5SWytJnOISEZTJR9YuGgODAzT378+0PG6QJZXKhmVes8KXyciAk2YfBZDF8jK6T0TkaVoqgkHIiLSGJR8REQkdC3R7aYKBuEofJ8/udpo3C20RGQ5NX3y8apgsHX/JGevjrGxxCy4RlIPydWzHlxHOw9vnGn491dEqq/pk49XBYOxWceOoZnMv8YupVMv5YE868FNRlRKR0Q8Nf2YT7mSO41eSqdeygOpUoSIVKLpk0+QkjuNfIGsl4u+KkWISCWaPvkEqVPWyBfIernoe73PfR1zVa8UsS85ww2PH+WKbUPc8PhR9iVnqvrzRSQcTT/mk1vB4MWjU+w6PkduhbKYwXVnddYsvqWql/JAXpUiPrn6aFXHneplfEtElq7pWz6wsBr/7DXtFJbGnHVwzysTNYmrGrIX/Ws2dfKetW1cs6mzZhfj7Pv80OW93H3xGtZ1li5EWql6Gd8SkaVr+pZPrnoZH6m2Vil106yfn0graomWT1a9jI/I4ujzE2keLZV8vAbFtX1C49DnJ9I8WqrbTdsnNDZ9fiLNo6WSD7TO+Eiz0ucn0hxaqttNRETqg5KPiIiETslHRERCp+QjIiKhU/IREZHQKfmIiEjolHxERCR0Sj4iIhI6JR8REQmdko+IiIROyUdEREKn5CMiIqFT8hERkdAFSj5mdpmZvWxmu83sZo/n283s25nnnzGzMwueX29mo2b236oTtoiINLKyycfMosCdwOXAOcDHzeycgsOuB445594KfA34SsHzXwO2LT1cERFpBkH287kA2O2c2wNgZvcCVwEv5BxzFXBb5vb9wB1mZs45Z2YfAfYAY1WLehH2JWfYsjPJwfEUpzXgJmSNHr+ISK4gyWcd8HrO/UHgQr9jnHOzZjYC9JjZBPB7wPuBmnW57UvO8JHtw+xNpuYf+96+CTqjRjRinH9ynNvf1V23F3Ov+HcMTfPApT3LGvOTByf4zBMjHJ+aY1V7hK+/u5uLTutctt8nIq3DnHOlDzC7BrjUOfc7mfu/BVzgnPtczjG7MscMZu6/SrrFdAvwY+fcd8zsNmDUOfe/cn/+yMjIfAADAwNVOalCf/BynEeGSl+kT22b46/OnQLgrv0xhqYi9LbPceP6WdZ1ln6Plptf/Jf1zvDHvzCzLL/zuWMRPrurnRQ2/1gUx21vneLJkWhdvT8iUp/6+/vnb3d3d1vuc0FaPoPAGTn3+4A3fI4ZNLMY0A0cJd1CutrMvgqsAubMbNI5d0e5QJdqYGCA/v5+9iVneG7HEWCu5PGHpyP81eFVvDQym9PCiPLyZMeytzC8ZOMHGN09BEwXHTMW7aK/vzfwz6yk6+6qbx8kVfCepTBue7WD1HyuKf3+5J5DI2r0+KHxz6HR44fGP4flij/IbLdngX4z22hmbcC1wIMFxzwIfCpz+2rgMZf2Hufcmc65M4H/DfypX+JZDtnuqqHJ0okna8eRmbyuLYC9yRRbdiaXI7zATlsR9Xx8rc/jXrLvxX17Jnji0DT37ZngI9uH2Zf0bjm9OeH9nqUKGjn18P6ISOMpm3ycc7PATcB24EXgO865XWb2JTP7cOawb5Ie49kN/C5QNB27FrbsTBYlk9K8u48OjVfyM6rv1s0JNibyE83GRLrlEpTXe1EqcUTN82FPtX5/RKTxBOl2wzm3Fdha8NgXc25PAteU+Rm3LSK+JTlYwUWxb4VxXk8bW1+fKnqukhbGctiQiPPApT1s2Znk0HiKtYuY7eb3Xvgljnf1xnn8cLDxpFq/PyLSeAIln0bl112V66Q4XHRqO7e/qxuAF4/nzyqrtIWxXDYk4tx98ZpFv77Srru/eM9qfv27bzJckH+ilt/1Vi/vj4g0lqZMPvuSM/zBy3GG3AydUZgo0QC69IzOvIv6UlsYtVA4keC6szq555WJvIkFt25OsGNoOnBi3ZCIc+Ha9qKWYMrB+pVRNqyMNsz7IyL1p+mSz8KamDgwW/b4wm6npbYwwua1Buif9k4wm9M6ya4JqjSxnpjxHgPbsDLKQ5cHn2UnIlKo6ZJPpZMMGn28wut8Z31mpN198ZqKEms1ZtmJiHhpuuRT0SSDrgij03NcsW2oYUvWBD1fr4kF5db9VNpVV+jAhPHVx4+qJJCIFGm65BNkkkFvh/HO3jaeH55m2+DCmEYYJWuqLcj5AuwbTeUlWaBsyZ6lzLLbl5zhpl3tDE5O+P58EWldTbefz3VndRIrsUalMwqPXtFLVzzC4Hh+/1SpdS/7kjPc8PhRrtg2xA2PH/VdnBk2rzVAhecfM9g/mspbXHrz0yOB1v1kx8AeuryXuy9eEzhxbNmZZHAy/89LC1JFJKvpWj73vDJRNOaRazazcL+SdS+1KuwZZBabV+ske9yh8RT7RlPsHy1OMqM+kwmqtWC00nVFItJami75/PTIZMnnZxzc/PRIRYPppaoDLGVmXKkxlwMTxhcCzmLzmqGXrT59xbahouST5p18cs9/Kds4aLKCiJTSVMnn/76aZOBE+QrL/3xgiveva6evK8Lg2EINM7/B9FLf4iu9QO9LznDLMyM8dXiKken8cqe5yeSu/bGKZrH58UsC7+xt48Xjs76TCZba2rt1c4Kn3hjL63rTglQppH2qWldTJZ8bf3Qi0HGzDrYNTtG3wvjgGe0kZ5zvYPq+5IxPywEScavoAr0vOcOHth3JS3i59iZT3PLMCF3xCE8cDfbRlOvG8pux9uUL0xUdvCYT7EvOcOUjw57ddUFbexsSce54+xT/eGxNQy3YlfDUqjtb6kNTJR+fYQxfg+OOX14b4Vvv876YZv9zeCWfjYkozuHbHXfr5kTRN7otO5O+iSfrsQNTpItwB6vsWa4bq9yMtcJEUuqcobIxm3WdjrvPa5wFuxKu5erOlsbQVMlnMfwupn7f/gFWxIyuGDz2RnERUoC9J4q/0f2/vRNsXFk+nlK7P8Qsv+staDdWJVUbyi3S1ZiNVIsmpbS2lk8+XhfTct/+x2cd/3bM/z/Im5Ou6LUpB7vLzDLuiMKkx4/tjhsfOKMjbxbbcnVjlVq0qjEbqSZNSmltTZV8ClsG5XTFzPNiWvk+QAs2JqL0dER8E5eXuEFvZ4SJ2Tnv5NMe4eB4intemVj2cRO/C8L6lVH1xUtVLbWChjS2pko+lSQegDO60jOxbigoAVNJiZ5ca9psfnxlx5D/ItTOaLqVE4tEOKc7yqujKd+xoOwC0WwyW+4BWb8LghKPVFs19qmSxtVUyadSL4+k+MD33uRwztKgHUPTnL1qcW/LyrYIGxJxbt2c4L49E77HTaTgig3prRw+/s9HGBwrTlRrYnOs7IgvacbZYuiCIGFqtCryUj0tnXwc5CUeSF/c39YdoytmjFXYlDqlIz1DbUMizgU9UX487N+C2ntihn3JGb5/0HvSwsYuR2dn1LP7LndAdjnWSeiCICLLrelqu1XD6Kzj7NWV5+WNJy1c9O/+tR56SuSANycdW3YmPcd4AHrb5soOyGYnRty3ZyKvblu91J0TEfHT0i0fP08cmiZR4TvTFSOvOsDNT49wosTQ0amdEd+xJQPGU8bnzuosGn/piMKbY7N84tEjPDs0zdBkcXHUKx8ZprfDGJp0nNIZYWMipq4zEfFVi0oTSj4eHHCi/Cao86IGfV1RrnxkmETM8droHGNlXt/bEaEr7t3wdMAPj8Z4/ckR7riomzt3jc0vPp1MweOHS7ds0hMUFm7vGJrhe/smOGd1jE0nxUv+YanciUhrqVWlCSWfKki59OSFSjw3NMWfXnASW/dP+o4t7U2mp1d3xSMlF58GMZGC547M8tyRWZ46NMl5PW2cmHF5CUblTkRaT60qTSj51MjhSfj0j06UnR6+98SMT/3pxRscdwyOF2+ip3InIq2nVpUmlHxqKMhkuhePz3KST/dcLsNvk4TysglmOf8IW6k7r5XOVRpfrSpNKPnUubFZmJkr3+e21NbRocyF0stS/whbqTuvlc5VmkOtKk1oqnUDmF7ieE8Q2cWkhVtyV+OPsFR3XrPxO9crHxmuuy3YRWBhYfk1mzp5z9o2rtnUGcqXJbV8mlxXFC4+vR3n0uuXVsaMnx+b8dxEb7mqG7RS9WK/cw2zRJJIpWqxsFzJp8n1dKY3jste6LI7qU6lpgHj/JPj3P6uheeX44+wlaoX+51rLk3iEFHyaUjrV0bZsDLq2YoptH80xUe2D/PApT0ABeMRjpdGKljQtEjNUL046CQCr3P10oytPpFKKPk0oA0rozx0eS+wcFE8NJ4iETeefXOKoYJycbnjK7WYSt3oxUormURQeK77crrbcjVjq0+kEko+DWjfaIortg1xUtxwDpKz6cWi153VyX884F2o9NB4yndGXBjfwhu5WGml659yz9UrcTVaq09kOSj5NBgjf/A619b9k0z59MCV+qa9mG/hrbSWZSkTJhq91SeyXJR8Gkyp9Tx+ZXraIwtFT6sx9uLXDXXHRd3c88rEfEL65Gqjv6KfHPz3h5n4ljphopFbfSLLRcmnRXz2ieOctiI6nyD8voUHubD7dUP9xqPH8hLgUx3tPLxxpqqJYbkWcXqdd1YzTJgQqTdKPi1gai69TQTAU4enePjykz0v1EEv7H7dUIUtr8HJSNUnMyxH/Tm/8/7aWemWm7rORKpPFQ5azODYHJdvPeK5yj5oJYIga1myqj2ZYTkWrPqd9137F76bZbvOHrq8l7svXqPEI7JESj4t6I3xOc8dT4Ne2L3K8HT5tKGrPaV4ORas+p330LT+e4gsF/3valF7kylueWYk77GgF3avWlDfed+aooTU1zFX9XGR5ag/53fevW0hFNUTaVGBxnzM7DLgz4Eo8A3n3O0Fz7cDfwe8AxgGPuace83M3g/cDrQB08B/d849VsX4W5YB8cjSio4+dmCKfcmFCQGVDKx7zeB64NJY3rjIJ1cfrXr31HKMv/id943rJ6oRsoh4KJt8zCwK3Am8HxgEnjWzB51zL+Qcdj1wzDn3VjO7FvgK8DHgCHClc+4NM/tFYDuwrton0Yoc6cQTs/x9gaKW3lk1iMk58gbql3phL0xIAwPDec9Xa4p0tacu+5339KHmq7otUi+CtHwuAHY75/YAmNm9wFVAbvK5Crgtc/t+4A4zM+fcT3KO2QV0mFm7c857Gb5UbNYt1HpbuyLKi8em+bdjwQffC8dzlmtNSr3vc+N13gOHahSMSAsIMuazDng95/4gxa2X+WOcc7PACNBTcMxHgZ8o8QQVfHu4bK23uy9ew9mr2yr6LWHVGGulPX1EpLwgLR/zeKzwyljyGDN7O+muuA+U+kUDAwMBwiml0yeURhT8PHYfm+AHz+9mXafjk6uNpzraGZws/72ir2OOT64+WtQ9FtSBCeOu/TGGpiL0ts9x4/pZ1nXm/2lkP9M9R9pJDxnm2zM8uujfH4al/03WXqOfQ6PHD41/DouNv7/fv8ZJkOQzCJyRc78PeMPnmEEziwHdwFEAM+sD/gn4T865VxcbaCBPHFja6+tczCAWgcmCXrWDU1FueqmLc1fHSc46zus1zs3ZPO4nwzMcmliYmdAegV8/vT1vH59K7UvO8IW8brQoL0925HWjDQwMzH+mm944ynMnigfwN/WspL9//aJiWG658fup9xp3Qc6hnjV6/ND457Bc8QdJPs8C/Wa2ETgAXAt8ouCYB4FPAU8BVwOPOeecma0CHgZucc49Wb2wW9Pq9giPXnEyVz4yXFRYdHBsjsGxhR7NjYno/B4+H9o6lHdsb4ctKfFA5ZUGmrFETb2PY4nUs7J9M5kxnJtIz1R7EfiOc26XmX3JzD6cOeybQI+Z7QZ+F7g58/hNwFuBPzCzn2b+nVL1s2gR53RH2ZCIs35l8N0yt+xMMjheUPZm3BWNtexLznDD40e5YtsQNzx+1LMCQq5KKw0sdp/4SuMKk8axRBYv0Dof59xWYGvBY1/MuT0JXOPxui3AliXGKBkWSY8DBS1vE3QPn8V8g19MpYFKZ9IFjatWXV/LUepHpFWowkED+eHBad770GFGp+fo6yr/0a1dEQ2UJBbzDX45Kg0UChJXNkHdt2eCJw5Nc9+eCc/SQcthOUr9iLQKJZ8GMgc8d2SWbYNTHJmY85g7tiCbCLySREcURqfn5i/Qi/kGv9hutEoEiauWXV9hJGCRZqUtFRrUZImyOqd1RvISwQOX9nDLMyM8dmCKybn0bLltg1O8tH2YBy7tWfQ3+OXeJC1IXLXs+tJWCyKLp+RTRwz41VPjzJnx0vAEQzOL67759z3xvAvghkScrnikKGHtTab4/I+O0dUWoT1C3hbc2W/wtZxKHGSGXK27vrRLqcjiKPnUkXgEutoifPnCbvbuHeELr6ws6lIKYtRjO22/FsLjh/PHRjqi8GunpdcAATWdShykZdGMU7hFWoGSTx2ZnoOtr0/x3NCb/MKKOD0dEVIOuuOwJzlXtFOon5Ux44bHj+a1VoLOkJtMwcq2CBsScW54/KjneMqVjwyzfmU0lJZQuZaFur5EGpOSTx06PAmHJ2NAulWyMRHlL34lwR/tHGNoLMVEiRzUE4efH5thcGyhD23H0DR3XNTNg69N5HWt+cmOl/i1lvaPpuYXudbDokp1fYk0Hs12awB7kyluevIE+0dLJx6A9ngkL/FkX3/PKxO8d117oN+XHS8J0lrymlmWXRh64/PtdbcwVETqg1o+DWIi4NDP4XHvps2h8RR3vHsVLx7PH8Mp3A8od7zEazzF72dn5S8MjfLciYn5ltc9r0zUbQ00EQmXkk+T8UsTa1dEPcdHLuuL80c7xxiZmqO7PcIdF+XXfDt7VYzRmTnAiBkcnChObkEWrH54+9G8Te7qobtORGpHyacFdERgb3KWTzx6BOcgOes4bUWU687q5NM/PDZf+21kJsV//sFRNp/czpuTKV46PsvYbPanOPpWGH1d+d167REYm5mb347bb5yocHfVUkVIG0Wl09DroQJ2PcQgAko+LWFyDnYMFY+7PPTaRNHan8OT6QWoXgbHHZf3tXHuavj+wSkmU+m1QVtfn+LF46UXrHr5wRuT8+NBjXZBrLQeXj1UwK6HGESyNOGghZWqkuDnmaFpfjo8U7SnUHYK9nVndQaqOwcwNOn40LYjfGjrUE1qsy1FpWV9wi4D5DXpQ1W4pZ6o5SMVOTrl8Nvie/9oiusfP46bC57VCmfmQfm1RE8enOAzT4xwfGqOVe0Rvv7ubi46rbPic6lUbpfVy8dnPY/xK+sTZhkgv0kfa9q9d8dVFW6pBSUfqapDHhMSsiKki6MG4beW6MmDE1y1/ej8DL0TMymu2n6U7166pmoJKJtk9hxpZ9MbR+dn/xV2WXnxK+sTZhkgvxZOyqkKt9QPJR8JRW+H8c7eNra+7j2eVEru5ITPPDFCYaGHWQefeWKE569ZevLxazWcvSpWNvGUqocXZhkgv1bWqZ0RooZKEUldUPKRUFxyege3bk4UrTPq64qAc0W7rRbKdg0d9ynRMFLw+MIYxyxvTszR22FsOiledjKDX6shPd28WG+H8bZV8fmyPuBfDy+sMkB+rawzEzG+cXFCpYikLij5SNW1G0zl5JKowbb9Ezzz5jR/uLmLRwZnODSeIhE3nIOhqTkikTlO6TDenHTz3W25sl1Dq9ojnJgpfr67fWGSg9esrv2j6b2Qys3u8ms1pGuOFyfIS07vyJsu7lcPL9tyC2NqealWlkoRSb3QbDepulXtcHlfO2/tTGGk1/iMzqbHcT79oxNcd1ZnptpCemO8HUMz7B9NMTzl+MPNXXTF8gfGc7uGvv7ubgqeJmbpx7O8Wi9Z5WZ3+bUazj85HmjjuHrYWjt3o793dKeWZaM/kaVSy0eq7vBkujL22FxxW2HWwQ0/PE4sYkUtnL3JFJ//1xM5C1uhK0Ze1YWLTuvkr95zEp/71yRTs472mPGXv5LIm2zg33pJK5UI/FoN2S0mynVZ1Xp/oaxsC2dgYJj+/vWh/m6RIJR8xNdpnRHPcjpBHBpPkZz1blgfHJ/zmaxNXuLJ3r/nlYn55LIvOcOWn4wxnpl1MD7r2PKTMc4/pWM+EZRb6FoqEeSWINozPMqmnpV5SaZcl5X2FxIJRt1uLarNe8lHnnVdEToW+YV97YooiZh34gq2K9GC3JZKkIWSt25OFHWRZfV1Rcomgmyr4a5zp7j74jUVdVfldnm9Z22burxEfKjl06KCtGc2nhSntyPqW27HT19XhNHpObrMb5jeW1fMPDfMy22pBBlTySaAW54Z4dEDU0znnOzM7By3PDPCiRk3Pw0aqlvep1aD+l5TvEXqlZJPC4oWbKPg5dR25i9eL20vvQ1D3wrjvJ42kjOORNx4fng6k7DyWx8dUfh3q6M8c6Q4gaxfGeXr7+7mpidHSnZZBR1T2ZCI0xWP5CUegMNT5K01eurwVNFU7+yMuEbiV7fta2cZ/TWMS8SPut1aUGGFaS9DU3Dz0yMARd1I3710Td79hz/Yy7fedzIPXd5LVzziu2ZnMgWvJVNFtd+6YsyXyCnXZeXVpeY3pvL8kfIttsGxuaJ4G7HemV935F379f1S6pP+MsXTHOnq1i9tT1erLuxGyp1dli1ieXA8xQvHShcEPTwFF6+KcmzKzXexjc3CTU+O8MClsbJdVl57Evl1k+1OLm6yBDRevTO/7sihaX2/lPqk5CMlZVsBt25OeI6LeHX3lPPCSKpobKfc/j6L2YfGVTqzIUej1Tvz647sbVt8AhZZTko+UtbeE8UJ5qnDU5y7Os6OIzMMVbw3g3dW8GttLHYfmo6YzU/J9uNV3ifbjTd9aLjka+uJ3xTvG9dP1DAqEX9KPlKWV8mbwbE5BscqLxLaGYWUT67ya234jWe873tD8zXjvJLQX/5Kgut/eKLo8QtPidEWieTVY/Pqxhs4VOHJ1ZBfd+T0ocYau5LWoeTT5DqjMDeXX2utEgasajP2VyGWKDCRggmPGQ+lFmL6jmdMOu7bM+HbCvroW9I/r7AaQvbxXM1Q78xrvKyREqi0FiWfJjc9F2x2mx9H9QbfvX5Kb0eES05vLzmGU65iQanxoo++xTvZiEhtaSpMk1tK4sk6Nul8Kwbk6u0w2n3+oqI+FRXetipWtopAqYoFWY02O02k1Sn5tLhzV0f52dWncM0m/43YnOWv9fngGe30rSiuPP3oFb38+untnj8j7vOXFmRWWW7Jmt4O7x/UaLPTRFqdut1aQFesuGBn1hmRRfnSAAAIuElEQVQrF9bWfG/fASY8GhDxSPF4Qnbqc+Eg/e3v6ubnW4fyZo9FLb3AtFAlBTezv99r5psKd4o0HiWfJrcxEeWOi7q5c9dYUZ0zgOeHp9mXnGFDIs6mRIRdx4unor0lUdza8FsMuiER5+EP9s5XhR5KtXluDrd+ZXRRBTcrWWTazBaz7kmknij5NKAI/oVBY0BvZ4S+lVHOTMTmL0oXndbJx//5SFGR0MFxNz9Yf86adnYdL14XcvYa7640P7l7yXxhd6dn8tmwMrroi2Wr78a52HVPIvVEyafBbExE6emIsGOouIxNb4fx6BW9vhegpM+Cy+xg/XLsRVMvm6s1k1LbSrRyUpbGogkHdSgKRAqqAHRE4INntPPApT1sTHh/Z7jk9I6S33zLJYLl2IumkkKgEkw9bNUtslRq+dShD/S18+lTj/OPx9Z4jmsstoUS5HXV7tLSGE31qTUpzSBQ8jGzy4A/J/2l/BvOudsLnm8H/g54BzAMfMw591rmuVuA60mvMfy8c2571aJvQn0rjNvf1c30oWPcfZ53EljsBb1WiaDVx2iqTVt1SzMom3zMLArcCbwfGASeNbMHnXMv5Bx2PXDMOfdWM7sW+ArwMTM7B7gWeDtwOvComZ3lnFP/AAsz0e55ZaLiumKLvaArETQ+tSalGQRp+VwA7HbO7QEws3uBq4Dc5HMVcFvm9v3AHWZmmcfvdc5NAXvNbHfm5z1VnfDrz+o4/PLadpIzrqhw5WvJWQ5PzHFKh7HxpHjeTDSRSuhLhDS6IMlnHfB6zv1B4EK/Y5xzs2Y2AvRkHn+64LXr/H7RwMBAgHBK6SRdCnO5OeIGMy7/d/XE5vjmeVOs6xyffyxblv9/nF78U6YPDZds4Sz9/ai9Rj+HRo8fGv8cGj1+aPxzWGz8/f3+m7gHST5eV/PCObt+xwR57bxSgQbyxIGlvT6AUzoi/M0lq+hbGeOWZ0Z4dmgaMM4/Ob26v1pdHwMDA0t/P2qs0c+h0eOHxj+HRo8fGv8cliv+IMlnEDgj534f8IbPMYNmFgO6gaMBX1tzEaAtCv0nRXnb6rbA/effet/Jyx+ciEgTCpJ8ngX6zWwjcID0BIJPFBzzIPAp0mM5VwOPOeecmT0IfMvM/oz0hIN+4MfVCr7Q8d9ex6q/ybZ+8htem7pgXaJNg7MiInWgbPLJjOHcBGwnPdX6r51zu8zsS8AO59yDwDeBv89MKDhKOkGROe47pCcnzAKfXe6Zbsd/Oz2k1OhNXRGRZhZonY9zbiuwteCxL+bcngSu8XntnwB/soQYRUSkyai8joiIhE7JR0REQqfkIyIioVPyERGR0Cn5iIhI6JR8REQkdEo+IiISOiUfEREJnZKPiIiETslHRERCp+QjIiKhU/IREZHQKfmIiEjolHxERCR0Sj4iIhI6JR8REQmdko+IiIROyUdEREKn5CMiIqFT8hERkdAp+YiISOiUfEREJHRKPiIiEjolHxERCZ2Sj4iIhE7JR0REQqfkIyIioVPyERGR0Cn5iIhI6JR8REQkdEo+IiISOiUfEREJnZKPiIiETslHRERCp+QjIiKhM+dcTQMYGRmpbQAiIrLsuru7Lfe+Wj4iIhI6JR8REQldzbvdRESk9ajlIyIioWv45GNml5nZy2a228xu9ni+3cy+nXn+GTM7M/wo/QWI/1fNbKeZzZrZ1bWIsZQA8f+umb1gZs+b2b+Y2YZaxFlKgHO40cx+bmY/NbMnzOycWsTpp1z8OcddbWbOzM4PM74gAnwG15nZUOYz+KmZ/U4t4vQT5DMws9/I/F/YZWbfCjvGcgJ8Bl/Lef9fMbPjS/qFzrmG/QdEgVeBTUAb8DPgnIJj/gtwV+b2tcC3ax13hfGfCZwH/B1wda1jXkT8vwasyNz+TD29/xWcw0k5tz8MPFLruCuJP3NcAvgh8DRwfq3jXsRncB1wR61jXUL8/cBPgNWZ+6fUOu7F/B3lHP854K+X8jsbveVzAbDbObfHOTcN3AtcVXDMVcDfZm7fD7zXzIz6UDZ+59xrzrnngblaBFhGkPi/75wbz9x9GugLOcZygpzDiZy7XUA9DZQG+T8A8MfAV4HJMIMLKOg51Ksg8d8A3OmcOwbgnHsz5BjLqfQz+Djwf5byCxs9+awDXs+5P5h5zPMY59wsMAL0hBJdeUHir2eVxn89sG1ZI6pcoHMws8+a2aukL+CfDym2IMrGb2a/BJzhnPtemIFVIOjf0Ucz3bf3m9kZ4YQWSJD4zwLOMrMnzexpM7sstOiCCfx/OdN1vhF4bCm/sNGTj1cLpvBbaZBjaqWeYwsicPxm9pvA+cD/XNaIKhfoHJxzdzrn3gL8HnDrskcVXMn4zSwCfA34r6FFVLkgn8FDwJnOufOAR1nozagHQeKPke56u4R0q+EbZrZqmeOqRCXXomuB+51zqaX8wkZPPoNA7jegPuANv2PMLAZ0A0dDia68IPHXs0Dxm9n7gN8HPuycmwoptqAq/QzuBT6yrBFVplz8CeAXgR+Y2WvAu4AH62zSQdnPwDk3nPO3czfwjpBiCyLodei7zrkZ59xe4GXSyaheVPL/4FqW2OUGNPyEgxiwh3QTMDtI9vaCYz5L/oSD79Q67krizzn2HupvwkGQ9/+XSA9k9tc63iWcQ3/O7SuBHbWOezF/Q5njf0D9TTgI8hmclnP7PwBP1zruCuO/DPjbzO2TSXdx9dQ69kr/joBfAF4js0Z0Sb+z1iddhTftg8ArmQvc72ce+xLpb9kAHcB9wG7gx8CmWsdcYfzvJP2tZAwYBnbVOuYK438UOAz8NPPvwVrHvIhz+HNgVyb+75e6uNdj/AXH1l3yCfgZfDnzGfws8xm8rdYxVxi/AX8GvAD8HLi21jEv5u8IuA24vRq/TxUOREQkdI0+5iMiIg1IyUdEREKn5CMiIqFT8hERkdAp+YiISOiUfEREJHRKPiIiEjolHxERCd3/B/6vF1XAB6WTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68896484375"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0562350808385597"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.001522\n",
       "1      0.001499\n",
       "2      0.001489\n",
       "3      0.001516\n",
       "4      0.001572\n",
       "         ...   \n",
       "995    0.002478\n",
       "996    0.002478\n",
       "997    0.002516\n",
       "998    0.002506\n",
       "999    0.002440\n",
       "Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred)[0:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jeu de validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>agg_sales_store_dept</th>\n",
       "      <th>product_share</th>\n",
       "      <th>dow</th>\n",
       "      <th>dom</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>store_id_CA_1</th>\n",
       "      <th>store_id_CA_2</th>\n",
       "      <th>store_id_CA_3</th>\n",
       "      <th>store_id_CA_4</th>\n",
       "      <th>store_id_TX_1</th>\n",
       "      <th>store_id_TX_2</th>\n",
       "      <th>store_id_TX_3</th>\n",
       "      <th>store_id_WI_1</th>\n",
       "      <th>store_id_WI_2</th>\n",
       "      <th>store_id_WI_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881672</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881673</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881674</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881675</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46881676</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>853720 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         snap_CA snap_TX snap_WI  sell_price  agg_sales_store_dept  \\\n",
       "1017           0       0       0        8.38                   0.0   \n",
       "1018           0       0       0        8.38                   0.0   \n",
       "1019           0       0       0        8.38                   0.0   \n",
       "1020           0       0       0        8.38                   0.0   \n",
       "1021           0       0       0        8.38                   0.0   \n",
       "...          ...     ...     ...         ...                   ...   \n",
       "46881672       0       0       0        1.00                   0.0   \n",
       "46881673       0       0       0        1.00                   0.0   \n",
       "46881674       0       0       0        1.00                   0.0   \n",
       "46881675       0       0       0        1.00                   0.0   \n",
       "46881676       0       0       0        1.00                   0.0   \n",
       "\n",
       "          product_share  dow  dom  month  week  ...  store_id_CA_1  \\\n",
       "1017                NaN    0   25      4    17  ...              1   \n",
       "1018                NaN    1   26      4    17  ...              1   \n",
       "1019                NaN    2   27      4    17  ...              1   \n",
       "1020                NaN    3   28      4    17  ...              1   \n",
       "1021                NaN    4   29      4    17  ...              1   \n",
       "...                 ...  ...  ...    ...   ...  ...            ...   \n",
       "46881672            NaN    2   18      5    20  ...              0   \n",
       "46881673            NaN    3   19      5    20  ...              0   \n",
       "46881674            NaN    4   20      5    20  ...              0   \n",
       "46881675            NaN    5   21      5    20  ...              0   \n",
       "46881676            NaN    6   22      5    20  ...              0   \n",
       "\n",
       "          store_id_CA_2  store_id_CA_3 store_id_CA_4  store_id_TX_1  \\\n",
       "1017                  0              0             0              0   \n",
       "1018                  0              0             0              0   \n",
       "1019                  0              0             0              0   \n",
       "1020                  0              0             0              0   \n",
       "1021                  0              0             0              0   \n",
       "...                 ...            ...           ...            ...   \n",
       "46881672              0              0             0              0   \n",
       "46881673              0              0             0              0   \n",
       "46881674              0              0             0              0   \n",
       "46881675              0              0             0              0   \n",
       "46881676              0              0             0              0   \n",
       "\n",
       "          store_id_TX_2  store_id_TX_3  store_id_WI_1  store_id_WI_2  \\\n",
       "1017                  0              0              0              0   \n",
       "1018                  0              0              0              0   \n",
       "1019                  0              0              0              0   \n",
       "1020                  0              0              0              0   \n",
       "1021                  0              0              0              0   \n",
       "...                 ...            ...            ...            ...   \n",
       "46881672              0              0              0              0   \n",
       "46881673              0              0              0              0   \n",
       "46881674              0              0              0              0   \n",
       "46881675              0              0              0              0   \n",
       "46881676              0              0              0              0   \n",
       "\n",
       "          store_id_WI_3  \n",
       "1017                  0  \n",
       "1018                  0  \n",
       "1019                  0  \n",
       "1020                  0  \n",
       "1021                  0  \n",
       "...                 ...  \n",
       "46881672              1  \n",
       "46881673              1  \n",
       "46881674              1  \n",
       "46881675              1  \n",
       "46881676              1  \n",
       "\n",
       "[853720 rows x 28 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation['product_share'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.drop(columns=['product_share'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = model.predict(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation['product_share']=y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017        0.000016\n",
       "1018        0.000016\n",
       "1019        0.000016\n",
       "1020        0.000016\n",
       "1021        0.000016\n",
       "              ...   \n",
       "46881672    0.000059\n",
       "46881673    0.000059\n",
       "46881674    0.000060\n",
       "46881675    0.000060\n",
       "46881676    0.000060\n",
       "Name: product_share, Length: 853720, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation['product_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjnlqYrwfGmJ"
   },
   "outputs": [],
   "source": [
    "#predict sur le jeu de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrCnnqa8fJqW"
   },
   "outputs": [],
   "source": [
    "prediction = np.rint(model.predict(df_test, num_iteration=model.best_iteration))\n",
    "error = mean_squared_error(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuWDTn8VaRvV"
   },
   "outputs": [],
   "source": [
    "best_params = model.params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  RMSE = {}\".format(error))\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "  print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53VP9xrKaS4e"
   },
   "outputs": [],
   "source": [
    "print(‘Best Params:’, best_params)\n",
    "print(‘Tuning history:’, tuning_history)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Hierachical-Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
